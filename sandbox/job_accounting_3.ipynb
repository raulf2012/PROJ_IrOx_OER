{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job accounting attempt 3\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "from collections import Counter \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    get_df_slab,\n",
    "    get_other_job_ids_in_set,\n",
    "    get_df_active_sites,\n",
    "    get_df_slabs_to_run,\n",
    "    get_df_features_targets,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_slab = get_df_slab()\n",
    "\n",
    "df_active_sites = get_df_active_sites()\n",
    "\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_slabs_to_run = df_slabs_to_run.set_index(\"slab_id\")\n",
    "\n",
    "df_features_targets = get_df_features_targets()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_i = df_slab[df_slab.phase == 2]\n",
    "\n",
    "slab_ids = df_slab_i.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_i = df_jobs[\n",
    "    df_jobs.slab_id.isin(slab_ids)\n",
    "    ]\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal[\n",
    "    df_jobs_anal.index.to_frame().slab_id.isin(slab_ids)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job accounting starting from jobs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "\n",
    "    # \"\\n\",\n",
    "    40 * \"#\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"Job accounting (All slabs)\",\n",
    "\n",
    "    \"\\n\",\n",
    "    40 * \"#\",\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting number of unique bulks\n",
    "bulk_ids__i = df_slab_i.bulk_id.unique().tolist()\n",
    "\n",
    "print(\n",
    "    \"There are a total of \",\n",
    "    df_slab_i.shape[0],\n",
    "    \" slabs (phase 2)\",\n",
    "    sep=\"\")\n",
    "\n",
    "df_slab_i_2 = df_slab_i[df_slab_i.num_atoms <= 80]\n",
    "\n",
    "print(\n",
    "    \"  \",\n",
    "    len(bulk_ids__i),\n",
    "    \" unique bulks represented\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \" + 20 * \"-\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slab_i_2.shape[0],\n",
    "    \" of the slabs have 80 atoms or less\",\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slab_i[df_slab_i.num_atoms > 80].shape[0],\n",
    "    \" slabs are > 80 atoms\",\n",
    "    sep=\"\")\n",
    "\n",
    "\n",
    "ids_that_have_been_run = []\n",
    "ids_that_have_not_been_run = []\n",
    "for slab_id_i, row_i in df_slab_i_2.iterrows():\n",
    "    df_ind_i = df_jobs_anal_i.index.to_frame()\n",
    "    df_ind_i = df_ind_i[df_ind_i.slab_id == slab_id_i]\n",
    "\n",
    "    if df_ind_i.shape[0] == 0:\n",
    "        ids_that_have_not_been_run.append(slab_id_i)\n",
    "    else:\n",
    "        ids_that_have_been_run.append(slab_id_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Slabs that were run and are good to go\n",
    "# #########################################################\n",
    "\n",
    "# Getting number of unique bulks\n",
    "df_slab__i = df_slab.loc[df_slab_i_2.index.tolist()]\n",
    "bulk_ids__i = df_slab__i.bulk_id.unique().tolist()\n",
    "\n",
    "print(\"\")\n",
    "print(\n",
    "\n",
    "    \"Of the \",\n",
    "    df_slab_i_2.shape[0],\n",
    "    \" slabs that are 80 atoms or less\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(bulk_ids__i),\n",
    "    \" unique bulks represented\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \" + 20 * \"-\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(ids_that_have_been_run),\n",
    "    \" slabs have been run\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(ids_that_have_not_been_run),\n",
    "    \" slabs have not been run\",\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Slabs that were run and are good to go\n",
    "# #########################################################\n",
    "\n",
    "# #########################################################\n",
    "ids_run__ok = []\n",
    "ids_run__bad = []\n",
    "ids_need_to_man_anal = []\n",
    "for slab_id_i in ids_that_have_been_run:\n",
    "    if slab_id_i in df_slabs_to_run.index:\n",
    "        row_slab_i = df_slabs_to_run.loc[slab_id_i]\n",
    "        status_i = row_slab_i.status\n",
    "\n",
    "        if status_i == \"ok\":\n",
    "            ids_run__ok.append(slab_id_i)\n",
    "        elif status_i == \"bad\":\n",
    "            ids_run__bad.append(slab_id_i)\n",
    "        else:\n",
    "            print(\"bad bad badf sijdifsd998ijsd\")\n",
    "\n",
    "    else:\n",
    "        ids_need_to_man_anal.append(slab_id_i)\n",
    "\n",
    "# Getting number of unique bulks\n",
    "df_slab__been_run = df_slab.loc[ids_that_have_been_run]\n",
    "bulk_ids__been_run = df_slab__been_run.bulk_id.unique().tolist()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\n",
    "    \"Of the \", len(ids_that_have_been_run), \" slabs that were run:\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(bulk_ids__been_run),\n",
    "    \" unique bulks represented\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \" + 20 * \"-\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(ids_run__ok),\n",
    "    \" slabs had good *O relaxed structures\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(ids_run__bad),\n",
    "    \" slabs had bad *O relaxed slabs (bad struct. drift)\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    len(ids_need_to_man_anal),\n",
    "    \" slabs haven't finished or been run, or haven't been manually analyzed\",\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Slabs that were run and are good to go\n",
    "# #########################################################\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "df_slab__ok = df_slab.loc[ids_run__ok]\n",
    "bulk_ids__ok = df_slab__ok.bulk_id.unique().tolist()\n",
    "\n",
    "print(\n",
    "    \"Of the \",\n",
    "     len(ids_run__ok),\n",
    "    \" slabs that were good:\",\n",
    "     sep=\"\")\n",
    "\n",
    "print(\n",
    "    \"  \",\n",
    "    len(bulk_ids__ok),\n",
    "    \" unique bulks represented\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \" + 20 * \"-\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  There are \",\n",
    "    df_active_sites.loc[ids_run__ok].num_active_sites_unique.sum(),\n",
    "    \" total active sites\",\n",
    "\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  Each slab has \",\n",
    "    np.round(\n",
    "        df_active_sites.loc[ids_run__ok].num_active_sites_unique.mean(),\n",
    "        3),\n",
    "    \" active sites on average\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_targets_i = df_features_targets[df_features_targets[\"data\"][\"phase\"] > 1]\n",
    "\n",
    "print(\"\")\n",
    "print(\n",
    "    \"There are \",\n",
    "    df_features_targets_i.shape[0],\n",
    "    \" data points in df_features_targets (phase 2 only)\",\n",
    "    sep=\"\")\n",
    "\n",
    "df_features_targets_i_2 = df_features_targets_i.dropna(\n",
    "    axis=0,\n",
    "    subset=[\n",
    "        (\"targets\", \"g_o\", \"\", ),\n",
    "        (\"targets\", \"g_oh\", \"\", ), \n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"  \",\n",
    "    df_features_targets_i_2.shape[0],\n",
    "    \" of these points have both G_*O and G_*OH\",\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job accounting using good slabs as starting point"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    5  * \"\\n\",\n",
    "\n",
    "    \"\\n\",\n",
    "    40 * \"#\",\n",
    "    \n",
    "    \"\\n\",\n",
    "    \"Check progress on 'good' slabs\",    \n",
    "\n",
    "    \"\\n\",\n",
    "    40 * \"#\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_i = copy.deepcopy(df_slab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs\",\n",
    "    \"out_data\")\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    directory,\n",
    "    \"df_slabs_to_run.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_slabs_to_run = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"There are \",\n",
    "    df_slabs_to_run.shape[0],\n",
    "    \" slabs that come from octahedral, non-layered, stable (0.3 eV/atom hull cutoff) polymorphs\",\n",
    "    \n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slabs_to_run.bulk_id.unique().shape[0],\n",
    "    \" bulk polymorphs make of these slabs\",\n",
    "    \n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    \"Each polymorph makes on average \",\n",
    "    np.round(\n",
    "        df_slabs_to_run.shape[0] / df_slabs_to_run.bulk_id.unique().shape[0],\n",
    "        3),\n",
    "    \" slabs\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import read_data_json\n",
    "\n",
    "data = read_data_json()\n",
    "systems_that_took_too_long = data.get(\"systems_that_took_too_long\", []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_slab_ids = []\n",
    "for slab_id_i, row_i in df_slab_i.iterrows():\n",
    "    bulk_id_i = row_i.bulk_id\n",
    "    facet_i = row_i.facet\n",
    "\n",
    "\n",
    "    took_too_long_i = False\n",
    "    for i in systems_that_took_too_long:\n",
    "        if i[0] == bulk_id_i and i[1] == facet_i:\n",
    "            took_too_long_i = True\n",
    "\n",
    "    # if took_too_long_i:\n",
    "    #     print(\"took_too_long_i\")\n",
    "\n",
    "    df = df_slabs_to_run\n",
    "    df = df[\n",
    "        (df[\"bulk_id\"] == bulk_id_i) &\n",
    "        (df[\"facet_str\"] == facet_i) &\n",
    "        [True for i in range(len(df))]\n",
    "        ]\n",
    "    if df.shape[0] > 0:\n",
    "        good_slab_ids.append(slab_id_i)\n",
    "    \n",
    "    else:\n",
    "        if not took_too_long_i:\n",
    "            tmp = 42\n",
    "            # print(\"What's up with this one:\", slab_id_i)\n",
    "\n",
    "df_slab_i_2 = df_slab_i.loc[good_slab_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP | TEMP | TEMP | TEMP | TEMP | TEMP\n",
    "\n",
    "# bulk_facet_list = []\n",
    "# for slab_id_i, row_i in df_slab_i_2.iterrows():\n",
    "#     tmp = 42\n",
    "\n",
    "#     tup_i = (\n",
    "#         row_i.bulk_id,\n",
    "#         row_i.facet,\n",
    "#         )\n",
    "#     bulk_facet_list.append(tup_i)\n",
    "\n",
    "# idx = pd.MultiIndex.from_tuples(bulk_facet_list)\n",
    "\n",
    "# len(idx.unique().tolist())\n",
    "\n",
    "\n",
    "# for i in bulk_facet_list:\n",
    "#     d = Counter(bulk_facet_list)\n",
    "#     if d[i] > 1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_took_too_long = 0\n",
    "for i_cnt, row_i in df_slabs_to_run.iterrows():\n",
    "    bulk_id_i = row_i.bulk_id\n",
    "    facet_i = row_i.facet_str\n",
    "\n",
    "    # #####################################################\n",
    "    took_too_long_i = False\n",
    "    for i in systems_that_took_too_long:\n",
    "        if i[0] == bulk_id_i and i[1] == facet_i:\n",
    "            took_too_long_i = True\n",
    "\n",
    "\n",
    "    df = df_slab_i\n",
    "    df = df[\n",
    "        (df[\"bulk_id\"] == bulk_id_i) &\n",
    "        (df[\"facet\"] == facet_i) &\n",
    "        [True for i in range(len(df))]\n",
    "        ]\n",
    "\n",
    "    # if took_too_long_i:\n",
    "    #     num_took_too_long += 1\n",
    "\n",
    "    if took_too_long_i and df.shape[0] == 0:\n",
    "        # print(i_cnt)\n",
    "        # print(\"Took too long\", bulk_id_i, facet_i)\n",
    "        num_took_too_long += 1\n",
    "\n",
    "    if df.shape[0] == 0 and not took_too_long_i:\n",
    "        tmp = 42\n",
    "        print(bulk_id_i, facet_i)\n",
    "\n",
    "#         print(\"ijisdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\n\",\n",
    "    df_slab_i_2.shape[0],\n",
    "    \" rows are in df_slab that are from the pristine \",\n",
    "    df_slabs_to_run.shape[0],\n",
    "    \" set\",    \n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    num_took_too_long,\n",
    "    \" slabs took too long to create and are thus missing\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slabs_to_run.shape[0] - df_slab_i_2.shape[0] - num_took_too_long,\n",
    "    \" are still uncounted for\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slab_i_2.shape\n",
    "\n",
    "print(\n",
    "\n",
    "    \"\\n\",\n",
    "    \"Of the 285 pristine slabs:\",\n",
    "    \n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slab_i_2[df_slab_i_2.num_atoms < 80].shape[0],\n",
    "    \" of them are under 80 atoms\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    df_slab_i_2[df_slab_i_2.num_atoms >= 80].shape[0],\n",
    "    \" of them are over 80 atoms\",\n",
    "    \n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slab_i_2.num_atoms.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_list = []\n",
    "num_slabs_list = []\n",
    "for cutoff_i in range(0, 350, 1):\n",
    "    cutoff_list.append(cutoff_i)\n",
    "\n",
    "    num_slabs_i = df_slab_i_2[df_slab_i_2.num_atoms <= cutoff_i].shape[0]\n",
    "    num_slabs_list.append(num_slabs_i)\n",
    "\n",
    "\n",
    "x_array = cutoff_list\n",
    "y_array = num_slabs_list\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    )\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_i_3 = df_slab_i_2[df_slab_i_2.num_atoms < 80]\n",
    "\n",
    "df_ind_i = df_jobs_anal.index.to_frame()\n",
    "\n",
    "num_have_been_run = 0\n",
    "num_have_not_been_run = 0\n",
    "for slab_id_i, row_i in df_slab_i_3.iterrows():\n",
    "\n",
    "    df = df_ind_i\n",
    "    df = df[\n",
    "        (df[\"slab_id\"] == slab_id_i) &\n",
    "        (df[\"ads\"] == \"o\") &\n",
    "        (df[\"active_site\"] == \"NaN\") &\n",
    "        [True for i in range(len(df))]\n",
    "        ]\n",
    "\n",
    "    \n",
    "    if df.shape[0] == 0:\n",
    "        num_have_not_been_run += 1\n",
    "        print(slab_id_i, \"|\", row_i.phase)\n",
    "        # print(df.shape[0])\n",
    "\n",
    "    elif df.shape[0] > 0:\n",
    "        num_have_been_run += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\n\",\n",
    "    \"Of the \",\n",
    "    df_slab_i_3.shape[0],\n",
    "    \" slabs that are under 80 atoms:\",\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    num_have_been_run,\n",
    "    \" slabs have been run\",\n",
    "\n",
    "\n",
    "    \"\\n\",\n",
    "    \"  \",\n",
    "    num_have_not_been_run,\n",
    "    \" slabs have not been run\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# These don't have any jobs run for them, why?\n",
    "# #########################################################\n",
    "\n",
    "# pumusuma_66 | 1\n",
    "# fufalego_15 | 1\n",
    "# tefenipa_47 | 1\n",
    "# silovabu_91 | 1\n",
    "# naronusu_67 | 1\n",
    "# nofabigo_84 | 1\n",
    "# kodefivo_37 | 1\n",
    "\n",
    "# NEW | THESE ARE GOOD NOW I THINK\n",
    "# romudini_21 | 2\n",
    "# wafitemi_24 | 2\n",
    "# kapapohe_58 | 2\n",
    "# bekusuvu_00 | 2\n",
    "# pemupehe_18 | 2\n",
    "# hahesegu_39 | 2\n",
    "# migidome_55 | 2\n",
    "# semodave_57 | 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing something here forgot what"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features_targets_i_2[\n",
    "#     df_features_targets_i_2[\"features\"][\"oh\"][\"octa_vol\"].isnull()\n",
    "#     ].index.tolist()\n",
    "\n",
    "df_features_targets_i_2[\n",
    "    df_features_targets_i_2[\"features\"][\"oh\"][\"octa_vol\"].isnull()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "df_jobs_anal_o = df_jobs_anal_i.loc[\n",
    "    df_index[df_index.ads == \"o\"].index\n",
    "    ]\n",
    "\n",
    "df_jobs_anal_o_i = df_jobs_anal_o[df_jobs_anal_o.job_completely_done == False]\n",
    "\n",
    "indices_to_keep = []\n",
    "for index_i, row_i in df_jobs_anal_o_i.iterrows():\n",
    "    decision_i = row_i.decision\n",
    "\n",
    "    if \"PENDING\" not in decision_i and \"RUNNING\" not in decision_i:\n",
    "        indices_to_keep.append(index_i)\n",
    "\n",
    "df_jobs_anal_o_i.loc[\n",
    "    indices_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_slabs_to_run__ok = df_slabs_to_run[df_slabs_to_run.status == \"ok\"]\n",
    "# df_slabs_to_run__bad = df_slabs_to_run[df_slabs_to_run.status == \"bad\"]\n",
    "\n",
    "# # df_slabs_to_run__bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # df_active_sites\n",
    "\n",
    "# ids_that_have_been_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # df_features_targets_i[\"targets\"]\n",
    "# # df_features_targets_i[(\"targets\", \"g_o\")]\n",
    "# df_features_targets_i.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "#     \"\\n\",\n",
    "#     \"  \" + 20 * \"-\",\n",
    "# print(\n",
    "#     \"  There are \",\n",
    "#     df_active_sites.loc[ids_run__ok].num_active_sites_unique.sum(),\n",
    "#     \" total active sites\",\n",
    "#     sep=\"\")\n",
    "# print(\n",
    "#     \"  Each slab has \",\n",
    "#     np.round(\n",
    "#         df_active_sites.loc[ids_run__ok].num_active_sites_unique.mean(),\n",
    "#         3),\n",
    "#     \" active sites on average\",\n",
    "#     sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# len(good_slab_ids)\n",
    "\n",
    "# np.unique(good_slab_ids).shape\n",
    "\n",
    "# df_slab_i.shape\n",
    "\n",
    "# df_slab_i.slab_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df = df_slab_i_2\n",
    "# df = df[\n",
    "#     (df[\"bulk_id\"] == \"n36axdbw65\") &\n",
    "#     (df[\"facet\"] == \"023\") &\n",
    "#     # (df[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# print('{} has occurred {} times'.format(x, d[x])) \n",
    "# l = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5] \n",
    "# l = bulk_facet_list\n",
    "# x = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_slab_i_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_slabs_to_run.loc[[\n",
    "#     211,\n",
    "#     217,\n",
    "#     250,\n",
    "#     256,\n",
    "#     263,\n",
    "#     264,\n",
    "#     265,\n",
    "#     267,\n",
    "#     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# b583vr8hvw 110\n",
    "# b583vr8hvw 310\n",
    "# b583vr8hvw 200\n",
    "# b583vr8hvw 111\n",
    "# b583vr8hvw 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(111 * \"TEMP | \")\n",
    "# df_slab_i_3 = df_slab_i_3.loc[[\n",
    "#     \"vapopihe_87\"    \n",
    "#     ]]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
