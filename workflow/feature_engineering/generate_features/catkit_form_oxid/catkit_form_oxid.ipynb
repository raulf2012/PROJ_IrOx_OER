{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute formal oxidation state from Kirsten's CatKit code\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_active_sites,\n",
    "    create_name_str_from_tup,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_jobs_paths,\n",
    "    get_df_features,\n",
    "    get_df_coord_wrap,\n",
    "    get_df_features_targets,\n",
    "    get_df_slabs_to_run,\n",
    "    )\n",
    "\n",
    "# from methods_features import original_slab_is_good\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import set_formal_oxidation_state, get_connectivity\n",
    "from local_methods import get_catkit_form_oxid_state_wrap\n",
    "from local_methods import get_effective_ox_state__test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_active_sites = get_df_active_sites()\n",
    "\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_slabs_to_run = df_slabs_to_run.set_index([\"compenv\", \"slab_id\", \"att_num\"])\n",
    "\n",
    "df_features_targets = get_df_features_targets()\n",
    "\n",
    "df_features = get_df_features()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_jobs_paths = get_df_jobs_paths()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_done = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "df_jobs_anal_i =  df_jobs_anal_i[df_jobs_anal_i.job_completely_done == True]\n",
    "\n",
    "# Selecting *O and *OH systems to process\n",
    "df_index = df_jobs_anal_i.index.to_frame()\n",
    "df_index_i = df_index[\n",
    "    df_index.ads.isin([\"o\", \"oh\", ])\n",
    "    ]\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    df_index_i.index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further filtering df_jobs_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "indices_to_run = []\n",
    "# #########################################################\n",
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "    # #####################################################\n",
    "    run_row = True\n",
    "    if name_i in df_atoms_sorted_ind.index:\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[name_i]\n",
    "        # #####################################################\n",
    "        failed_to_sort_i = row_atoms_i.failed_to_sort\n",
    "        # #####################################################\n",
    "\n",
    "        if failed_to_sort_i:\n",
    "            run_row = False\n",
    "    else:\n",
    "        run_row = False\n",
    "\n",
    "    if run_row:\n",
    "        indices_to_run.append(name_i)\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    indices_to_run    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "df = df_ind\n",
    "df = df[\n",
    "    # (df[\"compenv\"] == compenv_i) &\n",
    "    # (df[\"slab_id\"] == slab_id_i) &\n",
    "    (df[\"ads\"] == \"o\") &\n",
    "    # (df[\"active_site\"] == active_site_i) &\n",
    "    # (df[\"att_num\"] == att_num_i) &\n",
    "    # (df[\"\"] == ads_i) &\n",
    "    [True for i in range(len(df))]\n",
    "    ]\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    df.index\n",
    "    ]\n",
    "df_jobs_anal_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_ids = [\n",
    "\n",
    "\"tofebave_45\",\n",
    "\"titawupu_08\",\n",
    "\"rudosavu_57\",\n",
    "\"filetumi_93\",\n",
    "\"ralutiwa_59\",\n",
    "\"lilotuta_67\",\n",
    "\"bikoradi_95\",\n",
    "\"kakalito_08\",\n",
    "\"wefakuko_75\",\n",
    "\"filetumi_93\",\n",
    "\"rudosavu_57\",\n",
    "\"filetumi_93\",\n",
    "\"titawupu_08\",\n",
    "\"wefakuko_75\",\n",
    "\"vinamepa_43\",\n",
    "\"filetumi_93\",\n",
    "\"wesaburu_95\",\n",
    "\"rudosavu_57\",\n",
    "\"dukavula_34\",\n",
    "\"bikoradi_95\",\n",
    "\"lilotuta_67\",\n",
    "\"lilotuta_67\",\n",
    "\"bikoradi_95\",\n",
    "\"vinamepa_43\",\n",
    "\"ramufalu_44\",\n",
    "\"wefakuko_75\",\n",
    "\"putarude_21\",\n",
    "\"dukavula_34\",\n",
    "\"vinamepa_43\",\n",
    "\"putarude_21\",\n",
    "\"wefakuko_75\",\n",
    "\"vinamepa_43\",\n",
    "\"fogopemi_28\",\n",
    "\"vinamepa_43\",\n",
    "\"tofebave_45\",\n",
    "\"kakalito_08\",\n",
    "\"lilotuta_67\",\n",
    "]\n",
    "\n",
    "# slab_ids = [\n",
    "#     # \"titawupu_08\",\n",
    "#     \"ralutiwa_59\",\n",
    "#     ]\n",
    "\n",
    "df_ind = df_jobs_anal_i.index.to_frame()\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    df_ind[df_ind.slab_id.isin(slab_ids)].index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('slac', 'ralutiwa_59', 'o', 31.0, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "iterator = tqdm(df_jobs_anal_i.index, desc=\"1st loop\")\n",
    "for i_cnt, name_i in enumerate(iterator):\n",
    "    # print(name_i)\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    row_i = df_jobs_anal_i.loc[name_i]\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "\n",
    "    if verbose:\n",
    "        name_concat_i = \"_\".join([str(i) for i in list(name_i)])\n",
    "        print(40 * \"=\")\n",
    "        print(name_concat_i)\n",
    "        print(name_i)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(\n",
    "        list(df_jobs_anal_i.index.names), list(name_i)))\n",
    "\n",
    "    # #####################################################\n",
    "    row_atoms_i = df_atoms_sorted_ind.loc[name_i]\n",
    "    # #####################################################\n",
    "    atoms_sorted_good_i = row_atoms_i.atoms_sorted_good\n",
    "    # #####################################################\n",
    "    atoms = atoms_sorted_good_i\n",
    "\n",
    "    # #####################################################\n",
    "    row_sites_i = df_active_sites.loc[slab_id_i]\n",
    "    # #####################################################\n",
    "    active_sites_unique_i = row_sites_i.active_sites_unique\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    data_dict_i[\"job_id_max\"] = job_id_max_i\n",
    "\n",
    "\n",
    "    if active_site_i != \"NaN\":\n",
    "        # read_orig_O_df_coord_i = False\n",
    "\n",
    "        active_site_j = active_site_i\n",
    "\n",
    "\n",
    "        # oxid_state_i = get_catkit_form_oxid_state_wrap()\n",
    "        data_out_dict_i = get_catkit_form_oxid_state_wrap(\n",
    "            atoms=atoms,\n",
    "            name=name_i,\n",
    "            active_site=active_site_j,\n",
    "            )\n",
    "        oxid_state_i = data_out_dict_i[\"form_oxid\"]\n",
    "        atoms_out_i = data_out_dict_i[\"atoms_out\"]\n",
    "        neigh_dict_i = data_out_dict_i[\"neigh_dict\"]\n",
    "        \n",
    "        # atoms_out_i.write(\"tmp.traj\")\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_j = dict()\n",
    "        # #################################################\n",
    "        data_dict_j[\"from_oh\"] = True\n",
    "        data_dict_j[\"form_oxid_state__catkit\"] = oxid_state_i\n",
    "        data_dict_j[\"atoms_catkit\"] = atoms_out_i\n",
    "        data_dict_j[\"neigh_dict\"] = neigh_dict_i\n",
    "        # #################################################\n",
    "        data_dict_j.update(name_dict_i)\n",
    "        # data_dict_j.update(out_dict)\n",
    "        data_dict_j.update(data_dict_i)\n",
    "        # data_dict_j.update(data_out_dict_i)\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_j)\n",
    "        # #################################################\n",
    "\n",
    "    \n",
    "    else:\n",
    "        for active_site_j in active_sites_unique_i:\n",
    "\n",
    "            if verbose:\n",
    "                print(\"active_site_j:\", active_site_j)\n",
    "\n",
    "            # oxid_state_i = get_catkit_form_oxid_state_wrap(\n",
    "            data_out_dict_i = get_catkit_form_oxid_state_wrap(\n",
    "                atoms=atoms,\n",
    "                name=name_i,\n",
    "                active_site=active_site_j,\n",
    "                )\n",
    "            oxid_state_i = data_out_dict_i[\"form_oxid\"]\n",
    "            atoms_out_i = data_out_dict_i[\"atoms_out\"]\n",
    "            neigh_dict_i = data_out_dict_i[\"neigh_dict\"]\n",
    "            # atoms_out_i.write(\"tmp.traj\")\n",
    "\n",
    "            # #############################################\n",
    "            data_dict_j = dict()\n",
    "            # #############################################\n",
    "            data_dict_j[\"from_oh\"] = False\n",
    "            data_dict_j[\"form_oxid_state__catkit\"] = oxid_state_i\n",
    "            data_dict_j[\"active_site\"] = active_site_j\n",
    "            data_dict_j[\"atoms_catkit\"] = atoms_out_i\n",
    "            data_dict_j[\"neigh_dict\"] = neigh_dict_i\n",
    "            # #############################################\n",
    "            name_dict_i_cpy = copy.deepcopy(name_dict_i)\n",
    "            name_dict_i_cpy.pop(\"active_site\")\n",
    "            data_dict_j.update(name_dict_i_cpy)\n",
    "            # data_dict_j.update(out_dict)\n",
    "            data_dict_j.update(data_dict_i)\n",
    "            # data_dict_j.update(data_out_dict_i)\n",
    "            # #############################################\n",
    "            data_dict_list.append(data_dict_j)\n",
    "            # #############################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_eff_ox = pd.DataFrame(data_dict_list)\n",
    "df_eff_ox = df_eff_ox.set_index([\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", \"from_oh\", ])\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_indices = df_features.index.intersection(\n",
    "    df_eff_ox.index\n",
    "    ).unique()\n",
    "\n",
    "\n",
    "data_dict_list = []\n",
    "for index_i in shared_indices:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    # #####################################################\n",
    "    row_feat_i = df_features.loc[index_i]\n",
    "    # #####################################################\n",
    "    eff_oxid_state__mine = row_feat_i[\"features\"][\"eff_oxid_state\"]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_ox_i = df_eff_ox.loc[index_i]\n",
    "    # #####################################################\n",
    "    eff_oxid_state__catkit = row_ox_i[\"form_oxid_state__catkit\"]\n",
    "    job_id_i = row_ox_i.job_id_max\n",
    "    atoms_catkit_i = row_ox_i.atoms_catkit\n",
    "    neigh_dict__catkit_i = row_ox_i[\"neigh_dict\"]\n",
    "    # #####################################################\n",
    "\n",
    "    index_slabs_to_run = (index_i[0], index_i[1], index_i[4], )\n",
    "    if index_slabs_to_run in df_slabs_to_run.index:\n",
    "        row_slab_i = df_slabs_to_run.loc[\n",
    "            index_slabs_to_run\n",
    "            ]\n",
    "        status_i = row_slab_i.status\n",
    "    else:\n",
    "        status_i = \"NaN\"\n",
    "\n",
    "    # row_slab_i = df_slabs_to_run.loc[\n",
    "    #     # (name_i[0], name_i[1], name_i[4], )\n",
    "    #     (index_i[0], index_i[1], index_i[4], )\n",
    "    #     ]\n",
    "    # status_i = row_slab_i.status\n",
    "\n",
    "\n",
    "    if not np.isnan(eff_oxid_state__mine) and not np.isnan(eff_oxid_state__catkit):\n",
    "        isclose_i = np.isclose(\n",
    "            eff_oxid_state__mine,\n",
    "            eff_oxid_state__catkit,\n",
    "            atol=1e-05,\n",
    "            equal_nan=True,\n",
    "            )\n",
    "\n",
    "        if not isclose_i:\n",
    "            if True:\n",
    "            # if status_i == \"ok\":\n",
    "                print(\n",
    "                    status_i,\n",
    "                    \" | \",\n",
    "                    index_i,\n",
    "                    \": \",\n",
    "                    np.round(eff_oxid_state__mine, 3),\n",
    "                    \" | \",\n",
    "                    np.round(eff_oxid_state__catkit, 3),\n",
    "                    sep=\"\")\n",
    "\n",
    "            # #############################################\n",
    "            data_dict_i[\"status\"] = status_i\n",
    "            data_dict_i[\"index\"] = index_i\n",
    "            data_dict_i[\"compenv\"] = index_i[0]\n",
    "            data_dict_i[\"slab_id\"] = index_i[1]\n",
    "            data_dict_i[\"ads\"] = index_i[2]\n",
    "            data_dict_i[\"active_site\"] = index_i[3]\n",
    "            data_dict_i[\"att_num\"] = index_i[4]\n",
    "            data_dict_i[\"from_oh\"] = index_i[5]\n",
    "            data_dict_i[\"job_id\"] = job_id_i\n",
    "            data_dict_i[\"atoms_catkit\"] = atoms_catkit_i\n",
    "            data_dict_i[\"neigh_dict__catkit\"] = neigh_dict__catkit_i\n",
    "            # #############################################\n",
    "            data_dict_list.append(data_dict_i)\n",
    "            # #############################################\n",
    "\n",
    "# #########################################################\n",
    "df_oxi_comp = pd.DataFrame(data_dict_list)\n",
    "df_oxi_comp = df_oxi_comp.set_index([\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ])\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('sherlock', 'filetumi_93', 'o', 67.0, 1) | Kirsten's better\n",
    "# ('sherlock', 'ramufalu_44', 'o', 54.0, 1) | Kirsten's better\n",
    "# ('sherlock', 'filetumi_93', 'o', 65.0, 1) | Kirsten's better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38 don't match\n",
    "# 7 with ok "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_i = ('nersc', 'titawupu_08', 'o', 78.0, 1, False)\n",
    "# name_i = ('nersc', 'titawupu_08', 'o', 78.0, 1, )\n",
    "\n",
    "names = [\n",
    "    # ('sherlock', 'filetumi_93', 'o', 67.0, 1, True),\n",
    "    # ('sherlock', 'ramufalu_44', 'o', 54.0, 1, True),\n",
    "    # ('sherlock', 'filetumi_93', 'o', 65.0, 1, True),\n",
    "    # ('sherlock', 'filetumi_93', 'o', 65.0, 1, False),\n",
    "    # ('sherlock', 'filetumi_93', 'o', 60.0, 1, False),\n",
    "\n",
    "    # ('sherlock', 'vinamepa_43', 'o', 77.0, 1, False),\n",
    "\n",
    "    ('slac', 'ralutiwa_59', 'o', 31.0, 1, False),\n",
    "    ]\n",
    "\n",
    "for name_i in names:\n",
    "    name_i = (name_i[0], name_i[1], name_i[2], name_i[3], name_i[4], )\n",
    "\n",
    "    print(40 * \"-\")\n",
    "    print(\"name_i:\", name_i)\n",
    "    active_site_i = name_i[3]\n",
    "\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "#     row_oxi_comp_i = df_oxi_comp.loc[name_i].iloc[0]\n",
    "    row_oxi_comp_i = df_oxi_comp.loc[name_i]\n",
    "    # #########################################################\n",
    "    from_oh_i = row_oxi_comp_i.from_oh\n",
    "    job_id_i = row_oxi_comp_i.job_id\n",
    "    atoms_catkit_i = row_oxi_comp_i.atoms_catkit\n",
    "    neigh_dict__catkit_i = row_oxi_comp_i[\"neigh_dict__catkit\"]\n",
    "    # #########################################################\n",
    "\n",
    "    # #########################################################\n",
    "    row_atoms_i = df_atoms_sorted_ind[df_atoms_sorted_ind.job_id == job_id_i]\n",
    "    row_atoms_i = row_atoms_i.iloc[0]\n",
    "    # #########################################################\n",
    "    atoms_i = row_atoms_i.atoms_sorted_good\n",
    "    name_orig_i = row_atoms_i.name\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    atoms_i[int(active_site_i)].symbol = \"N\"\n",
    "\n",
    "    # #########################################################\n",
    "    dir_name_i = create_name_str_from_tup(name_i)\n",
    "\n",
    "    directory = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/feature_engineering/catkit_form_oxid\",\n",
    "        \"out_data\",\n",
    "        dir_name_i,\n",
    "        )\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "    atoms_catkit_i.write(os.path.join(directory, \"atoms_catkit.traj\"))\n",
    "\n",
    "    # #########################################################\n",
    "    # #########################################################\n",
    "    # #########################################################\n",
    "    # #########################################################\n",
    "\n",
    "    df_coord_i = get_df_coord_wrap(name=name_orig_i, active_site=active_site_i)\n",
    "\n",
    "    if from_oh_i:\n",
    "        active_site_original = active_site_i\n",
    "    else:\n",
    "        active_site_original = \"NaN\"\n",
    "\n",
    "    print(\"My numbers\")\n",
    "    metal_atom_symbol_i = \"Ir\"\n",
    "    out_dict = get_effective_ox_state__test(\n",
    "        # name=name_i,\n",
    "        name=name_orig_i,\n",
    "        active_site=active_site_i,\n",
    "        df_coord_i=df_coord_i,\n",
    "        metal_atom_symbol=metal_atom_symbol_i,\n",
    "        active_site_original=name_orig_i[3],\n",
    "        )\n",
    "    neigh_dict_i = out_dict[\"neigh_dict\"]\n",
    "    effective_ox_state_i = out_dict[\"effective_ox_state\"]\n",
    "    # print(effective_ox_state_i)\n",
    "\n",
    "    coord_list = []\n",
    "    for atom in atoms_i:\n",
    "        coord_i = neigh_dict_i.get(atom.index, 0)\n",
    "        coord_list.append(coord_i)\n",
    "\n",
    "    atoms_i.set_initial_charges(np.round(coord_list, 4))\n",
    "\n",
    "    atoms_i.write(os.path.join(directory, \"final.traj\"))\n",
    "    atoms_i.write(os.path.join(directory, \"final.cif\"))\n",
    "\n",
    "    # #########################################################\n",
    "    neigh_keys = list(neigh_dict__catkit_i.keys())\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"catkit numbers\")\n",
    "    for i in np.sort(neigh_keys):\n",
    "        print(\n",
    "            i,\n",
    "            \"|\",\n",
    "            neigh_dict__catkit_i[i]\n",
    "            )\n",
    "\n",
    "    coord_list = []\n",
    "    for atom in atoms_i:\n",
    "        coord_i = neigh_dict__catkit_i.get(atom.index, 0)\n",
    "        coord_list.append(coord_i)\n",
    "\n",
    "    atoms_i.set_initial_charges(np.round(coord_list, 4))\n",
    "\n",
    "    atoms_i.write(os.path.join(directory, \"final__catkit.traj\"))\n",
    "    atoms_i.write(os.path.join(directory, \"final__catkit.cif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# row_atoms_i = df_atoms_sorted_ind[df_atoms_sorted_ind.job_id == job_id_i]\n",
    "# row_atoms_i = row_atoms_i.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_atoms_sorted_ind[df_atoms_sorted_ind.job_id == job_id_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# job_id_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_atoms_sorted_ind.job_id == job_id_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# from methods_features import original_slab_is_good\n",
    "# from methods_features import find_missing_O_neigh_with_init_df_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# name = name_orig_i\n",
    "# active_site = active_site_i\n",
    "# df_coord_i = df_coord_i\n",
    "# metal_atom_symbol = metal_atom_symbol_i\n",
    "# active_site_original = name_orig_i[3]\n",
    "\n",
    "# # def get_effective_ox_state__test(\n",
    "# #     name=None,\n",
    "# #     active_site=None,\n",
    "# #     df_coord_i=None,\n",
    "# #     metal_atom_symbol=\"Ir\",\n",
    "# #     active_site_original=None,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# #| - get_effective_ox_state\n",
    "# # #########################################################\n",
    "# name_i = name\n",
    "# active_site_j = active_site\n",
    "# # #########################################################\n",
    "# compenv_i = name_i[0]\n",
    "# slab_id_i = name_i[1]\n",
    "# ads_i = name_i[2]\n",
    "# active_site_i = name_i[3]\n",
    "# att_num_i = name_i[4]\n",
    "# # #########################################################\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# #| - Processing central Ir atom nn_info\n",
    "# df_coord_i = df_coord_i.set_index(\"structure_index\", drop=False)\n",
    "\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# import pickle\n",
    "\n",
    "\n",
    "\n",
    "# # row_coord_i = df_coord_i.loc[21]\n",
    "# row_coord_i = df_coord_i.loc[active_site_j]\n",
    "\n",
    "# nn_info_i = row_coord_i.nn_info\n",
    "\n",
    "# neighbor_count_i = row_coord_i.neighbor_count\n",
    "# num_Ir_neigh = neighbor_count_i.get(\"Ir\", 0)\n",
    "\n",
    "# mess_i = \"For now only deal with active sites that have 1 Ir neighbor\"\n",
    "# # print(\"num_Ir_neigh:\", num_Ir_neigh)\n",
    "# assert num_Ir_neigh == 1, mess_i\n",
    "\n",
    "# for j_cnt, nn_j in enumerate(nn_info_i):\n",
    "#     site_j = nn_j[\"site\"]\n",
    "#     elem_j = site_j.as_dict()[\"species\"][0][\"element\"]\n",
    "\n",
    "#     if elem_j == metal_atom_symbol:\n",
    "#         corr_j_cnt = j_cnt\n",
    "\n",
    "# site_j = nn_info_i[corr_j_cnt]\n",
    "# metal_index = site_j[\"site_index\"]\n",
    "# #__|\n",
    "\n",
    "# # #########################################################\n",
    "# row_coord_i = df_coord_i.loc[metal_index]\n",
    "\n",
    "# neighbor_count_i = row_coord_i[\"neighbor_count\"]\n",
    "# nn_info_i =  row_coord_i.nn_info\n",
    "# num_neighbors_i = row_coord_i.num_neighbors\n",
    "\n",
    "# num_O_neigh = neighbor_count_i.get(\"O\", 0)\n",
    "\n",
    "# six_O_neigh = num_O_neigh == 6\n",
    "# mess_i = \"There should be exactly 6 oxygens about the Ir atom\"\n",
    "# # assert six_O_neigh, mess_i\n",
    "\n",
    "# six_neigh = num_neighbors_i == 6\n",
    "# mess_i = \"Only 6 neighbors total is allowed, all oxygens\"\n",
    "# # assert six_neigh, mess_i\n",
    "\n",
    "# skip_this_sys = False\n",
    "# if not six_O_neigh or not six_neigh:\n",
    "#     skip_this_sys = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from methods import get_df_coord\n",
    "\n",
    "# init_slab_name_tuple_i = (\n",
    "#     compenv_i, slab_id_i, ads_i,\n",
    "#     active_site_original, att_num_i,\n",
    "#     )\n",
    "# # print(\"init_slab_name_tuple_i:\", init_slab_name_tuple_i)\n",
    "# df_coord_orig_slab = get_df_coord(\n",
    "#     mode=\"init-slab\",\n",
    "#     init_slab_name_tuple=init_slab_name_tuple_i,\n",
    "#     )\n",
    "\n",
    "# orig_slab_good_i = original_slab_is_good(\n",
    "#     nn_info=nn_info_i,\n",
    "#     # slab_id=None,\n",
    "#     metal_index=metal_index,\n",
    "#     df_coord_orig_slab=df_coord_orig_slab,\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# num_missing_Os = 0\n",
    "# used_unrelaxed_df_coord = False\n",
    "# if not six_O_neigh:\n",
    "#     used_unrelaxed_df_coord = True\n",
    "\n",
    "#     from methods import get_df_coord\n",
    "#     init_slab_name_tuple_i = (\n",
    "#         compenv_i, slab_id_i, ads_i,\n",
    "#         # active_site_i, att_num_i,\n",
    "#         active_site_original, att_num_i,\n",
    "#         )\n",
    "#     df_coord_orig_slab = get_df_coord(\n",
    "#         mode=\"init-slab\",\n",
    "#         init_slab_name_tuple=init_slab_name_tuple_i,\n",
    "#         )\n",
    "\n",
    "#     out_dict_0 = find_missing_O_neigh_with_init_df_coord(\n",
    "#         nn_info=nn_info_i,\n",
    "#         slab_id=slab_id_i,\n",
    "#         metal_index=metal_index,\n",
    "#         df_coord_orig_slab=df_coord_orig_slab,\n",
    "#         )\n",
    "#     new_nn_info_i = out_dict_0[\"nn_info\"]\n",
    "#     num_missing_Os = out_dict_0[\"num_missing_Os\"]\n",
    "#     orig_slab_good_i = out_dict_0[\"orig_slab_good\"]\n",
    "\n",
    "#     nn_info_i = new_nn_info_i\n",
    "\n",
    "#     if new_nn_info_i is not None:\n",
    "#         skip_this_sys = False\n",
    "#     else:\n",
    "#         skip_this_sys = True\n",
    "\n",
    "# # #####################################################\n",
    "# effective_ox_state = None\n",
    "# # if six_O_neigh and six_neigh:\n",
    "# if not skip_this_sys:\n",
    "#     #| - Iterating through 6 oxygens\n",
    "#     second_shell_coord_list = []\n",
    "#     tmp_list = []\n",
    "\n",
    "#     print(\"nn_info_i:\", nn_info_i)\n",
    "\n",
    "#     neigh_dict = dict()\n",
    "#     for nn_j in nn_info_i:\n",
    "\n",
    "#         from_orig_df_coord = nn_j.get(\"from_orig_df_coord\", False)\n",
    "#         if from_orig_df_coord:\n",
    "#             Ir_neigh_adjustment = 1\n",
    "\n",
    "#             active_metal_in_nn_list = False\n",
    "#             for i in df_coord_i.loc[site_index].nn_info:\n",
    "#                 if i[\"site_index\"] == metal_index:\n",
    "#                     active_metal_in_nn_list = True\n",
    "\n",
    "#             if active_metal_in_nn_list:\n",
    "#                 Ir_neigh_adjustment = 0\n",
    "\n",
    "#         else:\n",
    "#             Ir_neigh_adjustment = 0\n",
    "\n",
    "\n",
    "#         site_index = nn_j[\"site_index\"]\n",
    "\n",
    "#         row_coord_j = df_coord_i.loc[site_index]\n",
    "\n",
    "#         neighbor_count_j = row_coord_j.neighbor_count\n",
    "\n",
    "#         num_Ir_neigh_j = neighbor_count_j.get(\"Ir\", 0)\n",
    "\n",
    "#         # print(site_index, \"|\", num_Ir_neigh_j)\n",
    "\n",
    "#         neigh_dict[site_index] = num_Ir_neigh_j\n",
    "\n",
    "#         # print(\"num_Ir_neigh_j:\", site_index, num_Ir_neigh_j)\n",
    "#         num_Ir_neigh_j += Ir_neigh_adjustment\n",
    "\n",
    "#         # print(\"num_Ir_neigh_j:\", num_Ir_neigh_j)\n",
    "\n",
    "#         second_shell_coord_list.append(num_Ir_neigh_j)\n",
    "\n",
    "#         tmp_list.append(2 / num_Ir_neigh_j)\n",
    "\n",
    "#     # second_shell_coord_list\n",
    "#     effective_ox_state = np.sum(tmp_list)\n",
    "#     #__|\n",
    "\n",
    "\n",
    "# neigh_keys = list(neigh_dict.keys())\n",
    "\n",
    "# for i in np.sort(neigh_keys):\n",
    "#     print(\n",
    "#         i,\n",
    "#         \"|\",\n",
    "#         neigh_dict[i]\n",
    "#         )\n",
    "\n",
    "# # #####################################################\n",
    "# out_dict = dict()\n",
    "# # #####################################################\n",
    "# out_dict[\"effective_ox_state\"] = effective_ox_state\n",
    "# out_dict[\"used_unrelaxed_df_coord\"] = used_unrelaxed_df_coord\n",
    "# out_dict[\"num_missing_Os\"] = num_missing_Os\n",
    "# out_dict[\"orig_slab_good\"] = orig_slab_good_i\n",
    "# out_dict[\"neigh_dict\"] = neigh_dict\n",
    "# # #####################################################\n",
    "# # return(out_dict)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# effective_ox_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# metal_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_coord_i.loc[26].nn_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# active_metal_in_nn_list = False\n",
    "# for i in df_coord_i.loc[22].nn_info:\n",
    "#     if i[\"site_index\"] == metal_index:\n",
    "#         active_metal_in_nn_list = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # row_coord_i\n",
    "# # row_coord_i.nn_info\n",
    "\n",
    "# nn_info_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_oxi_comp.loc[name_i].iloc[0]\n",
    "# df_oxi_comp.loc[name_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# name_i"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
