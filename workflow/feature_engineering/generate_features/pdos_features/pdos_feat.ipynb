{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the p-band center feature for all systems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/feature_engineering/generate_features/pdos_features\n",
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# #########################################################\n",
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_active_sites,\n",
    "    get_df_jobs_data,\n",
    "    get_df_jobs,\n",
    "    read_pdos_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "df_jobs_i = df_jobs\n",
    "\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "df_atoms_sorted_ind_i = df_atoms_sorted_ind\n",
    "\n",
    "df_active_sites = get_df_active_sites()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering down `df_jobs_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_i = df_jobs_i[df_jobs_i.rev_num == df_jobs_i.num_revs]\n",
    "\n",
    "dos_bader_job_ids = df_jobs_i[df_jobs_i.job_type == \"dos_bader\"].index.tolist()\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_jobs_data_i = df_jobs_data.loc[\n",
    "    dos_bader_job_ids\n",
    "    ]\n",
    "df_jobs_data_i = df_jobs_data_i.set_index(\"job_id_orig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering down to `oer_adsorbate` jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal.index.to_frame()\n",
    "df_jobs_anal = df_jobs_anal.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]\n",
    "df_jobs_anal = df_jobs_anal.droplevel(level=0)\n",
    "\n",
    "\n",
    "df_ind = df_atoms_sorted_ind_i.index.to_frame()\n",
    "df_atoms_sorted_ind_i = df_atoms_sorted_ind_i.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]\n",
    "df_atoms_sorted_ind_i = df_atoms_sorted_ind_i.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/feature_engineering\"))\n",
    "\n",
    "from feature_engineering_methods import get_df_feat_rows\n",
    "df_feat_rows = get_df_feat_rows(\n",
    "    df_jobs_anal=df_jobs_anal,\n",
    "    df_atoms_sorted_ind=df_atoms_sorted_ind_i,\n",
    "    df_active_sites=df_active_sites,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc332367e4a1437db8143c7e73455d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1st loop', max=2818.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "iterator = tqdm(df_feat_rows.index, desc=\"1st loop\")\n",
    "for i_cnt, index_i in enumerate(iterator):\n",
    "    # #####################################################\n",
    "    row_i = df_feat_rows.loc[index_i]\n",
    "    # #####################################################\n",
    "    # job_type_i = row_i.job_type\n",
    "    compenv_i = row_i.compenv\n",
    "    slab_id_i = row_i.slab_id\n",
    "    ads_i = row_i.ads\n",
    "    active_site_orig_i = row_i.active_site_orig\n",
    "    att_num_i = row_i.att_num\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    active_site_i = row_i.active_site\n",
    "    # #####################################################\n",
    "\n",
    "    if job_id_max_i in df_jobs_data_i.index:\n",
    "        # print(ads_i)\n",
    "        # print(job_id_max_i)\n",
    "\n",
    "        # #########################################################\n",
    "        row_data_i = df_jobs_data_i.loc[job_id_max_i]\n",
    "        # #########################################################\n",
    "        job_id_pdos_i = row_data_i.job_id\n",
    "        # #########################################################\n",
    "\n",
    "        if active_site_orig_i == \"NaN\":\n",
    "            from_oh_i = False\n",
    "        else:\n",
    "            from_oh_i = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_pdos_file_path = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer\"],\n",
    "            \"workflow/dos_analysis\",\n",
    "            \"out_data/pdos_data\",\n",
    "            job_id_pdos_i + \"__df_pdos.pickle\")\n",
    "    \n",
    "            # sahutoho_38__df_pdos.pickle\n",
    "\n",
    "        from pathlib import Path\n",
    "        pdos_files_exist = False\n",
    "        my_file = Path(df_pdos_file_path)\n",
    "        if my_file.is_file():\n",
    "            pdos_files_exist = True\n",
    "\n",
    "        if pdos_files_exist:\n",
    "\n",
    "            # Read dos band centers\n",
    "            df_pdos_i, df_band_centers_i = read_pdos_data(job_id_pdos_i)\n",
    "\n",
    "            df_band_centers_i = df_band_centers_i.set_index(\"atom_num\", drop=False)\n",
    "\n",
    "\n",
    "            # Get the new active site number to use (atoms objects get shuffled around)\n",
    "            # #####################################################\n",
    "            row_atoms_i = df_atoms_sorted_ind.loc[\n",
    "                (\"dos_bader\", compenv_i, slab_id_i, ads_i, active_site_i, att_num_i, )\n",
    "                ]\n",
    "            # #####################################################\n",
    "            atom_index_mapping_i = row_atoms_i.atom_index_mapping\n",
    "            # #####################################################\n",
    "\n",
    "            atom_index_mapping_i = {v: k for k, v in atom_index_mapping_i.items()}\n",
    "\n",
    "            new_active_site_i = atom_index_mapping_i[active_site_i]\n",
    "            new_active_site_i = new_active_site_i + 1\n",
    "\n",
    "            # #####################################################\n",
    "            row_bands_i = df_band_centers_i.loc[new_active_site_i]\n",
    "            # #####################################################\n",
    "            p_band_center_i = row_bands_i.p_tot_band_center\n",
    "            # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # #####################################################\n",
    "            data_dict_i = dict()\n",
    "            # #####################################################\n",
    "            data_dict_i[\"job_id_max\"] = job_id_max_i\n",
    "            data_dict_i[\"from_oh\"] = from_oh_i\n",
    "            data_dict_i[\"active_site\"] = active_site_i\n",
    "            data_dict_i[\"compenv\"] = compenv_i\n",
    "            data_dict_i[\"slab_id\"] = slab_id_i\n",
    "            data_dict_i[\"ads\"] = ads_i\n",
    "            data_dict_i[\"active_site_orig\"] = active_site_orig_i\n",
    "            data_dict_i[\"att_num\"] = att_num_i\n",
    "            data_dict_i[\"p_band_center\"] = p_band_center_i\n",
    "            # #####################################################\n",
    "            data_dict_list.append(data_dict_i)\n",
    "            # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_i = pd.DataFrame(data_dict_list)\n",
    "# #########################################################\n",
    "col_order_list = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\"]\n",
    "df_i = reorder_df_columns(col_order_list, df_i)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df_i.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", \"from_oh\"],\n",
    "    drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_i\n",
    "\n",
    "multi_columns_dict = {\n",
    "    \"features\": [\"p_band_center\", ],\n",
    "    \"data\": [\"from_oh\", \"compenv\", \"slab_id\", \"ads\", \"att_num\", \"active_site\", \"job_id_max\", ],\n",
    "    }\n",
    "\n",
    "nested_columns = dict()\n",
    "for col_header, cols in multi_columns_dict.items():\n",
    "    for col_j in cols:\n",
    "        nested_columns[col_j] = (col_header, col_j)\n",
    "\n",
    "df = df.rename(columns=nested_columns)\n",
    "df.columns = [c if isinstance(c, tuple) else (\"\", c) for c in df.columns]\n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "\n",
    "df_i = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df_i.reindex(columns = [\"data\", \"features\", ], level=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdos_feat = df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "root_path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/feature_engineering/generate_features/pdos_features\")\n",
    "\n",
    "directory = os.path.join(root_path_i, \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "path_i = os.path.join(root_path_i, \"out_data/df_pdos_feat.pickle\")\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_pdos_feat, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_pdos_feat\n",
    "\n",
    "df_pdos_feat_tmp = get_df_pdos_feat()\n",
    "df_pdos_feat_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"pdos_feat.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_i.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df = df_i\n",
    "\n",
    "# df = df[\n",
    "#     (df[(\"data\", \"compenv\")] == \"sherlock\") &\n",
    "#     (df[(\"data\", \"slab_id\")] == \"lufinanu_76\") &\n",
    "#     # (df[\"slab_id\"] == \"lufinanu_76\") &\n",
    "#     # (df[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_i.ads.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # ('sherlock', 'tetuwido_70', 25.0)\n",
    "\n",
    "# df = df_feat_rows\n",
    "# df = df[\n",
    "#     (df[\"compenv\"] == \"sherlock\") &\n",
    "#     (df[\"slab_id\"] == \"tetuwido_70\") &\n",
    "#     (df[\"active_site\"] == 25.) &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_feat_rows = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
