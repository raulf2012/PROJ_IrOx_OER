{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_dft\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import XRDCalculator\n",
    "from local_methods import get_top_xrd_facets\n",
    "from local_methods import compare_facets_for_being_the_same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "# verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = get_df_dft()\n",
    "\n",
    "print(\"df_dft.shape:\", df_dft.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# df_dft = df_dft.sample(n=3)\n",
    "\n",
    "# bulk_id_i = \"64cg6j9any\"\n",
    "# bulk_id_i = \"zwvqnhbk7f\"\n",
    "# bulk_id_i = \"8p8evt9pcg\"\n",
    "bulk_id_i = \"b5cgvsb16w\"\n",
    "\n",
    "# df_dft = df_dft.loc[[bulk_id_i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_xrd\n",
    "df_xrd_old = get_df_xrd()\n",
    "\n",
    "print(\n",
    "    \"Number of rows in df_xrd:\",\n",
    "    df_xrd_old.shape[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_xrd_old.drop_duplicates("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_cnt, (id_unique_i, row_i) in enumerate(df_dft.iterrows()):\n",
    "    data_dict_i = dict()\n",
    "    if verbose:\n",
    "        print(40 * \"=\")\n",
    "        print(str(i_cnt).zfill(3), \"id_unique_i:\", id_unique_i)\n",
    "\n",
    "    # #####################################################\n",
    "    atoms_i = row_i.atoms\n",
    "    atoms_stan_prim_i = row_i.atoms_stan_prim\n",
    "    # #####################################################\n",
    "\n",
    "    from methods import get_df_xrd\n",
    "    df_xrd_old = get_df_xrd()\n",
    "\n",
    "    # if not id_unique_i in df_xrd_old.index:\n",
    "    if id_unique_i in df_xrd_old.index:\n",
    "        if verbose:\n",
    "            print(\"Already computed, skipping\")\n",
    "            \n",
    "    else:\n",
    "        # #####################################################\n",
    "        # df_xrd_i = get_top_xrd_facets(atoms=atoms_stan_prim_i)\n",
    "        xrd_out_dict = get_top_xrd_facets(atoms=atoms_stan_prim_i)\n",
    "\n",
    "        df_xrd_all = xrd_out_dict[\"df_xrd\"]\n",
    "        df_xrd_unique = xrd_out_dict[\"df_xrd_unique\"]\n",
    "\n",
    "        df_xrd_i = df_xrd_unique\n",
    "\n",
    "        # Collect all facets into a list\n",
    "        all_facets = []\n",
    "        for i in df_xrd_all.facets:\n",
    "            all_facets.extend(i)\n",
    "        all_facets = list(set(all_facets))\n",
    "\n",
    "        # df_xrd_i_1 = df_xrd_i[df_xrd_i.y_norm > 30].iloc[0:10]\n",
    "        df_xrd_i_1 = df_xrd_i[df_xrd_i.y_norm > 10].iloc[0:15]\n",
    "\n",
    "        top_facets_i = []\n",
    "        facet_rank_list = []\n",
    "        for i_cnt, i in enumerate(df_xrd_i_1.facets.tolist()):\n",
    "            top_facets_i.extend(i)\n",
    "            rank_list_i = [i_cnt for i in range(len(i))]\n",
    "            # print(rank_list_i)\n",
    "            facet_rank_list.extend(rank_list_i)\n",
    "\n",
    "        # top_facets_i = facets_list\n",
    "\n",
    "        num_top_facets = len(top_facets_i)\n",
    "\n",
    "        if verbose:\n",
    "            tmp = [len(i) for i in top_facets_i]\n",
    "            #print(tmp)\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_i[\"id_unique\"] = id_unique_i\n",
    "        data_dict_i[\"top_facets\"] = top_facets_i\n",
    "        data_dict_i[\"facet_rank\"] = facet_rank_list\n",
    "        data_dict_i[\"num_top_facets\"] = num_top_facets\n",
    "        data_dict_i[\"all_xrd_facets\"] = all_facets\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        # Creating df_xrd with one row and combine it with df_xrd in file\n",
    "        data_dict_list = []\n",
    "        data_dict_list.append(data_dict_i)\n",
    "        df_xrd_row = pd.DataFrame(data_dict_list)\n",
    "        df_xrd_row = df_xrd_row.set_index(\"id_unique\", drop=False)\n",
    "\n",
    "        df_xrd_new = pd.concat([\n",
    "            df_xrd_row,\n",
    "            df_xrd_old,\n",
    "            ], axis=0)\n",
    "\n",
    "        # Pickling data ###################################\n",
    "        import os; import pickle\n",
    "        directory = \"out_data\"\n",
    "        if not os.path.exists(directory): os.makedirs(directory)\n",
    "        with open(os.path.join(directory, \"df_xrd.pickle\"), \"wb\") as fle:\n",
    "            pickle.dump(df_xrd_new, fle)\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# df_xrd = pd.DataFrame(data_dict_list)\n",
    "# df_xrd = df_xrd.set_index(\"id_unique\", drop=False)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_xrd\n",
    "\n",
    "df_xrd_tmp = get_df_xrd()\n",
    "df_xrd_tmp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_xrd_row\n",
    "\n",
    "# df_xrd_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# Saving data to pickle\n",
    "\n",
    "# # Pickling data ###########################################\n",
    "# import os; import pickle\n",
    "# directory = \"out_data\"\n",
    "# if not os.path.exists(directory): os.makedirs(directory)\n",
    "# with open(os.path.join(directory, \"df_xrd.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(df_xrd, fle)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# def compare_facets_for_being_the_same(\n",
    "#     facet_0,\n",
    "#     facet_1,\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     Checks whether facet_0 and facet_1 differ only by an integer multiplicative.\n",
    "#     \"\"\"\n",
    "#     # #########################################################\n",
    "#     facet_j_abs = [np.abs(i) for i in facet_j]\n",
    "#     facet_j_sum = np.sum(facet_j_abs)\n",
    "\n",
    "#     # #########################################################\n",
    "#     facet_k_abs = [np.abs(i) for i in facet_k]\n",
    "#     facet_k_sum = np.sum(facet_k_abs)\n",
    "\n",
    "#     # #########################################################\n",
    "#     if facet_j_sum > facet_k_sum:\n",
    "#         # facet_j_abs / facet_k_abs\n",
    "\n",
    "#         facet_larger = facet_j_abs\n",
    "#         facet_small = facet_k_abs\n",
    "#     else:\n",
    "#         facet_larger = facet_k_abs\n",
    "#         facet_small = facet_j_abs\n",
    "\n",
    "#     # #########################################################\n",
    "#     facet_frac = np.array(facet_larger) / np.array(facet_small)\n",
    "\n",
    "#     something_wrong = False\n",
    "#     all_terms_are_whole_nums = True\n",
    "#     for i_cnt, i in enumerate(facet_frac):\n",
    "#         # print(i.is_integer())\n",
    "#         if np.isnan(i):\n",
    "#             if facet_j_abs[i_cnt] != 0 or facet_k_abs[i_cnt] != 0:\n",
    "#                 something_wrong = True\n",
    "#                 print(\"Not good, these should both be zero\")\n",
    "\n",
    "#         elif not i.is_integer():\n",
    "#             all_terms_are_whole_nums = False\n",
    "#             # print(\"Not a whole number here\")\n",
    "\n",
    "#     duplicate_found = False\n",
    "#     if all_terms_are_whole_nums and not something_wrong:\n",
    "#         duplicate_found = True\n",
    "#         print(\"Found a duplicate facet here\")\n",
    "\n",
    "\n",
    "#     return(duplicate_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # duplicate_facet_found = \\\n",
    "\n",
    "# facet_j = (1, 0, 1)\n",
    "# facet_l = (3, 0, 1)\n",
    "\n",
    "# compare_facets_for_being_the_same(facet_j, facet_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# facet_0 = (1, 0, 1)\n",
    "# facet_1 = (3, 0, 1)\n",
    "\n",
    "# # def compare_facets_for_being_the_same(\n",
    "# #     facet_0,\n",
    "# #     facet_1,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "# Checks whether facet_0 and facet_1 differ only by an integer multiplicative.\n",
    "# \"\"\"\n",
    "# #| - compare_facets_for_being_the_same\n",
    "# # #########################################################\n",
    "# facet_j = facet_0\n",
    "# facet_k = facet_1\n",
    "\n",
    "# # #########################################################\n",
    "# facet_j_abs = [np.abs(i) for i in facet_j]\n",
    "# facet_j_sum = np.sum(facet_j_abs)\n",
    "\n",
    "# # #########################################################\n",
    "# facet_k_abs = [np.abs(i) for i in facet_k]\n",
    "# facet_k_sum = np.sum(facet_k_abs)\n",
    "\n",
    "# # #########################################################\n",
    "# if facet_j_sum > facet_k_sum:\n",
    "#     # facet_j_abs / facet_k_abs\n",
    "\n",
    "#     facet_larger = facet_j_abs\n",
    "#     facet_small = facet_k_abs\n",
    "# else:\n",
    "#     facet_larger = facet_k_abs\n",
    "#     facet_small = facet_j_abs\n",
    "\n",
    "# # #########################################################\n",
    "# facet_frac = np.array(facet_larger) / np.array(facet_small)\n",
    "\n",
    "# # #####################################################\n",
    "# something_wrong = False\n",
    "# all_terms_are_whole_nums = True\n",
    "# # #####################################################\n",
    "# div_ints =  []\n",
    "# # #####################################################\n",
    "# for i_cnt, i in enumerate(facet_frac):\n",
    "#     # print(i.is_integer())\n",
    "#     if np.isnan(i):\n",
    "#         if facet_j_abs[i_cnt] != 0 or facet_k_abs[i_cnt] != 0:\n",
    "#             something_wrong = True\n",
    "#             print(\"Not good, these should both be zero\")\n",
    "\n",
    "#     elif not i.is_integer() or i == 0:\n",
    "#         all_terms_are_whole_nums = False\n",
    "#         # print(\"Not a whole number here\")\n",
    "\n",
    "#     elif i.is_integer():\n",
    "#         div_ints.append(int(i))\n",
    "\n",
    "# all_int_factors_are_same = False\n",
    "# if len(list(set(div_ints))) == 1:\n",
    "#     all_int_factors_are_same = True\n",
    "\n",
    "# duplicate_found = False\n",
    "# if all_terms_are_whole_nums and not something_wrong and all_int_factors_are_same:\n",
    "#     duplicate_found = True\n",
    "#     # print(\"Found a duplicate facet here\")\n",
    "\n",
    "# # return(duplicate_found)\n",
    "# #__|\n",
    "\n",
    "\n",
    "# print(\"duplicate_found:\", duplicate_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# facet_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# all_terms_are_whole_nums\n",
    "# something_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# indices_to_drop = []\n",
    "# # #########################################################\n",
    "# for ind_i, row_i in df_xrd_unique.iterrows():\n",
    "\n",
    "#     # #####################################################\n",
    "#     facets_i = row_i.facets\n",
    "#     # #####################################################\n",
    "\n",
    "#     for facet_j in facets_i:\n",
    "\n",
    "#         for ind_k, row_k in df_xrd_unique.iterrows():\n",
    "\n",
    "#             # #############################################\n",
    "#             facets_k = row_k.facets\n",
    "#             # #############################################\n",
    "\n",
    "#             for facet_l in facets_k:\n",
    "\n",
    "#                 if facet_j == facet_l:\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     duplicate_facet_found = \\\n",
    "#                         compare_facets_for_being_the_same(facet_j, facet_l)\n",
    "\n",
    "#                     if duplicate_facet_found:\n",
    "#                         # print(duplicate_facet_found, facet_j, facet_l)\n",
    "\n",
    "#                         if np.sum(np.abs(facet_j)) > np.sum(np.abs(facet_l)):\n",
    "#                             indices_to_drop.append(ind_i)\n",
    "#                             # print(ind_i)\n",
    "#                         else:\n",
    "#                             indices_to_drop.append(ind_k)\n",
    "#                             # print(ind_k)\n",
    "\n",
    "# # #########################################################\n",
    "# indices_to_drop = list(set(indices_to_drop))\n",
    "# # #########################################################\n",
    "\n",
    "# df_xrd_unique_1 = df_xrd_unique.drop(index=indices_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_xrd_i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# top_facets_i = []\n",
    "# facet_rank_list = []\n",
    "# for i_cnt, i in enumerate(df_xrd_i_1.facets.tolist()):\n",
    "#     top_facets_i.extend(i)\n",
    "#     rank_list_i = [i_cnt for i in range(len(i))]\n",
    "#     print(rank_list_i)\n",
    "#     facet_rank_list.extend(rank_list_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_xrd_i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# facet_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_xrd\n",
    "\n",
    "# df_xrd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# [0, 10, 22, 29, 30]\n",
    "# [10, 29, 22, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_xrd_unique = df_xrd_unique.loc[[2, 19]]\n",
    "# df_xrd_unique = df_xrd_unique.loc[[2, 22]]\n",
    "\n",
    "# xrd_out_dict\n",
    "\n",
    "# df_xrd_unique"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
