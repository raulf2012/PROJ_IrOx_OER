{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OER Analysis Notebook\n",
    "---\n",
    "\n",
    "* Compute overpotential for all systems\n",
    "* Save ORR_PLT instance for OXR plotting classes\n",
    "* Save df_overpot dataframe to combine with df_features_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/oer_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "# #########################################################\n",
    "# Python Modules\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "# My Modules\n",
    "from oxr_reaction.oxr_rxn import ORR_Free_E_Plot\n",
    "\n",
    "from methods import (\n",
    "    get_df_ads,\n",
    "    get_df_job_ids,\n",
    "    get_df_dft,\n",
    "    get_df_features_targets,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_dft = get_df_dft()\n",
    "\n",
    "# #########################################################\n",
    "df_job_ids = get_df_job_ids()\n",
    "\n",
    "# #########################################################\n",
    "df_features_targets = get_df_features_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in size of df_features from dropping non-complete rows:\n",
      "366\n",
      "366\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(\n",
    "        \"Change in size of df_features from dropping non-complete rows:\"\n",
    "\n",
    "        \"\\n\",\n",
    "        df_features_targets.shape[0],\n",
    "        sep=\"\")\n",
    "\n",
    "# Only passing through OER sets that are 100% done will all calculations\n",
    "# if True:\n",
    "if False:\n",
    "    df_features_targets = df_features_targets[df_features_targets[\"data\"][\"all_done\"] == True]\n",
    "\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        df_features_targets.shape[0],\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_format_dict = [\n",
    "    [{\"stoich\": \"AB2\"}, {\"color2\": \"black\"}],\n",
    "    [{\"stoich\": \"AB3\"}, {\"color2\": \"grey\"}],\n",
    "    ]\n",
    "\n",
    "ORR_PLT = ORR_Free_E_Plot(\n",
    "    free_energy_df=None,\n",
    "    state_title=\"ads\",\n",
    "    free_e_title=\"ads_g\",\n",
    "    smart_format=smart_format_dict,\n",
    "    color_list=None,\n",
    "    rxn_type=\"OER\")\n",
    "\n",
    "\n",
    "# new_col = (df_features_targets[\"targets\"][\"g_oh\"] + 2.8)\n",
    "new_col = (1.16 * df_features_targets[\"targets\"][\"g_oh\"] + 2.8)\n",
    "\n",
    "new_col.name = (\"targets\", \"g_ooh\", \"\", )\n",
    "\n",
    "df_features_targets = pd.concat([\n",
    "    new_col,\n",
    "    df_features_targets,\n",
    "    ], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Loop through data and add to ORR_PLT\n",
    "data_dict_list_0 = []\n",
    "for name_i, row_i in df_features_targets.iterrows():\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    g_o_i = row_i[(\"targets\", \"g_o\", \"\", )]\n",
    "    g_oh_i = row_i[(\"targets\", \"g_oh\", \"\", )]\n",
    "    g_ooh_i = row_i[(\"targets\", \"g_ooh\", \"\", )]\n",
    "    slab_id_i = row_i[(\"data\", \"slab_id\", \"\")]\n",
    "    active_site_i = row_i[(\"data\", \"active_site\", \"\")]\n",
    "    job_id_o_i = row_i[(\"data\", \"job_id_o\", \"\")]\n",
    "    job_id_oh_i = row_i[(\"data\", \"job_id_oh\", \"\")]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_job_ids_i = df_job_ids[df_job_ids.slab_id == slab_id_i]\n",
    "\n",
    "    bulk_ids = df_job_ids_i.bulk_id.unique()\n",
    "\n",
    "    mess_i = \"SIJFIDSIFJIDSJIf\"\n",
    "    assert len(bulk_ids) == 1, mess_i\n",
    "\n",
    "    bulk_id_i = bulk_ids[0]\n",
    "\n",
    "    # #########################################################\n",
    "    row_dft_i = df_dft.loc[bulk_id_i]\n",
    "    # #########################################################\n",
    "    stoich_i = row_dft_i.stoich\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    data_dict_list =  [\n",
    "        {\"ads_g\": g_o_i, \"ads\": \"o\", },\n",
    "        {\"ads_g\": g_oh_i, \"ads\": \"oh\", },\n",
    "        {\"ads_g\": g_ooh_i, \"ads\": \"ooh\", },\n",
    "        {\"ads_g\": 0., \"ads\": \"bulk\", },\n",
    "        ]\n",
    "    df_i = pd.DataFrame(data_dict_list)\n",
    "\n",
    "    df_i[\"stoich\"] = stoich_i\n",
    "\n",
    "\n",
    "    prop_name_list = [\n",
    "        \"stoich\",\n",
    "        ]\n",
    "\n",
    "    # #########################################################\n",
    "    # name_i = \"IDSJFISDf\"\n",
    "    name_i_2 = slab_id_i + \"__\" + str(int(active_site_i))\n",
    "    ORR_PLT.add_series(\n",
    "        df_i,\n",
    "        plot_mode=\"all\",\n",
    "        overpotential_type=\"OER\",\n",
    "        property_key_list=prop_name_list,\n",
    "        add_overpot=False,\n",
    "        name_i= name_i_2,\n",
    "        )\n",
    "\n",
    "    # #################################################\n",
    "    data_dict_i = dict()\n",
    "    # #################################################\n",
    "    data_dict_i[\"name\"] = name_i_2\n",
    "    data_dict_i[\"compenv\"] = name_i[0]\n",
    "    data_dict_i[\"slab_id\"] = name_i[1]\n",
    "    data_dict_i[\"active_site\"] = name_i[2]\n",
    "    # #################################################\n",
    "    data_dict_list_0.append(data_dict_i)\n",
    "    # #################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_dict_list_0)\n",
    "df = df.set_index(\"name\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for OXR_Series_i in ORR_PLT.series_list:\n",
    "\n",
    "    name_i = OXR_Series_i.name_i\n",
    "\n",
    "    # #####################################################\n",
    "    overpot_out = OXR_Series_i.calc_overpotential_OER()\n",
    "    # #####################################################\n",
    "    overpot_i = overpot_out[0]\n",
    "    lim_step_i = overpot_out[1]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    if lim_step_i == [\"bulk\", \"oh\"]:\n",
    "        lim_step_str_i = \"bulk__oh\"\n",
    "        lim_step_num = 1\n",
    "    elif lim_step_i == [\"oh\", \"o\"]:\n",
    "        lim_step_str_i = \"oh__o\"\n",
    "        lim_step_num = 2\n",
    "    elif lim_step_i == [\"o\", \"ooh\"]:\n",
    "        lim_step_str_i = \"o__ooh\"\n",
    "        lim_step_num = 3\n",
    "    elif lim_step_i == [\"ooh\", \"bulk\"]:\n",
    "        lim_step_str_i = \"ooh__bulk\"\n",
    "        lim_step_num = 4\n",
    "\n",
    "    else:\n",
    "        print(\"WOOOOOPS\")\n",
    "        print(lim_step_i)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    data_dict_i[\"name\"] = name_i\n",
    "    data_dict_i[\"overpot\"] = overpot_i\n",
    "    data_dict_i[\"lim_step\"] = lim_step_i\n",
    "    data_dict_i[\"lim_step_str\"] = lim_step_str_i\n",
    "    data_dict_i[\"lim_step_num\"] = lim_step_num\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "df_overpot = pd.DataFrame(data_dict_list)\n",
    "df_overpot = df_overpot.set_index(\"name\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overpot = pd.concat([df, df_overpot], axis=1)\n",
    "\n",
    "df_overpot = df_overpot.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/oer_analysis\",\n",
    "    \"out_data\")\n",
    "\n",
    "# Pickling data ###########################################\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_overpot.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_overpot, fle)\n",
    "# #########################################################\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"ORR_PLT.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(ORR_PLT, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.139 min\n",
      "oer_analysis.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"oer_analysis.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
