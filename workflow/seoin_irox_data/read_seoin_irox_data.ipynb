{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing IrOx Data from Seoin\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ase import Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Seoin\n",
    "oxy_ref = -7.4484\n",
    "hyd_ref = -3.3851\n",
    "\n",
    "# # Mine\n",
    "# oxy_ref = -7.45942759\n",
    "# hyd_ref = -3.38574595\n",
    "\n",
    "# MISC\n",
    "# # oxy_ref = -7.459\n",
    "# oxy_ref = -7.463\n",
    "# hyd_ref = -3.38574595\n",
    "\n",
    "# oxy_ref = -7.469\n",
    "# hyd_ref = -3.38574595\n",
    "\n",
    "# oxy_ref = -7.489\n",
    "# hyd_ref = -3.38574595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Seoin\n",
    "oxy_ref = -7.4484\n",
    "# hyd_ref = -3.3851\n",
    "# hyd_ref = -3.395\n",
    "# hyd_ref = -3.405\n",
    "# hyd_ref = -3.415\n",
    "# hyd_ref = -3.43\n",
    "hyd_ref = -3.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-3.3851 - -3.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From Seoin\n",
    "# G_corr_o = 0.05\n",
    "# G_corr_oh = 0.34\n",
    "# G_corr_ooh = 0.37\n",
    "\n",
    "# G_corr_h2 = -0.04\n",
    "# G_corr_h2o = 0.0\n",
    "\n",
    "\n",
    "# Mine\n",
    "G_corr_o = 0.081\n",
    "G_corr_oh = 0.307\n",
    "G_corr_ooh = 0.426\n",
    "\n",
    "G_corr_h2 = -0.049\n",
    "G_corr_h2o = -0.012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_corr_o_tot = G_corr_o - (G_corr_h2o - G_corr_h2)\n",
    "G_corr_oh_tot = G_corr_oh - (G_corr_h2o - 0.5 * G_corr_h2)\n",
    "G_corr_ooh_tot = G_corr_ooh - (2 * G_corr_h2o - 1.5 * G_corr_h2)\n",
    "\n",
    "print(\n",
    "    \"G_corr_o_tot: \",\n",
    "    G_corr_o_tot,\n",
    "    \"\\n\",\n",
    "\n",
    "    \"G_corr_oh_tot: \",\n",
    "    G_corr_oh_tot,\n",
    "    \"\\n\",\n",
    "\n",
    "    \"G_corr_ooh_tot: \",\n",
    "    G_corr_ooh_tot,\n",
    "    \"\\n\",\n",
    "\n",
    "    sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_corr_o_tot: 0.010000000000000002\n",
    "# G_corr_oh_tot: 0.32\n",
    "# G_corr_ooh_tot: 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_corr_o_tot: 0.044\n",
    "# G_corr_oh_tot: 0.2945\n",
    "# G_corr_ooh_tot: 0.3765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/seoin_irox_data\",\n",
    "    \"in_data/oer.pkl\")\n",
    "with open(path_i, 'rb') as f:\n",
    "     oer_data = pickle.load(f) \n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/seoin_irox_data\",\n",
    "    \"in_data/all_info.csv\")\n",
    "df_oer = pd.read_csv(path_i, dtype={\"facet\": object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/seoin_irox_data\",\n",
    "    \"manually_id_active_site.csv\")\n",
    "df_active_sites = pd.read_csv(path_i,\n",
    "    dtype={\"facet\": object},\n",
    "    )\n",
    "\n",
    "df_active_sites = df_active_sites.set_index(\n",
    "    [\"crystal\", \"facet\", \"coverage\", \"termination\", \"active_site\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(222 * \"TEMP | \")\n",
    "\n",
    "# df_oer = df_oer.loc[\n",
    "\n",
    "#     # [\n",
    "#     #     # 3,\n",
    "#     #     32,\n",
    "#     #   ]\n",
    "\n",
    "#     # #####################################################\n",
    "\n",
    "#     # [\n",
    "#     #     3, 150, 178, 186, 211, 212,\n",
    "#     #     351, 368, 382, 443, 461, 506,\n",
    "#     #     524, 533, 534, 618, 624, 664,\n",
    "#     #     702, 710, 722, 789, 859, 901,\n",
    "#     #     913, 939, 971, 975, 991, 992,\n",
    "#     #     993, 1001, 1016, 1021, 1037, 1055,\n",
    "#     #     1061, 1065, 1083,\n",
    "#     #     ]\n",
    "\n",
    "#     # #####################################################\n",
    "\n",
    "#     # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "#     # [\n",
    "#     #     887, 889, 898, 899, 900,\n",
    "#     #     914, 925, 926, 932, 933,\n",
    "#     #     937, 947, 948, 949, 957,\n",
    "#     #     958, 959, 961, 973, 974,\n",
    "#     #     975, 983, 984,\n",
    "#     #     ]\n",
    "\n",
    "#     [961, 973, 974, 975, 983, 984, 963],\n",
    "\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `df_oer`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oer = df_oer.rename(\n",
    "    columns={\n",
    "        \"termination\": \"termination_str\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "\n",
    "    # #####################################################\n",
    "    new_column_values_dict = {\n",
    "        \"ads\": None,\n",
    "        }\n",
    "    # #####################################################\n",
    "    name_i = row_i[\"name\"]\n",
    "    energy_i = row_i[\"energy\"]\n",
    "    location_i = row_i[\"location\"]\n",
    "    termination_str_i = row_i[\"termination_str\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Parse termination text\n",
    "    if \"O_covered\" in termination_str_i:\n",
    "        coverage_type_i = \"O_covered\"\n",
    "    if \"OH_covered\" in termination_str_i:\n",
    "        coverage_type_i = \"OH_covered\"\n",
    "\n",
    "    # row_i = df_oer.iloc[0]\n",
    "    # termination_str_i = row_i.termination_str\n",
    "\n",
    "    termination_int_i = None\n",
    "    for i in termination_str_i.split(\"_\"):\n",
    "        try:\n",
    "            int_i = int(i)\n",
    "            termination_int_i = int_i\n",
    "            break\n",
    "        except:\n",
    "            tmp = 42\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Short location\n",
    "    loc_short_i = location_i[56:]\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Parsing adsorbate species\n",
    "    is_bare = any([i == \"Bare\" for i in name_i.split(\"_\")])\n",
    "    is_O = any([i == \"O\" for i in name_i.split(\"_\")])\n",
    "    is_OH = any([i == \"OH\" for i in name_i.split(\"_\")])\n",
    "    is_OOH = any([i == \"OOH\" for i in name_i.split(\"_\")])\n",
    "\n",
    "    if is_bare:\n",
    "        ads_i = \"bare\"\n",
    "    elif is_O:\n",
    "        ads_i = \"o\"\n",
    "    elif is_OH:\n",
    "        ads_i = \"oh\"\n",
    "    elif is_OOH:\n",
    "        ads_i = \"ooh\"\n",
    "    else:\n",
    "        ads_i = None\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Getting OER data from sorted dict object\n",
    "    num_matches = 0\n",
    "    oer_ind_i = None\n",
    "    \n",
    "    # print(20 * \"-\")\n",
    "    # print(energy_i)\n",
    "\n",
    "    for oer_ind_j, oer_data_j in enumerate(oer_data):\n",
    "        energy_j = oer_data_j[\"results\"][\"energy\"]\n",
    "\n",
    "        is_close = np.isclose(\n",
    "            energy_i, energy_j,\n",
    "            # rtol=1e-05,\n",
    "            # atol=1e-08,\n",
    "\n",
    "            rtol=1e-09,\n",
    "            atol=1e-09,\n",
    "            )\n",
    "        if is_close:\n",
    "            # print(energy_j)\n",
    "\n",
    "            num_matches += 1\n",
    "            oer_ind_i = oer_ind_j\n",
    "\n",
    "    if num_matches > 1:\n",
    "        # print(row_i.name)\n",
    "        assert False\n",
    "\n",
    "    # #####################################################\n",
    "    oer_data_i = oer_data[oer_ind_i]\n",
    "    # #####################################################\n",
    "    atoms_i = oer_data_i[\"atoms\"]\n",
    "    calc = oer_data_i[\"calc\"]\n",
    "    results = oer_data_i[\"results\"]\n",
    "    # #####################################################\n",
    "    initial_configuration = oer_data_i[\"initial_configuration\"]\n",
    "    # #####################################################\n",
    "    atoms_init_i = initial_configuration[\"atoms\"]\n",
    "    # results_init_i = initial_configuration[\"results\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    symbol_counts_i = atoms_i[\"symbol_counts\"]\n",
    "\n",
    "    O_Ir_frac_i = symbol_counts_i[\"O\"] / symbol_counts_i[\"Ir\"]\n",
    "    # print(O_Ir_frac_i, \",\", sep=\"\")\n",
    "\n",
    "        \n",
    "    # #####################################################\n",
    "    symbols_list = []\n",
    "    positions_list = []\n",
    "    for atom_i in atoms_i[\"atoms\"]:\n",
    "        symbols_list.append(atom_i[\"symbol\"])\n",
    "        positions_list.append(atom_i[\"position\"])\n",
    "\n",
    "\n",
    "    atoms_i_2 = Atoms(\n",
    "        symbols=symbols_list,\n",
    "        positions=positions_list,\n",
    "\n",
    "        cell=atoms_i[\"cell\"],\n",
    "        pbc=atoms_i[\"pbc\"],\n",
    "        constraint=atoms_i[\"constraints\"],\n",
    "\n",
    "        # numbers=None,\n",
    "        # tags=None,\n",
    "        # momenta=None,\n",
    "        # masses=None,\n",
    "        # magmoms=None,\n",
    "        # charges=None,\n",
    "        # scaled_positions=None,\n",
    "\n",
    "        # celldisp=None,\n",
    "\n",
    "        # calculator=None,\n",
    "        # info=None,\n",
    "        # velocities=None,\n",
    "        )\n",
    "\n",
    "    # #####################################################\n",
    "    symbols_list = []\n",
    "    positions_list = []\n",
    "    for atom_i in atoms_init_i[\"atoms\"]:\n",
    "        symbols_list.append(atom_i[\"symbol\"])\n",
    "        positions_list.append(atom_i[\"position\"])\n",
    "\n",
    "\n",
    "    atoms_init_i_2 = Atoms(\n",
    "        symbols=symbols_list,\n",
    "        positions=positions_list,\n",
    "\n",
    "        cell=atoms_init_i[\"cell\"],\n",
    "        pbc=atoms_init_i[\"pbc\"],\n",
    "        constraint=atoms_init_i[\"constraints\"],\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Getting active site and attempt number\n",
    "    name_split_i = name_i.split(\"_\")\n",
    "\n",
    "    # if name_split_i[0] == \"OH\":\n",
    "    if \"OH\" in name_split_i:\n",
    "        # doubled_OH_covered_0_0\n",
    "        active_site_i = name_split_i[-2]\n",
    "        attempt_i = name_split_i[-1]\n",
    "\n",
    "    elif name_split_i[0] == \"OOH\":\n",
    "        active_site_i = name_split_i[1]\n",
    "        attempt_i = name_split_i[2]\n",
    "\n",
    "    elif name_split_i[0] == \"Bare\":\n",
    "        active_site_i = name_split_i[1]\n",
    "        if len(name_split_i) == 2:\n",
    "            attempt_i = 0\n",
    "        else:\n",
    "            print(\"Check this out\")\n",
    "\n",
    "    # elif name_split_i[0] == \"O\":\n",
    "    # name_split_i[0] == \"O\":\n",
    "    elif \"O\" in name_split_i:\n",
    "        active_site_i = name_split_i[-1]\n",
    "        attempt_i = 0\n",
    "\n",
    "    else:\n",
    "        print(name_i)\n",
    "        print(\"Wooooooooops\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    new_column_values_dict[\"ads\"] = ads_i\n",
    "    new_column_values_dict[\"oer_ind\"] = oer_ind_i\n",
    "    new_column_values_dict[\"atoms\"] = atoms_i_2\n",
    "    new_column_values_dict[\"atoms_init\"] = atoms_init_i_2\n",
    "    new_column_values_dict[\"loc_short\"] = loc_short_i\n",
    "    new_column_values_dict[\"active_site\"] = int(active_site_i)\n",
    "    new_column_values_dict[\"attempt\"] = attempt_i\n",
    "    new_column_values_dict[\"coverage_type\"] = coverage_type_i\n",
    "    new_column_values_dict[\"termination\"] = termination_int_i\n",
    "    new_column_values_dict[\"O_Ir_frac\"] = O_Ir_frac_i\n",
    "    # #####################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    # #####################################################\n",
    "    return(row_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_oer = df_oer.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over OER sets, preparing adsorption energies"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing *OH covered slabs\n",
    "# It was messing up the code below, and I don't really need these calculations\n",
    "\n",
    "# df_oer = df_oer[df_oer.coverage_type != \"OH_covered\"]\n",
    "\n",
    "\n",
    "\n",
    "df_oer_wo_O = df_oer[df_oer.ads != \"o\"]\n",
    "\n",
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "group_cols = [\"crystal\", \"facet\", \"termination_str\", \"termination\", \"coverage_type\", \"active_site\", ]\n",
    "grouped = df_oer_wo_O.groupby(group_cols)\n",
    "# #########################################################\n",
    "for name, group in grouped:\n",
    "\n",
    "# for i in range(1):\n",
    "#     name = ('columbite', '120', 'O_covered_1_OER', 1, 'O_covered', 3)\n",
    "#     group = grouped.get_group(name)\n",
    "\n",
    "    # #####################################################\n",
    "    crystal_i = name[0]\n",
    "    facet_i = name[1]\n",
    "    termination_str_i = name[2]\n",
    "    termination_i = name[3]\n",
    "    coverage_type_i = name[4]\n",
    "    active_site_i = name[5]\n",
    "    # #####################################################\n",
    "\n",
    "    O_Ir_frac_ave_i = group[\"O_Ir_frac\"].mean()\n",
    "\n",
    "    if O_Ir_frac_ave_i < 3:\n",
    "        bulk_oxid_state_i = 4\n",
    "        stoich_i = \"AB2\"\n",
    "    else:\n",
    "        bulk_oxid_state_i = 6\n",
    "        stoich_i = \"AB3\"\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    oh_present_i = \"oh\" in group.ads.unique().tolist()\n",
    "    ooh_present_i = \"ooh\" in group.ads.unique().tolist()\n",
    "    bare_present_i = \"bare\" in group.ads.unique().tolist()\n",
    "    # #####################################################\n",
    "    all_ads_present = np.all([oh_present_i, ooh_present_i, bare_present_i])\n",
    "    # #####################################################\n",
    "\n",
    "    if all_ads_present:\n",
    "\n",
    "        # #####################################################\n",
    "        df = group\n",
    "        df = df[\n",
    "            (df[\"ads\"] == \"oh\") &\n",
    "            [True for i in range(len(df))]\n",
    "            ]\n",
    "        group_oh = df\n",
    "\n",
    "        row_oh_i = group_oh.sort_values(\"energy\").iloc[[0]]\n",
    "\n",
    "        # #####################################################\n",
    "        df = group\n",
    "        df = df[\n",
    "            (df[\"ads\"] == \"ooh\") &\n",
    "            [True for i in range(len(df))]\n",
    "            ]\n",
    "        group_ooh = df\n",
    "\n",
    "        row_ooh_i = group_ooh.sort_values(\"energy\").iloc[[0]]\n",
    "\n",
    "        # #####################################################\n",
    "        df = group\n",
    "        df = df[\n",
    "            (df[\"ads\"] == \"bare\") &\n",
    "            [True for i in range(len(df))]\n",
    "            ]\n",
    "        group_bare = df\n",
    "\n",
    "        row_bare_i = group_bare.sort_values(\"energy\").iloc[[0]]\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        df = df_oer\n",
    "        df = df[\n",
    "            (df[\"termination\"] == termination_i) &\n",
    "            (df[\"ads\"] == \"o\") &\n",
    "            (df[\"crystal\"] == crystal_i) &\n",
    "            (df[\"facet\"] == facet_i) &\n",
    "            [True for i in range(len(df))]\n",
    "            ]\n",
    "        group_o = df\n",
    "\n",
    "        if group_o.shape[0] > 1:\n",
    "            print(\"There are various *O slabs, doesn't seem right\")\n",
    "            print(\n",
    "                '\"crystal\", \"facet\", \"termination_str\", \"termination\", \"coverage_type\", \"active_site\",'\n",
    "                )\n",
    "            print(name)\n",
    "\n",
    "        row_o_i = group_o.sort_values(\"energy\").iloc[[0]]\n",
    "\n",
    "        assert row_o_i.shape[0] == 1, \"ISDFIJDSIJfi\"\n",
    "\n",
    "\n",
    "        # Adsorbate indices for df_eor\n",
    "        bare_index_i = row_bare_i.index.tolist()[0]\n",
    "        oh_index_i = row_oh_i.index.tolist()[0]\n",
    "        ooh_index_i = row_ooh_i.index.tolist()[0]\n",
    "        o_index_i = row_o_i.index.tolist()[0]\n",
    "\n",
    "        # #####################################################\n",
    "        df_oer_set_i = pd.concat([\n",
    "            row_bare_i,\n",
    "            row_oh_i,\n",
    "            row_ooh_i,\n",
    "            row_o_i,\n",
    "            ], axis=0)\n",
    "\n",
    "        energy_o_i = df_oer_set_i[df_oer_set_i.ads == \"o\"].iloc[0].energy\n",
    "        energy_oh_i = df_oer_set_i[df_oer_set_i.ads == \"oh\"].iloc[0].energy\n",
    "        energy_ooh_i = df_oer_set_i[df_oer_set_i.ads == \"ooh\"].iloc[0].energy\n",
    "        energy_bare_i = df_oer_set_i[df_oer_set_i.ads == \"bare\"].iloc[0].energy\n",
    "\n",
    "        dE_O = energy_o_i - energy_bare_i - oxy_ref\n",
    "        dE_OH = energy_oh_i - energy_bare_i - oxy_ref - hyd_ref\n",
    "        dE_OOH = energy_ooh_i - energy_bare_i - 2 * oxy_ref - hyd_ref\n",
    "\n",
    "        dG_O = dE_O + G_corr_o_tot\n",
    "        dG_OH = dE_OH + G_corr_oh_tot\n",
    "        dG_OOH = dE_OOH + G_corr_ooh_tot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_i = dict()\n",
    "        # #################################################\n",
    "        data_dict_i[\"stoich\"] = stoich_i\n",
    "        data_dict_i[\"crystal\"] = crystal_i\n",
    "        data_dict_i[\"facet\"] = facet_i\n",
    "        data_dict_i[\"termination\"] = termination_i\n",
    "        data_dict_i[\"active_site\"] = active_site_i\n",
    "        data_dict_i[\"coverage\"] = coverage_type_i\n",
    "        data_dict_i[\"active_site\"] = active_site_i\n",
    "        data_dict_i[\"e_o\"] = dE_O\n",
    "        data_dict_i[\"e_oh\"] = dE_OH\n",
    "        data_dict_i[\"e_ooh\"] = dE_OOH\n",
    "        data_dict_i[\"g_o\"] = dG_O\n",
    "        data_dict_i[\"g_oh\"] = dG_OH\n",
    "        data_dict_i[\"g_ooh\"] = dG_OOH\n",
    "        data_dict_i[\"index_bare\"] = bare_index_i\n",
    "        data_dict_i[\"index_o\"] = o_index_i\n",
    "        data_dict_i[\"index_oh\"] = oh_index_i\n",
    "        data_dict_i[\"index_ooh\"] = ooh_index_i\n",
    "        data_dict_i[\"O_Ir_frac_ave\"] = O_Ir_frac_ave_i\n",
    "        data_dict_i[\"bulk_oxid_state\"] = bulk_oxid_state_i\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_i)\n",
    "        # #################################################\n",
    "\n",
    "# #########################################################\n",
    "df_ads_e = pd.DataFrame(data_dict_list)\n",
    "\n",
    "df_ads_e = df_ads_e.set_index(\n",
    "    [\"crystal\", \"facet\", \"coverage\", \"termination\", \"active_site\", ]\n",
    "    )\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oer_data[8].keys()\n",
    "# # oer_data[8][\"calc\"]\n",
    "# oer_data[8][\"atoms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write atoms to file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for name_i, row_i in df_ads_e.iterrows():\n",
    "\n",
    "        atoms_bare_i = df_oer.loc[row_i.index_bare].atoms\n",
    "        atoms_o_i = df_oer.loc[row_i.index_o].atoms\n",
    "        atoms_oh_i = df_oer.loc[row_i.index_oh].atoms\n",
    "        atoms_ooh_i = df_oer.loc[row_i.index_ooh].atoms\n",
    "\n",
    "\n",
    "        dir_name = \"_\".join([str(i) for i in list(name_i)])\n",
    "        # print(\"'\" + name_i[1], sep=\"\")\n",
    "        # print(name_i[1], sep=\"\")\n",
    "\n",
    "        # print(name_i[4], sep=\"\")\n",
    "\n",
    "        dir_i = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer\"],\n",
    "            \"workflow/seoin_irox_data\",\n",
    "            \"out_data/oer_sets\",\n",
    "            dir_name)\n",
    "        if not os.path.exists(dir_i):\n",
    "            os.makedirs(dir_i)\n",
    "\n",
    "        atoms_bare_i.write(os.path.join(dir_i, \"atoms_bare.traj\"))\n",
    "        atoms_o_i.write(os.path.join(dir_i, \"atoms_o.traj\"))\n",
    "        atoms_oh_i.write(os.path.join(dir_i, \"atoms_oh.traj\"))\n",
    "        atoms_ooh_i.write(os.path.join(dir_i, \"atoms_ooh.traj\"))\n",
    "\n",
    "        # atoms_init_j.write(os.path.join(dir_i, \"atoms_init.traj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads_e_2 = pd.concat([\n",
    "    df_ads_e,\n",
    "    df_active_sites,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting data to file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/seoin_irox_data\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "\n",
    "with open(os.path.join(directory, \"df_ads_e.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_ads_e_2, fle)\n",
    "\n",
    "with open(os.path.join(directory, \"df_oer.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_oer, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ads_e_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write atoms to file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j_ind, row_j in group.iterrows():\n",
    "    # #################################################\n",
    "    loc_short_j = row_j.loc_short\n",
    "    atoms_j = row_j.atoms\n",
    "    atoms_init_j = row_j.atoms_init\n",
    "    # #################################################\n",
    "\n",
    "    dir_i = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/seoin_irox_data\",\n",
    "        \"out_data\",\n",
    "        loc_short_j,\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(dir_i):\n",
    "        os.makedirs(dir_i)\n",
    "\n",
    "    atoms_j.write(os.path.join(dir_i, \"atoms.traj\"))\n",
    "    atoms_init_j.write(os.path.join(dir_i, \"atoms_init.traj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# df = px.data.tips()\n",
    "# fig = px.histogram(\n",
    "#     df_ads_e_2,\n",
    "#     x=\"O_Ir_frac_ave\",\n",
    "#     nbins=100,\n",
    "#     )\n",
    "\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
