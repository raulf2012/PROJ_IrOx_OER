{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further process slabs created in `create_slabs.ipynb`\n",
    "---\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "# from pathlib import Path\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# #########################################################\n",
    "from plotting.my_plotly import my_plotly_plot\n",
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_structure_coord_df\n",
    "from methods import (\n",
    "    get_df_dft,\n",
    "    get_slab_thickness,\n",
    "    get_df_slab,\n",
    "    )\n",
    "\n",
    "from local_methods import (\n",
    "    constrain_slab,\n",
    "    resize_z_slab,\n",
    "    calc_surface_area,\n",
    "    repeat_xy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `df_slab` and `df_dft` dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = get_df_slab(mode=\"almost-final\")\n",
    "\n",
    "df_dft = get_df_dft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"status\" in df_slab.columns:\n",
    "    df_slab = df_slab[df_slab.status != \"Took too long\"]\n",
    "else:\n",
    "    print(\"eh\")\n",
    "    df_slab = df_slab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directories"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs\")\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/final_slabs_1\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/final_slabs_2\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/bulk_structures_temp\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main processing slabs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "iterator = tqdm(df_slab.index.tolist(), desc=\"1st loop\")\n",
    "for i_cnt, slab_id_i in enumerate(iterator):\n",
    "    row_i = df_slab.loc[slab_id_i]\n",
    "\n",
    "    # if i_cnt > 100:\n",
    "    #     break\n",
    "\n",
    "    data_dict_i = dict()\n",
    "    t0 = time.time()\n",
    "\n",
    "    # #####################################################\n",
    "    slab_id = row_i.name\n",
    "    slab = row_i.slab_final\n",
    "    bulk_id_i = row_i.bulk_id\n",
    "    facet_i = row_i.facet\n",
    "    facet_rank_i = row_i.facet_rank\n",
    "    iter_time_i = row_i.iter_time_i\n",
    "    phase_i = row_i.phase\n",
    "    source_i = row_i.source\n",
    "    # #####################################################\n",
    "\n",
    "    slab_old = slab\n",
    "\n",
    "    # slab_constrained = constrain_slab(atoms=slab)\n",
    "    slab_final = resize_z_slab(atoms=slab, vacuum=15)\n",
    "    slab_final.center()\n",
    "    slab_final.wrap()\n",
    "\n",
    "\n",
    "    # Repeat slab if needed\n",
    "    min_len = 4\n",
    "    out_dict = repeat_xy(\n",
    "        atoms=slab_final,\n",
    "        min_len_x=min_len,\n",
    "        min_len_y=min_len)\n",
    "\n",
    "    atoms_repeated = out_dict[\"atoms_repeated\"]\n",
    "    is_repeated = out_dict[\"is_repeated\"]\n",
    "    repeat_list = out_dict[\"repeat_list\"]\n",
    "\n",
    "\n",
    "    num_atoms_i = atoms_repeated.get_global_number_of_atoms()\n",
    "\n",
    "\n",
    "    surf_a_i = calc_surface_area(atoms=atoms_repeated)\n",
    "\n",
    "    slab_final = atoms_repeated  # <-------------------------------------------\n",
    "\n",
    "    cell_mag_x = np.linalg.norm(slab_final.cell.array[0])\n",
    "    cell_mag_y = np.linalg.norm(slab_final.cell.array[1])\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"slab_id\"] = slab_id\n",
    "    data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "    data_dict_i[\"facet\"] = facet_i\n",
    "    data_dict_i[\"facet_rank\"] = facet_rank_i\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"slab_final_old\"] = slab_old\n",
    "    data_dict_i[\"slab_final\"] = slab_final\n",
    "    data_dict_i[\"phase\"] = phase_i\n",
    "    data_dict_i[\"source\"] = source_i\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"surf_area\"] = surf_a_i\n",
    "    data_dict_i[\"cell_mag_x\"] = cell_mag_x\n",
    "    data_dict_i[\"cell_mag_y\"] = cell_mag_y\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"is_repeated\"] = is_repeated\n",
    "    data_dict_i[\"repeat_list\"] = repeat_list\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"loop_time\"] = time.time() - t0\n",
    "    data_dict_i[\"iter_time_i\"] = iter_time_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".cif\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".traj\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "# #########################################################\n",
    "df_slab_2 = pd.DataFrame(data_dict_list)\n",
    "df_slab_2 = df_slab_2.set_index(\"slab_id\", drop=False)\n",
    "\n",
    "# df_slab_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis of slabs\n",
    "\n",
    "  * Get slab thickness\n",
    "  * Asign whether slab is unique or not based on slab similarity analysis"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_slab_simil\n",
    "df_slab_simil = get_df_slab_simil()\n",
    "\n",
    "df_slab_simil_i = df_slab_simil[df_slab_simil.num_ids_to_remove > 0]\n",
    "\n",
    "# #########################################################\n",
    "ids_to_remove = df_slab_simil_i.slab_ids_to_remove.tolist()\n",
    "\n",
    "ids_to_remove_flat = np.array([np.array(i) for i in ids_to_remove])\n",
    "ids_to_remove_flat = np.hstack(ids_to_remove_flat)\n",
    "ids_to_remove_flat = list(ids_to_remove_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "for slab_id_i, row_i in df_slab_2.iterrows():\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # Check whether slab is unique\n",
    "    unique_slab_i = True\n",
    "    if slab_id_i in ids_to_remove_flat:\n",
    "        unique_slab_i = False\n",
    "\n",
    "    # Computing slab thickness\n",
    "    slab_thick_i = get_slab_thickness(atoms=slab_final)\n",
    "\n",
    "    # from methods import get_df_coord\n",
    "    # df_coord_i = get_df_coord(\n",
    "    #     slab_id=slab_id,\n",
    "    #     slab=slab_final,\n",
    "    #     mode=\"slab\")\n",
    "\n",
    "    # from methods import remove_protruding_bottom_Os\n",
    "    # # atoms = slab_final_i\n",
    "    # dz = 0.75\n",
    "    # angle_thresh = 30\n",
    "    # atoms_out = remove_protruding_bottom_Os(\n",
    "    #     atoms=slab_final,\n",
    "    #     dz=dz,\n",
    "    #     angle_thresh=angle_thresh,\n",
    "    #     df_coord=df_coord_i,\n",
    "    #     )\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"slab_thick\"] = slab_thick_i\n",
    "    data_dict_i[\"unique_slab\"] = unique_slab_i\n",
    "    # data_dict_i[\"slab_final\"] = atoms_out\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_slab_info = pd.DataFrame(data_dict_list)\n",
    "df_slab_info = df_slab_info.set_index(\"slab_id\")\n",
    "\n",
    "df_slab_3 = pd.concat([\n",
    "    df_slab_2,\n",
    "    df_slab_info,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_order = [\n",
    "    \"slab_id\",\n",
    "    \"bulk_id\",\n",
    "    \"facet\",\n",
    "    \"slab_thick\",\n",
    "    \"num_atoms\",\n",
    "    \"slab_final\",\n",
    "    \"loop_time\",\n",
    "    \"iter_time_i\",\n",
    "    ]\n",
    "df_slab_3 = reorder_df_columns(cols_order, df_slab_3)\n",
    "\n",
    "df_slab_final = df_slab_3\n",
    "df_slab_final = df_slab_final.set_index(\"slab_id\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_slab_final.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slab_final, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (419, 18)\n",
    "# (457, 18)\n",
    "# (483, 18)\n",
    "\n",
    "df_slab_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import update_df_slab_ids\n",
    "\n",
    "update_df_slab_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting `df_coord` for final slab\n",
    "\n",
    "Needed because of cell xy repitiion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_local = False\n",
    "for i_cnt, row_i in df_slab_final.iterrows():\n",
    "\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    slab_id = row_i.slab_id\n",
    "    # #####################################################\n",
    "\n",
    "    if verbose_local:\n",
    "        print(40 * \"*\")\n",
    "        print(\"slab_id:\", slab_id)\n",
    "\n",
    "    file_name_i = slab_id + \"_after_rep\" + \".pickle\"\n",
    "    file_path_i = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/creating_slabs/out_data/df_coord_files\",\n",
    "        file_name_i)\n",
    "\n",
    "    my_file = Path(file_path_i)\n",
    "    if not my_file.is_file():\n",
    "        df_coord_slab_final = get_structure_coord_df(slab_final)\n",
    "        with open(file_path_i, \"wb\") as fle:\n",
    "            pickle.dump(df_coord_slab_final, fle)\n",
    "    else:\n",
    "        if verbose_local:\n",
    "            print(\"Already computed\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that no slabs are less than 15 A in thickness"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slabs_too_thin = df_slab_3[df_slab_3.slab_thick < 15]\n",
    "\n",
    "print(\"Number of slabs that are too thin:\", \"\\n\", df_slabs_too_thin.shape[0])\n",
    "\n",
    "# df_slabs_too_thin[[\"slab_id\", \"bulk_id\", \"facet\"]].to_csv(\"temp_slabs_too_thin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Processing Speed vs Structure Size"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = df_slab_2.iter_time_i / 60\n",
    "x_array = df_slab_2.num_atoms\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Processing speed vs structure size (num atoms)\",\n",
    "    xaxis=dict(title=dict(text=\"Number of atoms\")),\n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Processing time (min)\",\n",
    "            ),\n",
    "        range=[-1, 40],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=\"iter_speed_vs_num_atoms\",\n",
    "    write_html=True,\n",
    "    write_png=False,\n",
    "    png_scale=6.0,\n",
    "    write_pdf=False,\n",
    "    write_svg=False,\n",
    "    try_orca_write=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the structures that are unique octahedras"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################################################\n",
    "data_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs/selecting_bulks\",\n",
    "    \"out_data/data.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    data = json.load(fle)\n",
    "# #######################################################################\n",
    "\n",
    "bulk_ids__octa_unique = data[\"bulk_ids__octa_unique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_slab_2\n",
    "df_i = df[df.bulk_id.isin(bulk_ids__octa_unique)]\n",
    "\n",
    "file_names_list = []\n",
    "for i_cnt, row_i in df_i.iterrows():\n",
    "    slab = row_i.slab_final\n",
    "\n",
    "    file_name_base = row_i.bulk_id + \"__\" + row_i.slab_id + \"__\" + row_i.facet\n",
    "    file_names_list.append(file_name_base)\n",
    "\n",
    "    file_name = file_name_base + \".cif\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)\n",
    "\n",
    "    file_name = file_name_base + \".traj\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "if False:\n",
    "    file_names_list_i = [i + \".traj\" for i in file_names_list]\n",
    "    print(\"ase gui\", *file_names_list_i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # slab_id\n",
    "\n",
    "# # df_coord_i =\n",
    "# slab_id = \"tetuwido_70\"\n",
    "\n",
    "# get_df_coord(\n",
    "#     slab_id=slab_id,\n",
    "#     slab=slab_final,\n",
    "#     mode=\"slab\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# print(\"TEMP\")\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #| - Import Modules\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# import copy\n",
    "# # from pathlib import Path\n",
    "# from pathlib import Path\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "# import pickle\n",
    "# import  json\n",
    "\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# from pymatgen.io.ase import AseAtomsAdaptor\n",
    "# from pymatgen.analysis import local_env\n",
    "\n",
    "# # #########################################################\n",
    "# from misc_modules.pandas_methods import drop_columns\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # def update_df_slab_ids():\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# #| - update_df_slab_ids\n",
    "# # #####################################################\n",
    "# # Read Data\n",
    "# from methods import get_df_slab_ids\n",
    "# df_slab_ids = get_df_slab_ids()\n",
    "\n",
    "# from methods import get_df_slab\n",
    "# df_slab = get_df_slab()\n",
    "\n",
    "\n",
    "# # #####################################################\n",
    "# # Checking that df_slab_ids has only unique bulk_id+facet pairs\n",
    "# num_entries = len(df_slab_ids.index.tolist())\n",
    "# num_unique_entries = len(list(set(df_slab_ids.index.tolist())))\n",
    "\n",
    "# if num_entries != num_unique_entries:\n",
    "#     print(\"Woh what's going on here\")\n",
    "\n",
    "# mess_i = \"Woops not good\"\n",
    "# assert num_entries == num_unique_entries, mess_i\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# # Looping through df_slab rows and checking if the slab_id is present in df_slab_ids\n",
    "\n",
    "\n",
    "# df = df_slab\n",
    "# df = df[\n",
    "#     (df[\"bulk_id\"] == \"v1xpx482ba\") &\n",
    "#     (df[\"facet\"] == \"20-23\") &\n",
    "#     # (df[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_slab = df\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# data_dict_list = []\n",
    "# # #########################################################\n",
    "# for slab_id_i, row_i in df_slab.iterrows():\n",
    "#     print(\"slab_id_i:\", slab_id_i)\n",
    "#     # #####################################################\n",
    "#     data_dict_i = dict()\n",
    "#     # #####################################################\n",
    "#     bulk_id_i = row_i.bulk_id\n",
    "#     facet_i = row_i.facet\n",
    "#     # #####################################################\n",
    "\n",
    "#     # df_slab_ids.loc[bulk_id_i, facet_i]\n",
    "#     slab_ids_match_i = \"NaN\"\n",
    "#     index_in_df_slab_ids_i = (bulk_id_i, facet_i, ) in df_slab_ids.index\n",
    "#     if index_in_df_slab_ids_i:\n",
    "#         # #################################################\n",
    "#         row_id_i = df_slab_ids.loc[(bulk_id_i, facet_i)]\n",
    "#         # #################################################\n",
    "#         slab_id__from_fle = row_id_i.slab_id\n",
    "#         # #################################################\n",
    "\n",
    "#         slab_ids_match_i = slab_id_i == slab_id__from_fle\n",
    "\n",
    "#     # #####################################################\n",
    "#     data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "#     data_dict_i[\"facet\"] = facet_i\n",
    "#     data_dict_i[\"slab_id\"] = slab_id_i\n",
    "#     data_dict_i[\"index_in_df_slab_ids\"] = index_in_df_slab_ids_i\n",
    "#     data_dict_i[\"slab_ids_match\"] = slab_ids_match_i\n",
    "#     # #####################################################\n",
    "#     data_dict_list.append(data_dict_i)\n",
    "#     # #####################################################\n",
    "\n",
    "# # #########################################################\n",
    "# df = pd.DataFrame(data_dict_list)\n",
    "# # #########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # #####################################################\n",
    "# # # Checking that data objects are consistent with each other\n",
    "# # df_i = df[df.index_in_df_slab_ids == True]\n",
    "\n",
    "# # df_slab__df_slab_ids__consistent = False\n",
    "# # unique_vals = list(set(df_i.slab_ids_match.tolist()))\n",
    "# # if (len(unique_vals) == 1) and unique_vals[0] == True:\n",
    "# #     df_slab__df_slab_ids__consistent = True\n",
    "\n",
    "# # mess_i = \"df_slab and df_slab_ids are not consistent\"\n",
    "# # assert df_slab__df_slab_ids__consistent, mess_i\n",
    "\n",
    "# # # #####################################################\n",
    "# # # Getting all the entries in df_slab that aren't present in df_slab_ids\n",
    "# # df_1 = df[df.index_in_df_slab_ids == False]\n",
    "# # df_1 = df_1.set_index([\"bulk_id\", \"facet\", ], drop=False)\n",
    "# # df_1 = df_1.sort_index()\n",
    "\n",
    "# # # #####################################################\n",
    "# # # Combining the old and new df_slab_ids and saving\n",
    "# # df_slab_ids_new = pd.concat(\n",
    "# #     [\n",
    "# #         df_1[[\"bulk_id\", \"facet\", \"slab_id\", ]],\n",
    "# #         df_slab_ids,\n",
    "# #         ],\n",
    "# #     axis=0,\n",
    "# #     )\n",
    "\n",
    "# # # #####################################################\n",
    "# # # Writing data to file\n",
    "# # pre_dir = os.path.join(\n",
    "# #     os.environ[\"PROJ_irox_oer\"],\n",
    "# #     \"workflow/creating_slabs\")\n",
    "\n",
    "# # df_slab_ids_new.to_csv(\n",
    "# #     os.path.join(pre_dir, \"out_data/slab_id_mapping.csv\"),\n",
    "# #     index=False)\n",
    "\n",
    "# # df_slab_ids_new.to_csv(\n",
    "# #     os.path.join(pre_dir, \"in_data/slab_id_mapping.csv\"),\n",
    "# #     index=False)\n",
    "\n",
    "# #     # \"in_data/slab_id_mapping.csv\",\n",
    "\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df = df_slab\n",
    "# df = df[\n",
    "#     (df[\"bulk_id\"] == \"v1xpx482ba\") &\n",
    "#     (df[\"facet\"] == \"20-23\") &\n",
    "#     # (df[\"\"] == \"\") &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_slab = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# unique_vals = list(set(df_i.slab_ids_match.tolist()))\n",
    "\n",
    "# if (len(unique_vals) == 1) and unique_vals[0] == True:\n",
    "#     df_slab__df_slab_ids__consistent = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# v1xpx482ba\t20-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_i[df_i.slab_ids_match == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
