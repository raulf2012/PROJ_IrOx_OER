{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further process slabs created in `create_slabs.ipynb`\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "# from pathlib import Path\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# #########################################################\n",
    "from plotting.my_plotly import my_plotly_plot\n",
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_structure_coord_df\n",
    "from methods import (\n",
    "    get_df_dft,\n",
    "    get_slab_thickness,\n",
    "    get_df_slab,\n",
    "    )\n",
    "\n",
    "from local_methods import (\n",
    "    constrain_slab,\n",
    "    resize_z_slab,\n",
    "    calc_surface_area,\n",
    "    repeat_xy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `df_slab` and `df_dft` dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = get_df_slab(mode=\"almost-final\")\n",
    "\n",
    "df_dft = get_df_dft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"status\" in df_slab.columns:\n",
    "    df_slab = df_slab[df_slab.status != \"Took too long\"]\n",
    "else:\n",
    "    print(\"eh\")\n",
    "    df_slab = df_slab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs\")\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/final_slabs_1\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/final_slabs_2\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = os.path.join(\n",
    "    dir_root,\n",
    "    \"out_data/bulk_structures_temp\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main processing slabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "iterator = tqdm(df_slab.index.tolist(), desc=\"1st loop\")\n",
    "for i_cnt, slab_id_i in enumerate(iterator):\n",
    "    row_i = df_slab.loc[slab_id_i]\n",
    "\n",
    "    # if i_cnt > 100:\n",
    "    #     break\n",
    "\n",
    "    data_dict_i = dict()\n",
    "    t0 = time.time()\n",
    "\n",
    "    # #####################################################\n",
    "    slab_id = row_i.name\n",
    "    slab = row_i.slab_final\n",
    "    bulk_id_i = row_i.bulk_id\n",
    "    facet_i = row_i.facet\n",
    "    facet_rank_i = row_i.facet_rank\n",
    "    iter_time_i = row_i.iter_time_i\n",
    "    phase_i = row_i.phase\n",
    "    source_i = row_i.source\n",
    "    # #####################################################\n",
    "\n",
    "    slab_old = slab\n",
    "\n",
    "    # slab_constrained = constrain_slab(atoms=slab)\n",
    "    slab_final = resize_z_slab(atoms=slab, vacuum=15)\n",
    "    slab_final.center()\n",
    "    slab_final.wrap()\n",
    "\n",
    "\n",
    "    # Repeat slab if needed\n",
    "    min_len = 4\n",
    "    out_dict = repeat_xy(\n",
    "        atoms=slab_final,\n",
    "        min_len_x=min_len,\n",
    "        min_len_y=min_len)\n",
    "\n",
    "    atoms_repeated = out_dict[\"atoms_repeated\"]\n",
    "    is_repeated = out_dict[\"is_repeated\"]\n",
    "    repeat_list = out_dict[\"repeat_list\"]\n",
    "\n",
    "\n",
    "    num_atoms_i = atoms_repeated.get_global_number_of_atoms()\n",
    "\n",
    "\n",
    "    surf_a_i = calc_surface_area(atoms=atoms_repeated)\n",
    "\n",
    "    slab_final = atoms_repeated  # <-------------------------------------------\n",
    "\n",
    "    cell_mag_x = np.linalg.norm(slab_final.cell.array[0])\n",
    "    cell_mag_y = np.linalg.norm(slab_final.cell.array[1])\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"slab_id\"] = slab_id\n",
    "    data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "    data_dict_i[\"facet\"] = facet_i\n",
    "    data_dict_i[\"facet_rank\"] = facet_rank_i\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"slab_final_old\"] = slab_old\n",
    "    data_dict_i[\"slab_final\"] = slab_final\n",
    "    data_dict_i[\"phase\"] = phase_i\n",
    "    data_dict_i[\"source\"] = source_i\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"surf_area\"] = surf_a_i\n",
    "    data_dict_i[\"cell_mag_x\"] = cell_mag_x\n",
    "    data_dict_i[\"cell_mag_y\"] = cell_mag_y\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"is_repeated\"] = is_repeated\n",
    "    data_dict_i[\"repeat_list\"] = repeat_list\n",
    "    # -----------------------------------------------------\n",
    "    data_dict_i[\"loop_time\"] = time.time() - t0\n",
    "    data_dict_i[\"iter_time_i\"] = iter_time_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".cif\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".traj\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "# #########################################################\n",
    "df_slab_2 = pd.DataFrame(data_dict_list)\n",
    "df_slab_2 = df_slab_2.set_index(\"slab_id\", drop=False)\n",
    "\n",
    "# df_slab_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis of slabs\n",
    "\n",
    "  * Get slab thickness\n",
    "  * Asign whether slab is unique or not based on slab similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_slab_simil\n",
    "df_slab_simil = get_df_slab_simil()\n",
    "\n",
    "df_slab_simil_i = df_slab_simil[df_slab_simil.num_ids_to_remove > 0]\n",
    "\n",
    "# #########################################################\n",
    "ids_to_remove = df_slab_simil_i.slab_ids_to_remove.tolist()\n",
    "\n",
    "ids_to_remove_flat = np.array([np.array(i) for i in ids_to_remove])\n",
    "ids_to_remove_flat = np.hstack(ids_to_remove_flat)\n",
    "ids_to_remove_flat = list(ids_to_remove_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "for slab_id_i, row_i in df_slab_2.iterrows():\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # Check whether slab is unique\n",
    "    unique_slab_i = True\n",
    "    if slab_id_i in ids_to_remove_flat:\n",
    "        unique_slab_i = False\n",
    "\n",
    "    # Computing slab thickness\n",
    "    slab_thick_i = get_slab_thickness(atoms=slab_final)\n",
    "\n",
    "    # from methods import get_df_coord\n",
    "    # df_coord_i = get_df_coord(\n",
    "    #     slab_id=slab_id,\n",
    "    #     slab=slab_final,\n",
    "    #     mode=\"slab\")\n",
    "\n",
    "    # from methods import remove_protruding_bottom_Os\n",
    "    # # atoms = slab_final_i\n",
    "    # dz = 0.75\n",
    "    # angle_thresh = 30\n",
    "    # atoms_out = remove_protruding_bottom_Os(\n",
    "    #     atoms=slab_final,\n",
    "    #     dz=dz,\n",
    "    #     angle_thresh=angle_thresh,\n",
    "    #     df_coord=df_coord_i,\n",
    "    #     )\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"slab_thick\"] = slab_thick_i\n",
    "    data_dict_i[\"unique_slab\"] = unique_slab_i\n",
    "    # data_dict_i[\"slab_final\"] = atoms_out\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_slab_info = pd.DataFrame(data_dict_list)\n",
    "df_slab_info = df_slab_info.set_index(\"slab_id\")\n",
    "\n",
    "df_slab_3 = pd.concat([\n",
    "    df_slab_2,\n",
    "    df_slab_info,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_order = [\n",
    "    \"slab_id\",\n",
    "    \"bulk_id\",\n",
    "    \"facet\",\n",
    "    \"slab_thick\",\n",
    "    \"num_atoms\",\n",
    "    \"slab_final\",\n",
    "    \"loop_time\",\n",
    "    \"iter_time_i\",\n",
    "    ]\n",
    "df_slab_3 = reorder_df_columns(cols_order, df_slab_3)\n",
    "\n",
    "df_slab_final = df_slab_3\n",
    "df_slab_final = df_slab_final.set_index(\"slab_id\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_slab_final.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slab_final, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (419, 18)\n",
    "# (457, 18)\n",
    "# (483, 18)\n",
    "\n",
    "df_slab_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import update_df_slab_ids\n",
    "\n",
    "update_df_slab_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting `df_coord` for final slab\n",
    "\n",
    "Needed because of cell xy repitiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_local = False\n",
    "for i_cnt, row_i in df_slab_final.iterrows():\n",
    "\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    slab_id = row_i.slab_id\n",
    "    # #####################################################\n",
    "\n",
    "    if verbose_local:\n",
    "        print(40 * \"*\")\n",
    "        print(\"slab_id:\", slab_id)\n",
    "\n",
    "    file_name_i = slab_id + \"_after_rep\" + \".pickle\"\n",
    "    file_path_i = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/creating_slabs/out_data/df_coord_files\",\n",
    "        file_name_i)\n",
    "\n",
    "    my_file = Path(file_path_i)\n",
    "    if not my_file.is_file():\n",
    "        df_coord_slab_final = get_structure_coord_df(slab_final)\n",
    "        with open(file_path_i, \"wb\") as fle:\n",
    "            pickle.dump(df_coord_slab_final, fle)\n",
    "    else:\n",
    "        if verbose_local:\n",
    "            print(\"Already computed\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that no slabs are less than 15 A in thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slabs_too_thin = df_slab_3[df_slab_3.slab_thick < 15]\n",
    "\n",
    "print(\"Number of slabs that are too thin:\", \"\\n\", df_slabs_too_thin.shape[0])\n",
    "\n",
    "# df_slabs_too_thin[[\"slab_id\", \"bulk_id\", \"facet\"]].to_csv(\"temp_slabs_too_thin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Processing Speed vs Structure Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = df_slab_2.iter_time_i / 60\n",
    "x_array = df_slab_2.num_atoms\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Processing speed vs structure size (num atoms)\",\n",
    "    xaxis=dict(title=dict(text=\"Number of atoms\")),\n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Processing time (min)\",\n",
    "            ),\n",
    "        range=[-1, 40],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=\"iter_speed_vs_num_atoms\",\n",
    "    write_html=True,\n",
    "    write_png=False,\n",
    "    png_scale=6.0,\n",
    "    write_pdf=False,\n",
    "    write_svg=False,\n",
    "    try_orca_write=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the structures that are unique octahedras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################################################\n",
    "data_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs/selecting_bulks\",\n",
    "    \"out_data/data.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    data = json.load(fle)\n",
    "# #######################################################################\n",
    "\n",
    "bulk_ids__octa_unique = data[\"bulk_ids__octa_unique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_slab_2\n",
    "df_i = df[df.bulk_id.isin(bulk_ids__octa_unique)]\n",
    "\n",
    "file_names_list = []\n",
    "for i_cnt, row_i in df_i.iterrows():\n",
    "    slab = row_i.slab_final\n",
    "\n",
    "    file_name_base = row_i.bulk_id + \"__\" + row_i.slab_id + \"__\" + row_i.facet\n",
    "    file_names_list.append(file_name_base)\n",
    "\n",
    "    file_name = file_name_base + \".cif\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)\n",
    "\n",
    "    file_name = file_name_base + \".traj\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "if False:\n",
    "    file_names_list_i = [i + \".traj\" for i in file_names_list]\n",
    "    print(\"ase gui\", *file_names_list_i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
