{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing linear model for OER adsorption energies\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/model_building/SVR\n",
      "RegressionModel_2 will eventually replace  RegressionModel_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_features_targets,\n",
    "    get_df_features_targets_seoin,\n",
    "    )\n",
    "\n",
    "from methods_models import ModelAgent, GP_Regression\n",
    "\n",
    "from proj_data import adsorbates\n",
    "from proj_data import layout_shared\n",
    "from proj_data import scatter_marker_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/model_building/gaussian_process/my_data/all_features_mine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "target_ads_i = \"oh\"\n",
    "\n",
    "feature_ads_i = \"o\"\n",
    "\n",
    "use_seoin_data = False\n",
    "\n",
    "if use_seoin_data:\n",
    "    feature_ads_i = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_easy_settings = True\n",
    "if quick_easy_settings:\n",
    "    k_fold_partition_size = 170\n",
    "    do_every_nth_pca_comp = 8\n",
    "else:\n",
    "    k_fold_partition_size = 30\n",
    "    do_every_nth_pca_comp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_features_targets = get_df_features_targets()\n",
    "\n",
    "# #########################################################\n",
    "df_seoin = get_df_features_targets_seoin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine mine and Seoin's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_seoin_data:\n",
    "    # Replace multiindex with index of tuples so that my data and Seoin's data can be combined\n",
    "    indices = df_features_targets.index.tolist()\n",
    "    df_features_targets.index = indices\n",
    "\n",
    "    indices = df_seoin.index.tolist()\n",
    "    df_seoin.index = indices\n",
    "\n",
    "    # Remove columns that aren't shared by my and Seoin's data\n",
    "    cols_0 =df_features_targets.columns.tolist()\n",
    "    cols_1 = df_seoin.columns.tolist()\n",
    "\n",
    "    cols_comb = cols_0 + cols_1\n",
    "\n",
    "    cols_comb_unique = []\n",
    "    for col_i in cols_comb:\n",
    "        if col_i not in cols_comb_unique:\n",
    "            cols_comb_unique.append(col_i)\n",
    "\n",
    "    shared_cols = []\n",
    "    for col_i in cols_comb_unique:\n",
    "        if col_i in df_features_targets.columns and col_i in df_seoin.columns:\n",
    "            shared_cols.append(col_i)\n",
    "\n",
    "    # Combine data\n",
    "    df_data = pd.concat([\n",
    "        df_features_targets[shared_cols],\n",
    "        df_seoin[shared_cols],\n",
    "        ], axis=0)\n",
    "else:\n",
    "    df_data = df_features_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(111 * \"TEMP | \")\n",
    "\n",
    "if True:\n",
    "\n",
    "    if use_seoin_data:\n",
    "        df_data = df_data[[\n",
    "            # ('targets', 'g_o', ''),\n",
    "            ('targets', 'g_oh', ''),\n",
    "            ('data', 'stoich', ''),\n",
    "\n",
    "            ('features', 'o', 'active_o_metal_dist'),\n",
    "            ('features', 'o', 'angle_O_Ir_surf_norm'),\n",
    "            ('features', 'o', 'ir_o_mean'),\n",
    "            ('features', 'o', 'ir_o_std'),\n",
    "            ('features', 'o', 'octa_vol'),\n",
    "            ('features', 'dH_bulk', ''),\n",
    "            ('features', 'volume_pa', ''),\n",
    "            ('features', 'bulk_oxid_state', ''),\n",
    "            ('features', 'effective_ox_state', ''),\n",
    "            ]]\n",
    "    else:\n",
    "        df_data = df_data[[\n",
    "\n",
    "            # ('targets', 'g_o', ''),\n",
    "            ('targets', 'g_oh', ''),\n",
    "\n",
    "            ('data', 'stoich', ''),\n",
    "            ('data', 'job_id_o', ''),\n",
    "            ('data', 'job_id_oh', ''),\n",
    "            ('data', 'job_id_bare', ''),\n",
    "\n",
    "            ('features', 'o', 'O_magmom'),\n",
    "            ('features', 'o', 'Ir_magmom'),\n",
    "            ('features', 'o', 'Ir*O_bader'),\n",
    "            ('features', 'o', 'Ir_bader'),\n",
    "            ('features', 'o', 'O_bader'),\n",
    "            ('features', 'o', 'active_o_metal_dist'),\n",
    "            ('features', 'o', 'angle_O_Ir_surf_norm'),\n",
    "            ('features', 'o', 'ir_o_mean'),\n",
    "            ('features', 'o', 'ir_o_std'),\n",
    "            ('features', 'o', 'octa_vol'),\n",
    "            ('features', 'o', 'p_band_center'),\n",
    "            ('features', 'o', 'Ir*O_bader/ir_o_mean'),\n",
    "            ('features', 'dH_bulk', ''),\n",
    "            ('features', 'volume_pa', ''),\n",
    "            ('features', 'bulk_oxid_state', ''),\n",
    "            ('features', 'effective_ox_state', ''),\n",
    "\n",
    "            # ('features_pre_dft', 'active_o_metal_dist__pre', ''),\n",
    "            # ('features_pre_dft', 'ir_o_mean__pre', ''),\n",
    "            # ('features_pre_dft', 'ir_o_std__pre', ''),\n",
    "            # ('features_pre_dft', 'octa_vol__pre', ''),\n",
    "\n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdict = [\n",
    "    {\n",
    "        \"type\": \"gaussian\",\n",
    "        \"dimension\": \"single\",\n",
    "        \"width\": 1.8,\n",
    "        \"scaling\": 0.5,\n",
    "        \"scaling_bounds\": ((0.0001, 10.),),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "GP_R = GP_Regression(\n",
    "    kernel_list=kdict,\n",
    "    regularization=0.01,\n",
    "    optimize_hyperparameters=True,\n",
    "    scale_data=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods_models import SVR_Regression\n",
    "\n",
    "SVR_R = SVR_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "4\n",
      "MAE: 0.1939\n",
      "MA.r2: 0.7289\n",
      "MAE (in_fold): 0.1633\n",
      "\n",
      "****************************************\n",
      "12\n",
      "MAE: 0.2133\n",
      "MA.r2: 0.6777\n",
      "MAE (in_fold): 0.105\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4 PCA components are ideal with an MAE of 0.1939\n"
     ]
    }
   ],
   "source": [
    "data_dict_list = []\n",
    "num_feat_cols = df_data.features.shape[1]\n",
    "for num_pca_i in range(4, num_feat_cols + 1, do_every_nth_pca_comp):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(40 * \"*\")\n",
    "        print(num_pca_i)\n",
    "\n",
    "    MA = ModelAgent(\n",
    "        df_features_targets=df_data,\n",
    "        Regression=SVR_R,\n",
    "        Regression_class=SVR_Regression,\n",
    "        use_pca=True,\n",
    "        num_pca=num_pca_i,\n",
    "        adsorbates=adsorbates,\n",
    "        stand_targets=False,  # True was giving much worse errors, keep False\n",
    "        )\n",
    "\n",
    "    MA.run_kfold_cv_workflow(\n",
    "        k_fold_partition_size=k_fold_partition_size,\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MAE:\", np.round(MA.mae, 4))\n",
    "        print(\"MA.r2:\", np.round(MA.r2, 4))\n",
    "        print(\"MAE (in_fold):\", np.round(MA.mae_infold, 4))\n",
    "\n",
    "    data_dict_i = dict()\n",
    "    data_dict_i[\"num_pca\"] = num_pca_i\n",
    "    data_dict_i[\"MAE\"] = MA.mae\n",
    "    data_dict_i[\"ModelAgent\"] = MA\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "df_models = pd.DataFrame(data_dict_list)\n",
    "df_models = df_models.set_index(\"num_pca\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "# Finding best performing model\n",
    "row_models_i = df_models.sort_values(\"MAE\").iloc[0]\n",
    "\n",
    "MA_best = row_models_i.ModelAgent\n",
    "\n",
    "print(4 * \"\\n\")\n",
    "if verbose:\n",
    "    print(\n",
    "        row_models_i.name,\n",
    "        \" PCA components are ideal with an MAE of \",\n",
    "        np.round(\n",
    "        row_models_i.MAE,\n",
    "            4),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP\n",
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP\n",
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = MA\n",
    "k_fold_partition_size=30\n",
    "\n",
    "# def run_kfold_cv_workflow(self,\n",
    "#     k_fold_partition_size=None,\n",
    "#     ):\n",
    "\"\"\"Wed Jun  9 20:48:08 PDT 2021\n",
    "\"\"\"\n",
    "# | - run_kfold_cv_workflow\n",
    "# #################################################\n",
    "_run_kfold_cv_workflow__get_cv_data = \\\n",
    "    self._run_kfold_cv_workflow__get_cv_data\n",
    "_run_kfold_cv_workflow__process_df_predict = \\\n",
    "    self._run_kfold_cv_workflow__process_df_predict\n",
    "_run_kfold_cv_workflow__run_infold = \\\n",
    "    self._run_kfold_cv_workflow__run_infold\n",
    "# #################################################\n",
    "\n",
    "# _run_kfold_cv_workflow__run_infold()\n",
    "\n",
    "# _run_kfold_cv_workflow__get_cv_data(\n",
    "#     k_fold_partition_size=k_fold_partition_size,\n",
    "#     )\n",
    "\n",
    "# _run_kfold_cv_workflow__process_df_predict()\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = MA\n",
    "k_fold_partition_size=100\n",
    "from methods_models import RegressionWorkflow\n",
    "\n",
    "# def _run_kfold_cv_workflow__run_infold(self):\n",
    "\"\"\"Thu Jun 10 16:03:57 PDT 2021\n",
    "\"\"\"\n",
    "# | - _run_kfold_cv_workflow__run_infold\n",
    "# #################################################\n",
    "df_features_targets = self.df_features_targets\n",
    "Regression = self.Regression\n",
    "Regression_class = self.Regression_class\n",
    "use_pca = self._use_pca\n",
    "num_pca = self.num_pca\n",
    "stand_targets = self._stand_targets\n",
    "# #################################################\n",
    "_standardize_train_test = self._standardize_train_test\n",
    "# #################################################\n",
    "init_params = Regression.init_params\n",
    "# #################################################\n",
    "\n",
    "\n",
    "df_data = df_features_targets\n",
    "\n",
    "df_train = df_data\n",
    "df_test = df_data\n",
    "\n",
    "df_train_std, df_test_std = \\\n",
    "    _standardize_train_test(\n",
    "        df_train,\n",
    "        df_test=df_test,\n",
    "        stand_targets=stand_targets,\n",
    "        )\n",
    "df_train_final = df_train_std\n",
    "df_test_final = df_test_std\n",
    "\n",
    "\n",
    "if use_pca:\n",
    "    df_pca_train, df_pca_test, PCA = \\\n",
    "        self._run_pca(df_train, df_test=df_test, num_pca=num_pca)\n",
    "    df_train_final = df_pca_train\n",
    "    df_test_final = df_pca_test\n",
    "\n",
    "# #############################################\n",
    "# Running regression workflow\n",
    "RC = Regression_class(**init_params)\n",
    "\n",
    "RW_infold = RegressionWorkflow(\n",
    "    df_data=df_train_final,\n",
    "    Regression=RC,\n",
    "    )\n",
    "RW_infold.run_Regression()\n",
    "\n",
    "# RW_infold.predict(df_test_final.features, df_test_final.targets)\n",
    "\n",
    "# df_predict = RW_infold.df_predict\n",
    "# mae_infold = df_predict.error.abs().mean()\n",
    "\n",
    "\n",
    "# # #################################################\n",
    "# self.RW_infold = RW_infold\n",
    "# self.mae_infold = mae_infold\n",
    "# self.PCA_infold = PCA\n",
    "# # #################################################\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = RW_infold\n",
    "\n",
    "# def run_Regression(self):\n",
    "\"\"\"Wed Jun  9 00:30:03 PDT 2021\n",
    "\"\"\"\n",
    "# | - run_Regression\n",
    "# #################################################\n",
    "df_data = self.df_data\n",
    "Regression = self.Regression\n",
    "# #################################################\n",
    "\n",
    "\n",
    "# Run regression (train model)\n",
    "Regression.run_regression(\n",
    "    train_features=df_data.features,\n",
    "    train_targets=df_data.targets,\n",
    "    )\n",
    "# __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=df_data.features\n",
    "train_targets=df_data.targets\n",
    "\n",
    "# def run_regression(self, train_features, train_targets):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# | - run_regression\n",
    "# #################################################\n",
    "# kernel_list = self.kernel_list\n",
    "# regularization = self.regularization\n",
    "# optimize_hyperparameters = self.optimize_hyperparameters\n",
    "# scale_data = self.scale_data\n",
    "# #################################################\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "model_SVR = svm.SVR(\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    # gamma='scale',\n",
    "    gamma='auto',\n",
    "    coef0=0.0,\n",
    "    tol=0.001,\n",
    "    C=1.0,\n",
    "    epsilon=0.1,\n",
    "    shrinking=True,\n",
    "    cache_size=200,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    )\n",
    "\n",
    "# model_SVR.fit(train_features, train_targets[\"y\"].to_numpy())\n",
    "\n",
    "# model_SVR.fit(train_features, train_targets)\n",
    "\n",
    "model_SVR.fit(train_features, train_targets.values.ravel())\n",
    "\n",
    "\n",
    "# | - __old__\n",
    "# GP = GaussianProcess(\n",
    "#     kernel_list=kernel_list,\n",
    "#     regularization=regularization,\n",
    "#     train_fp=train_features,\n",
    "#     train_target=train_targets,\n",
    "#     scale_data=False,\n",
    "#     )\n",
    "#\n",
    "# if optimize_hyperparameters:\n",
    "#     GP.optimize_hyperparameters(\n",
    "#         global_opt=False,\n",
    "#         algomin='L-BFGS-B',\n",
    "#         eval_jac=False,\n",
    "#         loss_function='lml',\n",
    "#         # loss_function='rmse',\n",
    "#         )\n",
    "# __|\n",
    "\n",
    "self.model = model_SVR\n",
    "# __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW_infold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = RW_infold\n",
    "df_features=df_test_final.features\n",
    "df_targets=df_test_final.targets\n",
    "\n",
    "\n",
    "# def predict(self, df_features, df_targets=None):\n",
    "\"\"\"Wed Jun  9 10:11:15 PDT 2021\n",
    "\"\"\"\n",
    "# | - run_Regression\n",
    "# #################################################\n",
    "Regression = self.Regression\n",
    "# #################################################\n",
    "\n",
    "\n",
    "# df_predict = Regression.predict(df_features, df_targets=df_targets)\n",
    "\n",
    "# self.df_predict = df_predict\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Regression\n",
    "df_features\n",
    "df_targets=None\n",
    "\n",
    "# def predict(self,\n",
    "#     df_features,\n",
    "#     df_targets=None,\n",
    "#     ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# | - predict\n",
    "#################################################\n",
    "predict_wrap = self.predict_wrap\n",
    "#################################################\n",
    "\n",
    "\n",
    "df_predict = predict_wrap(df_features)\n",
    "\n",
    "# | - Attach actual target values if test_targets is given\n",
    "if df_targets is not None:\n",
    "    df_targets.columns = [\"actual\"]\n",
    "\n",
    "    df_predict = pd.concat([df_predict, df_targets], axis=1)\n",
    "    df_predict[\"error\"] = df_predict.prediction - df_predict.actual\n",
    "\n",
    "    df_predict_cols = df_predict.columns.tolist()\n",
    "    cols_to_keep_together = [\"prediction\", \"actual\", \"error\", ]\n",
    "    for col_i in cols_to_keep_together:\n",
    "        df_predict_cols.remove(col_i)\n",
    "\n",
    "    new_cols = cols_to_keep_together + df_predict_cols\n",
    "    df_predict = df_predict[new_cols]\n",
    "# __|\n",
    "\n",
    "# return(df_predict)\n",
    "# __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features=df_data.features\n",
    "test_targets=df_data.targets\n",
    "\n",
    "# def predict_wrap(self,\n",
    "#     df_features,\n",
    "#     # df_targets=None,\n",
    "#     ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# | - predict_wrap\n",
    "# #################################################\n",
    "model = self.model\n",
    "# #################################################\n",
    "\n",
    "# prediction = model.predict(\n",
    "#     test_fp=df_features,\n",
    "#     uncertainty=True,\n",
    "#     )\n",
    "\n",
    "prediction = model.predict(\n",
    "    # test_fp=df_features,\n",
    "    df_features,\n",
    "    # uncertainty=True,\n",
    "    )\n",
    "\n",
    "# Construct dataframe of predictions\n",
    "df_predict = pd.DataFrame()\n",
    "df_predict[\"prediction\"] = prediction\n",
    "# df_predict[\"prediction\"] = prediction[\"prediction\"].flatten()\n",
    "# df_predict[\"uncertainty\"] = prediction[\"uncertainty\"]\n",
    "# df_predict[\"uncertainty_with_reg\"] = prediction[\"uncertainty\"]\n",
    "\n",
    "df_predict.index = df_features.index\n",
    "\n",
    "# return(df_predict)\n",
    "# __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP\n",
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP\n",
    "TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP TEMP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SVR_R.run_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# predict_wrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # prediction = \n",
    "\n",
    "# model.predict(\n",
    "#     # test_fp=df_features,\n",
    "#     df_features,\n",
    "#     # uncertainty=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# model.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Regression.model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
