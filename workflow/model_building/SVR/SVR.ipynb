{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing linear model for OER adsorption energies\n",
    "---\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import scatter_marker_props, layout_shared\n",
    "\n",
    "# #########################################################\n",
    "from methods_models import run_gp_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,  os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/model_building\"))\n",
    "\n",
    "from methods_model_building import (\n",
    "    simplify_df_features_targets,\n",
    "    run_kfold_cv_wf,\n",
    "    run_kfold_cv_wf__TEMP,\n",
    "    process_feature_targets_df,\n",
    "    process_pca_analysis,\n",
    "    pca_analysis,\n",
    "    run_regression_wf,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_features_targets\n",
    "df_features_targets = get_df_features_targets()\n",
    "\n",
    "from methods import get_df_slab\n",
    "df_slab = get_df_slab()\n",
    "\n",
    "from methods import get_df_SOAP_AS, get_df_SOAP_MS, get_df_SOAP_ave\n",
    "df_SOAP_AS = get_df_SOAP_AS()\n",
    "df_SOAP_MS = get_df_SOAP_MS()\n",
    "df_SOAP_ave = get_df_SOAP_ave()\n",
    "\n",
    "# #########################################################\n",
    "df_i = df_features_targets\n",
    "\n",
    "# Getting phase > 1 slab ids\n",
    "df_slab_i = df_slab[df_slab.phase > 1]\n",
    "phase_2_slab_ids = df_slab_i.slab_id.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping phase 1 slabs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_i.index.to_frame()\n",
    "df_index_i = df_index[\n",
    "    df_index.slab_id.isin(phase_2_slab_ids)\n",
    "    ]\n",
    "\n",
    "if verbose:\n",
    "    print(\"Dropping phase 1 slabs\")\n",
    "df_i = df_i.loc[\n",
    "    df_index_i.index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G_O Model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "target_ads_i = \"o\"\n",
    "\n",
    "# target_ads_i = \"oh\"\n",
    "feature_ads_i = \"o\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_SOAP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all features built into df, going to be using new ones\n",
    "\n",
    "if using_SOAP:\n",
    "    df_i = df_i.drop(columns=[\"features\", \"features_stan\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SOAP_i = df_SOAP_AS\n",
    "df_SOAP_i = df_SOAP_MS\n",
    "# df_SOAP_i = df_SOAP_ave\n",
    "\n",
    "# df_SOAP_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col_i in df_SOAP_i.columns:\n",
    "    new_cols.append((\"features\", \"o\", col_i))\n",
    "df_SOAP_i.columns = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_tmp = df_i\n",
    "\n",
    "\n",
    "df_tmp_2 = pd.concat([\n",
    "    df_tmp,\n",
    "    df_SOAP_i,\n",
    "    ], axis=1)\n",
    "\n",
    "df_j_tmp = df_tmp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_SOAP:\n",
    "    df_to_use = df_j_tmp\n",
    "else:\n",
    "    df_to_use = df_i\n",
    "\n",
    "df_j = simplify_df_features_targets(\n",
    "    df_to_use,\n",
    "    # df_i,\n",
    "    # df_j_tmp,\n",
    "    target_ads=\"o\",\n",
    "    # feature_ads=\"o\",\n",
    "    feature_ads=\"o\",\n",
    "    )\n",
    "\n",
    "df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with no variance"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j_info = df_j.describe()\n",
    "\n",
    "tmp = (df_j_info.loc[\"std\"] == 0.)\n",
    "\n",
    "columns_to_drop = []\n",
    "for key, val in tmp.to_dict().items():\n",
    "    if val is True:\n",
    "        columns_to_drop.append(key)\n",
    "\n",
    "df_j = df_j.drop(columns=columns_to_drop)\n",
    "\n",
    "df_j = df_j.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if verbose:\n",
    "#     print(\n",
    "#         \"Feature columns available:\"\n",
    "#         \"\\n\",\n",
    "#         20 * \"-\",\n",
    "#         sep=\"\")\n",
    "#     tmp = [print(i) for i in list(df_j[\"features\"].columns)]\n",
    "\n",
    "cols_to_use = list(df_j[\"features\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j = df_j.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False:\n",
    "if True:\n",
    "    data_dict = dict()\n",
    "    max_pca_num = 0\n",
    "    num_pca_list = []\n",
    "    # for num_pca_i in range(1, len(cols_to_use) + 1, 1):\n",
    "    for num_pca_i in range(1, len(cols_to_use) + 1, 2):\n",
    "    # for num_pca_i in range(1, 100, 16):\n",
    "#     for num_pca_i in range(1, 8, 2):\n",
    "    # for num_pca_i in [4, 8, 15]:\n",
    "    # for num_pca_i in [1, ]:\n",
    "\n",
    "        if num_pca_i > max_pca_num:\n",
    "            max_pca_num = num_pca_i\n",
    "\n",
    "        num_pca_list.append(num_pca_i)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\")\n",
    "            print(40 * \"*\")\n",
    "            print(num_pca_i)\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        out_dict = run_kfold_cv_wf__TEMP(\n",
    "            df_features_targets=df_j,\n",
    "            cols_to_use=cols_to_use,\n",
    "            df_format=df_format,\n",
    "            run_pca=True,\n",
    "            num_pca_comp=num_pca_i,\n",
    "            # k_fold_partition_size=40,\n",
    "            # k_fold_partition_size=30,\n",
    "            k_fold_partition_size=60,\n",
    "            model_workflow=run_gp_workflow,\n",
    "\n",
    "            # model_settings=None,\n",
    "\n",
    "            # model_settings=dict(\n",
    "            #     gp_settings=gp_settings,\n",
    "            #     kdict=kdict,\n",
    "            #     ),\n",
    "            )\n",
    "        # #####################################################\n",
    "        df_target_pred = out_dict[\"df_target_pred\"]\n",
    "        MAE = out_dict[\"MAE\"]\n",
    "        R2 = out_dict[\"R2\"]\n",
    "        PCA = out_dict[\"pca\"]\n",
    "        regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "        df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "        MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "        # RM_2 = out_dict[\"RM_2\"]\n",
    "        # #####################################################\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"MAE: \",\n",
    "                np.round(MAE, 5),\n",
    "                \" eV\",\n",
    "                sep=\"\")\n",
    "\n",
    "            print(\n",
    "                \"R2: \",\n",
    "                np.round(R2, 5),\n",
    "                sep=\"\")\n",
    "\n",
    "            print(\n",
    "                \"MAE (predicting on train set): \",\n",
    "                np.round(MAE_pred_on_train, 5),\n",
    "                sep=\"\")\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        data_dict_i = dict()\n",
    "        # #####################################################\n",
    "        data_dict_i[\"df_target_pred\"] = df_target_pred\n",
    "        data_dict_i[\"MAE\"] = MAE\n",
    "        data_dict_i[\"R2\"] = R2\n",
    "        data_dict_i[\"PCA\"] = PCA\n",
    "\n",
    "        data_dict_i[\"df_target_pred\"] = df_target_pred_on_train\n",
    "        data_dict_i[\"MAE_2\"] = MAE_pred_on_train\n",
    "        # data_dict_i[\"RM_2\"] = RM_2\n",
    "        # #####################################################\n",
    "        data_dict[num_pca_i] = data_dict_i\n",
    "        # #####################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting in-fold predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict_i = data_dict[\n",
    "#     num_pca_best\n",
    "#     ]\n",
    "\n",
    "# df_target_pred = data_dict_i[\"df_target_pred\"]\n",
    "df_target_pred = df_target_pred_on_train\n",
    "# data_dict_i[\"df_target_pred\"]\n",
    "\n",
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dd = 0.1\n",
    "\n",
    "trace_parity = go.Scatter(\n",
    "    y=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    x=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    mode=\"lines\",\n",
    "    name=\"Parity line\",\n",
    "    line_color=\"black\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trace_i = go.Scatter(\n",
    "    y=df_target_pred[\"y\"],\n",
    "    x=df_target_pred[\"y_pred\"],\n",
    "    mode=\"markers\",\n",
    "    name=\"CV Regression\",\n",
    "    # opacity=0.8,\n",
    "    opacity=1.,\n",
    "\n",
    "    marker=dict(\n",
    "        color=df_target_pred[\"color\"],\n",
    "        # color=\"grey\",\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()\n",
    "\n",
    "dd = 0.1\n",
    "\n",
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=True,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Simulated \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Predicted \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared_i = copy.deepcopy(layout_shared)\n",
    "layout_shared_i = layout_shared_i.update(layout_mine)\n",
    "\n",
    "# data = [trace_parity, trace_i, trace_j]\n",
    "data = [trace_parity, trace_i, ]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout_shared_i)\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down PCA stats"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = data_dict[max_pca_num][\"PCA\"]\n",
    "\n",
    "if PCA is not None:\n",
    "    if verbose:\n",
    "        print(\"Explained variance percentage\")\n",
    "        print(40 * \"-\")\n",
    "        tmp = [print(100 * i) for i in PCA.explained_variance_ratio_]\n",
    "        print(\"\")\n",
    "\n",
    "    df_pca_comp = pd.DataFrame(\n",
    "        abs(PCA.components_),\n",
    "        columns=cols_to_use,\n",
    "        )\n",
    "\n",
    "    # if verbose:\n",
    "    if False:\n",
    "        display(df_pca_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if verbose:\n",
    "if False:\n",
    "    for i in range(df_pca_comp.shape[0]):\n",
    "        print(40 * \"-\")\n",
    "        print(i)\n",
    "        print(40 * \"-\")\n",
    "\n",
    "        df_pca_comp_i = df_pca_comp.loc[i].sort_values(ascending=False)\n",
    "\n",
    "        print(df_pca_comp_i.iloc[0:4].to_string())\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for num_pca_i, dict_i in data_dict.items():\n",
    "\n",
    "    MAE_i = dict_i[\"MAE\"]\n",
    "    R2_i = dict_i[\"R2\"]\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    data_dict_i[\"num_pca\"] = num_pca_i\n",
    "    data_dict_i[\"MAE\"] = MAE_i\n",
    "    data_dict_i[\"R2\"] = R2_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "# #########################################################\n",
    "df = pd.DataFrame(data_dict_list)\n",
    "df = df.set_index(\"num_pca\")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=False,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=dict(\n",
    "            text=\"K-Fold Cross Validated MAE\",\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=dict(\n",
    "            text=\"Num PCA Components\",\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared_i = layout_shared.update(layout_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_i = go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df.MAE,\n",
    "    mode=\"markers\",\n",
    "\n",
    "    marker=dict(\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "data = [trace_i, ]\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=data,\n",
    "    layout=layout_shared_i,\n",
    "    )\n",
    "\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the best model (optimal num PCA components)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pca_best = 7\n",
    "# num_pca_best = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_i = data_dict[\n",
    "    num_pca_best\n",
    "    ]\n",
    "\n",
    "df_target_pred = data_dict_i[\"df_target_pred\"]\n",
    "\n",
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 0.1\n",
    "\n",
    "trace_parity = go.Scatter(\n",
    "    y=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    x=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    mode=\"lines\",\n",
    "    name=\"Parity line\",\n",
    "    line_color=\"black\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_i = go.Scatter(\n",
    "    y=df_target_pred[\"y\"],\n",
    "    x=df_target_pred[\"y_pred\"],\n",
    "    mode=\"markers\",\n",
    "    name=\"CV Regression\",\n",
    "    # opacity=0.8,\n",
    "    opacity=1.,\n",
    "\n",
    "    marker=dict(\n",
    "        color=df_target_pred[\"color\"],\n",
    "        # color=\"grey\",\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-fold model (trained on all data, no test/train split)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = run_regression_wf(\n",
    "    df_features_targets=df_j,\n",
    "    cols_to_use=cols_to_use,\n",
    "    df_format=df_format,\n",
    "    run_pca=False,\n",
    "    num_pca_comp=num_pca_best,\n",
    "    model_workflow=run_gp_workflow,\n",
    "\n",
    "    # model_settings=dict(\n",
    "    #     gp_settings=gp_settings,\n",
    "    #     kdict=kdict,\n",
    "    #     ),\n",
    "\n",
    "    )\n",
    "\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "\n",
    "if verbose:\n",
    "    print(\"MAE:\", MAE)\n",
    "    print(\"R2:\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()\n",
    "\n",
    "dd = 0.1\n",
    "\n",
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=True,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Simulated \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Predicted \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared = layout_shared.update(layout_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_j = go.Scatter(\n",
    "    y=df_target_pred[\"y\"],\n",
    "    x=df_target_pred[\"y_pred\"],\n",
    "    mode=\"markers\",\n",
    "    opacity=0.8,\n",
    "    name=\"In-fold Regression\",\n",
    "\n",
    "    marker=dict(\n",
    "        color=df_target_pred[\"color\"],\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "data = [trace_parity, trace_i, trace_j]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout_shared)\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"gaussian_proc.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "# my_plotly_plot(\n",
    "#     figure=fig,\n",
    "#     save_dir=None,\n",
    "#     place_in_out_plot=True,\n",
    "#     plot_name='TEMP_PLOT_NAME',\n",
    "#     write_html=True,\n",
    "#     write_png=False,\n",
    "#     png_scale=6.0,\n",
    "#     write_pdf=False,\n",
    "#     write_svg=False,\n",
    "#     try_orca_write=True,\n",
    "#     verbose=False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # | - Import  Modules\n",
    "# import os\n",
    "# import copy\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # SciKitLearn\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Catlearn\n",
    "# from catlearn.regression.gaussian_process import GaussianProcess\n",
    "# from catlearn.preprocess.clean_data import (\n",
    "#     clean_infinite,\n",
    "#     clean_variance,\n",
    "#     clean_skewness)\n",
    "# from catlearn.preprocess.scaling import standardize\n",
    "\n",
    "# from IPython.display import display\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# from methods_models import run_SVR_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_features_targets=df_j\n",
    "# cols_to_use=cols_to_use\n",
    "# df_format=df_format\n",
    "# run_pca=True\n",
    "# num_pca_comp=3\n",
    "# k_fold_partition_size=100\n",
    "# model_workflow=run_SVR_workflow\n",
    "# model_settings=None,\n",
    "\n",
    "# # def run_kfold_cv_wf__TEMP(\n",
    "# #     df_features_targets=None,\n",
    "# #     cols_to_use=None,\n",
    "# #     df_format=None,\n",
    "\n",
    "# #     run_pca=True,\n",
    "# #     num_pca_comp=3,\n",
    "# #     k_fold_partition_size=20,\n",
    "# #     model_workflow=None,\n",
    "# #     model_settings=None,\n",
    "# #     # kdict=None,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "\n",
    "# df_features_targets\n",
    "\n",
    "#     Column levels are as follows:\n",
    "\n",
    "#     features                         targets\n",
    "#     feat_0    feat_1    feat_2...    g_oh\n",
    "\n",
    "# \"\"\"\n",
    "# #| -  run_kfold_cv_wf\n",
    "# # df_j = df_features_targets\n",
    "\n",
    "# df_j = process_feature_targets_df(\n",
    "#     df_features_targets=df_features_targets,\n",
    "#     cols_to_use=cols_to_use,\n",
    "#     )\n",
    "\n",
    "# df_j = df_j.dropna()\n",
    "\n",
    "# # COMBAK New line\n",
    "# # print(17 * \"TEMP | \")\n",
    "# df_j = df_j.dropna(axis=1)\n",
    "\n",
    "# # print(df_j)\n",
    "\n",
    "# if run_pca:\n",
    "#     # #####################################################\n",
    "#     # df_pca = process_pca_analysis(\n",
    "#     out_dict = process_pca_analysis(\n",
    "#         df_features_targets=df_j,\n",
    "#         num_pca_comp=num_pca_comp,\n",
    "#         )\n",
    "#     # #####################################################\n",
    "#     df_pca = out_dict[\"df_pca\"]\n",
    "#     pca = out_dict[\"pca\"]\n",
    "#     # #####################################################\n",
    "\n",
    "#     df_data = df_pca\n",
    "# else:\n",
    "#     df_data = df_j\n",
    "#     pca = None\n",
    "\n",
    "\n",
    "# #| - Creating k-fold partitions\n",
    "# x = df_j.index.tolist()\n",
    "\n",
    "# partitions = []\n",
    "# for i in range(0, len(x), k_fold_partition_size):\n",
    "#     slice_item = slice(i, i + k_fold_partition_size, 1)\n",
    "#     partitions.append(x[slice_item])\n",
    "# #__|\n",
    "\n",
    "# #| - Run k-fold cross-validation\n",
    "# df_target_pred_parts = []\n",
    "# df_target_pred_parts_2 = []\n",
    "# regression_model_list = []\n",
    "# for k_cnt, part_k in enumerate(range(len(partitions))):\n",
    "\n",
    "#     test_partition = partitions[part_k]\n",
    "\n",
    "#     train_partition = partitions[0:part_k] + partitions[part_k + 1:]\n",
    "#     train_partition = [item for sublist in train_partition for item in sublist]\n",
    "\n",
    "\n",
    "#     # #####################################################\n",
    "#     # df_test = df_pca.loc[test_partition]\n",
    "#     # df_train = df_pca.loc[train_partition]\n",
    "#     df_test = df_data.loc[test_partition]\n",
    "#     df_train = df_data.loc[train_partition]\n",
    "#     # #####################################################\n",
    "#     df_train_features = df_train[\"features\"]\n",
    "#     df_train_targets = df_train[\"targets\"]\n",
    "#     df_test_features = df_test[\"features\"]\n",
    "#     df_test_targets = df_test[\"targets\"]\n",
    "#     # #####################################################\n",
    "\n",
    "#     # #####################################################\n",
    "#     # Using the model on the test set (Normal)\n",
    "#     # #####################################################\n",
    "#     out_dict = model_workflow(\n",
    "#         df_train_features=df_train_features,\n",
    "#         df_train_targets=df_train_targets,\n",
    "#         df_test_features=df_test_features,\n",
    "#         df_test_targets=df_test_targets,\n",
    "#         model_settings=model_settings,\n",
    "#         )\n",
    "#     # #####################################################\n",
    "#     df_target_pred = out_dict[\"df_target_pred\"]\n",
    "#     min_val = out_dict[\"min_val\"]\n",
    "#     max_val = out_dict[\"max_val\"]\n",
    "#     # RM_1 = out_dict[\"RegressionModel\"]\n",
    "#     # #####################################################\n",
    "\n",
    "#     # regression_model_list.append(RM_1)\n",
    "\n",
    "#     # #####################################################\n",
    "#     # Using the model on the training set (check for bad model)\n",
    "#     # #####################################################\n",
    "#     out_dict_2 = model_workflow(\n",
    "#         df_train_features=df_train_features,\n",
    "#         df_train_targets=df_train_targets,\n",
    "#         df_test_features=df_train_features,\n",
    "#         df_test_targets=df_train_targets,\n",
    "#         model_settings=model_settings,\n",
    "#         # kdict=kdict,\n",
    "#         )\n",
    "#     # #####################################################\n",
    "#     df_target_pred_2 = out_dict_2[\"df_target_pred\"]\n",
    "#     min_val_2 = out_dict_2[\"min_val\"]\n",
    "#     max_val_2 = out_dict_2[\"max_val\"]\n",
    "#     # RM_2 = out_dict_2[\"RegressionModel\"]\n",
    "#     # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     df_target_pred_parts.append(df_target_pred)\n",
    "#     df_target_pred_parts_2.append(df_target_pred_2)\n",
    "\n",
    "# # #########################################################\n",
    "# df_target_pred_concat = pd.concat(df_target_pred_parts)\n",
    "# df_target_pred = df_target_pred_concat\n",
    "\n",
    "# # Get format column from main `df_features_targets` dataframe\n",
    "\n",
    "# # df_features_targets[\"format\"][\"color\"][\"stoich\"]\n",
    "# # df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]\n",
    "\n",
    "# df_format.name = \"color\"\n",
    "\n",
    "# # Combining model output and target values\n",
    "# df_target_pred = pd.concat([\n",
    "#     df_format,\n",
    "#     df_target_pred,\n",
    "#     ], axis=1)\n",
    "\n",
    "# df_target_pred = df_target_pred.dropna()\n",
    "# # #########################################################\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# df_target_pred_concat_2 = pd.concat(df_target_pred_parts_2)\n",
    "# df_target_pred_2 = df_target_pred_concat_2\n",
    "\n",
    "# # Get format column from main `df_features_targets` dataframe\n",
    "\n",
    "# # df_features_targets[\"format\"][\"color\"][\"stoich\"]\n",
    "# # df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]\n",
    "\n",
    "# df_format.name = \"color\"\n",
    "\n",
    "# # # Combining model output and target values\n",
    "# # df_target_pred_2 = pd.concat([\n",
    "# #     df_format,\n",
    "# #     df_target_pred_2,\n",
    "# #     ], axis=1)\n",
    "\n",
    "# new_col_list = []\n",
    "# for name_i, row_i in df_target_pred_2.iterrows():\n",
    "#     color_i = df_format.loc[row_i.name]\n",
    "#     new_col_list.append(color_i)\n",
    "\n",
    "# df_target_pred_2[\"color\"] = new_col_list\n",
    "\n",
    "\n",
    "# df_target_pred_2 = df_target_pred_2.dropna()\n",
    "# df_target_pred_2 = df_target_pred_2.sort_index()\n",
    "# # #########################################################\n",
    "\n",
    "# #__|\n",
    "\n",
    "# # Calc MAE\n",
    "# MAE = df_target_pred[\"diff_abs\"].sum() / df_target_pred[\"diff\"].shape[0]\n",
    "\n",
    "# MAE_2 = df_target_pred_2[\"diff_abs\"].sum() / df_target_pred_2[\"diff\"].shape[0]\n",
    "\n",
    "\n",
    "# # Calc R2\n",
    "# from sklearn.metrics import r2_score\n",
    "# coefficient_of_dermination = r2_score(\n",
    "#     df_target_pred[\"y\"],\n",
    "#     df_target_pred[\"y_pred\"],\n",
    "#     )\n",
    "\n",
    "\n",
    "# # #####################################################\n",
    "# out_dict = dict()\n",
    "# # #####################################################\n",
    "# out_dict[\"df_target_pred\"] = df_target_pred\n",
    "# out_dict[\"MAE\"] = MAE\n",
    "# out_dict[\"R2\"] = coefficient_of_dermination\n",
    "# out_dict[\"pca\"] = pca\n",
    "# out_dict[\"regression_model_list\"] = regression_model_list\n",
    "\n",
    "# out_dict[\"df_target_pred_on_train\"] = df_target_pred_2\n",
    "# out_dict[\"MAE_pred_on_train\"] = MAE_2\n",
    "# # out_dict[\"RM_2\"] = RM_2\n",
    "# # #####################################################\n",
    "# # return(out_dict)\n",
    "# # #####################################################\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# MAE\n",
    "# MAE_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_train_features=df_train_features\n",
    "# df_train_targets=df_train_targets\n",
    "# df_test_features=df_test_features\n",
    "# df_test_targets=df_test_targets\n",
    "# model_settings=model_settings\n",
    "\n",
    "\n",
    "# # def run_SVR_workflow(\n",
    "# #     df_train_features=None,\n",
    "# #     df_train_targets=None,\n",
    "# #     df_test_features=None,\n",
    "# #     df_test_targets=None,\n",
    "# #     model_settings=None,\n",
    "# #     # kdict=None,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# # | - run_gp_workflow\n",
    "\n",
    "# # if model_settings is None:\n",
    "# #     # GP kernel parameters\n",
    "# #     gp_settings = {\n",
    "# #         \"noise\": 0.02542,\n",
    "# #         \"sigma_l\": 2.5,\n",
    "# #         \"sigma_f\": 0.8,\n",
    "# #         \"alpha\": 0.2,\n",
    "# #         }\n",
    "# # else:\n",
    "# #     gp_settings = model_settings[\"gp_settings\"]\n",
    "\n",
    "# #| - Setting up Gaussian Regression model\n",
    "\n",
    "# # Instantiate GP regression model\n",
    "\n",
    "# # RM = RegressionModel(\n",
    "# #     df_train=df_train_features,\n",
    "# #     train_targets=df_train_targets,\n",
    "\n",
    "# #     df_test=df_test_features,\n",
    "\n",
    "# #     opt_hyperparameters=True,\n",
    "# #     gp_settings_dict=gp_settings,\n",
    "# #     model_settings=model_settings,\n",
    "# #     uncertainty_type='regular',\n",
    "# #     verbose=True,\n",
    "# #     )\n",
    "\n",
    "# # RM.run_regression()\n",
    "\n",
    "\n",
    "# # Clean up model dataframe a bit\n",
    "# # model = RM.model\n",
    "# # model = model.drop(columns=[\"acquired\"])\n",
    "# # model.columns = [\"y_pred\", \"err_pred\"]\n",
    "\n",
    "# from sklearn import svm\n",
    "\n",
    "# # X = [[0, 0], [2, 2]]\n",
    "# # y = [0.5, 2.5]\n",
    "\n",
    "# regr = svm.SVR()\n",
    "# regr.fit(train_x, train_y_standard[\"y\"].to_numpy())\n",
    "\n",
    "# predicted_y = regr.predict(\n",
    "#     df_test_features.to_numpy()\n",
    "#     )\n",
    "\n",
    "\n",
    "# model_i = pd.DataFrame(\n",
    "#     predicted_y,\n",
    "#     columns=[\"y_pred\"],\n",
    "#     index=df_test_features.index,\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_y = df_test_targets[\"y\"]\n",
    "\n",
    "# y_std = train_y.std()\n",
    "\n",
    "# if type(y_std) != float and not isinstance(y_std, np.float64):\n",
    "#     # print(\"This if is True\")\n",
    "#     y_std = y_std.values[0]\n",
    "\n",
    "# y_mean = train_y.mean()\n",
    "# if type(y_mean) != float and not isinstance(y_mean, np.float64):\n",
    "#     y_mean = y_mean.values[0]\n",
    "\n",
    "# model_i[\"y_pred\"] = (model_i[\"y_pred\"] * y_std) + y_mean\n",
    "# # model_i[\"err\"] = (model_i[\"err\"] * y_std)\n",
    "\n",
    "# # __|\n",
    "\n",
    "# # Combining model output and target values\n",
    "# df_target_pred = pd.concat([\n",
    "#     # df_targets,\n",
    "#     df_test_targets,\n",
    "#     model_i,\n",
    "#     ], axis=1)\n",
    "\n",
    "# # Drop NaN rows again\n",
    "# df_target_pred = df_target_pred.dropna()\n",
    "\n",
    "\n",
    "# # Create columns for y_pred - y and |y_pred - y|\n",
    "# df_target_pred[\"diff\"] = df_target_pred[\"y_pred\"] - df_target_pred[\"y\"]\n",
    "# df_target_pred[\"diff_abs\"] = np.abs(df_target_pred[\"diff\"])\n",
    "\n",
    "\n",
    "# # Get global min/max values (min/max over targets and predictions)\n",
    "# df_target_pred_i = df_target_pred[[\"y\", \"y_pred\"]]\n",
    "\n",
    "# max_val = df_target_pred_i.max().max()\n",
    "# min_val = df_target_pred_i.min().min()\n",
    "\n",
    "# max_min_diff = max_val - min_val\n",
    "\n",
    "\n",
    "# # #####################################################\n",
    "# out_dict = dict()\n",
    "# # #####################################################\n",
    "# out_dict[\"df_target_pred\"] = df_target_pred\n",
    "# out_dict[\"min_val\"] = min_val\n",
    "# out_dict[\"max_val\"] = max_val\n",
    "# # out_dict[\"RegressionModel\"] = RM\n",
    "# # #####################################################\n",
    "# # return(out_dict)\n",
    "# # #####################################################\n",
    "# # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# predicted_y\n",
    "\n",
    "# model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# train_y = df_test_targets[\"y\"]\n",
    "\n",
    "# y_std = train_y.std()\n",
    "\n",
    "# if type(y_std) != float and not isinstance(y_std, np.float64):\n",
    "#     # print(\"This if is True\")\n",
    "#     y_std = y_std.values[0]\n",
    "\n",
    "# y_mean = train_y.mean()\n",
    "# if type(y_mean) != float and not isinstance(y_mean, np.float64):\n",
    "#     y_mean = y_mean.values[0]\n",
    "\n",
    "# model_i[\"y_pred\"] = (model_i[\"y_pred\"] * y_std) + y_mean\n",
    "# # model_i[\"err\"] = (model_i[\"err\"] * y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# train_x = df_train_features.to_numpy()\n",
    "# # train_y = train_targets\n",
    "# train_y = df_train_targets\n",
    "# # TEMP\n",
    "# # print(\"train_y.describe():\", train_y.describe())\n",
    "# train_y_standard = (train_y - train_y.mean()) / train_y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "# # X = [[0, 0], [2, 2]]\n",
    "# # y = [0.5, 2.5]\n",
    "\n",
    "# regr = svm.SVR()\n",
    "# regr.fit(train_x, train_y_standard[\"y\"].to_numpy())\n",
    "\n",
    "# predicted_y = regr.predict(\n",
    "#     df_test_features.to_numpy()\n",
    "#     )\n",
    "\n",
    "\n",
    "# model_i = pd.DataFrame(\n",
    "#     predicted_y,\n",
    "#     columns=[\"y_predicted\"],\n",
    "#     index=df_test_features.index,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_test_features.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 'bounds': \n",
    "\n",
    "# (5 * (0.0001, 10.),)\n",
    "\n",
    "# tuple([(0.0001, 10.) for i in range(5)])\n",
    "\n",
    "# # (0.0001, 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_settings = {\n",
    "#     \"noise\": 0.02542,\n",
    "#     # \"noise\": 0.12542,\n",
    "#     }\n",
    "\n",
    "# alpha = 0.01\n",
    "\n",
    "# # sigma_l = 0.1\n",
    "# # sigma_f = 0.1\n",
    "\n",
    "# sigma_l = 1.5\n",
    "# sigma_f = 0.1\n",
    "\n",
    "# kdict = [\n",
    "\n",
    "#     # Guassian Kernel (RBF)\n",
    "#     {\n",
    "#         'type': 'gaussian',\n",
    "#         'dimension': 'single',\n",
    "#         # 'dimension': 'features',\n",
    "#         'width': sigma_l,\n",
    "#         # 'width': 3 * [sigma_l, ],\n",
    "#         'scaling': sigma_f,\n",
    "#         'bounds': ((0.0001, 10.),),\n",
    "#         # 'bounds': (5 * (0.0001, 10.),),\n",
    "#         # 'bounds': tuple([(0.0001, 10.) for i in range(3)]),\n",
    "#         'scaling_bounds': ((0.0001, 10.),),\n",
    "#         },\n",
    "\n",
    "\n",
    "#     ]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
