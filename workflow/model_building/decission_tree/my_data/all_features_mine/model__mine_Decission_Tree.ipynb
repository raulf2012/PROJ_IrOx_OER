{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing linear model for OER adsorption energies\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 PCA components are ideal with an MAE of 0.1872"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/model_building/decission_tree/my_data/all_features_mine\n",
      "RegressionModel_2 will eventually replace  RegressionModel_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_features_targets,\n",
    "    get_df_features_targets_seoin,\n",
    "    )\n",
    "\n",
    "from methods_models import ModelAgent, GP_Regression, Decision_Tree_Regression\n",
    "\n",
    "from proj_data import adsorbates\n",
    "from proj_data import layout_shared\n",
    "from proj_data import scatter_marker_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/model_building/gaussian_process/my_data/all_features_mine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "target_ads_i = \"oh\"\n",
    "\n",
    "feature_ads_i = \"o\"\n",
    "\n",
    "use_seoin_data = False\n",
    "\n",
    "if use_seoin_data:\n",
    "    feature_ads_i = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_easy_settings = False\n",
    "if quick_easy_settings:\n",
    "    k_fold_partition_size = 170\n",
    "    do_every_nth_pca_comp = 8\n",
    "else:\n",
    "    k_fold_partition_size = 10\n",
    "    do_every_nth_pca_comp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(111 * \"TEMP | \")\n",
    "# do_every_nth_pca_comp = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_features_targets = get_df_features_targets()\n",
    "\n",
    "# #########################################################\n",
    "df_seoin = get_df_features_targets_seoin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine mine and Seoin's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_seoin_data:\n",
    "    # Replace multiindex with index of tuples so that my data and Seoin's data can be combined\n",
    "    indices = df_features_targets.index.tolist()\n",
    "    df_features_targets.index = indices\n",
    "\n",
    "    indices = df_seoin.index.tolist()\n",
    "    df_seoin.index = indices\n",
    "\n",
    "    # Remove columns that aren't shared by my and Seoin's data\n",
    "    cols_0 =df_features_targets.columns.tolist()\n",
    "    cols_1 = df_seoin.columns.tolist()\n",
    "\n",
    "    cols_comb = cols_0 + cols_1\n",
    "\n",
    "    cols_comb_unique = []\n",
    "    for col_i in cols_comb:\n",
    "        if col_i not in cols_comb_unique:\n",
    "            cols_comb_unique.append(col_i)\n",
    "\n",
    "    shared_cols = []\n",
    "    for col_i in cols_comb_unique:\n",
    "        if col_i in df_features_targets.columns and col_i in df_seoin.columns:\n",
    "            shared_cols.append(col_i)\n",
    "\n",
    "    # Combine data\n",
    "    df_data = pd.concat([\n",
    "        df_features_targets[shared_cols],\n",
    "        df_seoin[shared_cols],\n",
    "        ], axis=0)\n",
    "else:\n",
    "    df_data = df_features_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(222 * \"TEMP | \")\n",
    "\n",
    "# df_data = df_data[df_data.data.stoich == \"AB3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.columns.tolist()\n",
    "\n",
    "# features_pre_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data[[\n",
    "\n",
    "#     # ('targets', 'g_o', ''),\n",
    "#     ('targets', 'g_oh', ''),\n",
    "\n",
    "#     ('data', 'stoich', ''),\n",
    "#     ('data', 'job_id_o', ''),\n",
    "#     ('data', 'job_id_oh', ''),\n",
    "#     ('data', 'job_id_bare', ''),\n",
    "\n",
    "#     # ('features', 'o', 'O_magmom'),\n",
    "#     # ('features', 'o', 'Ir_magmom'),\n",
    "#     # ('features', 'o', 'Ir*O_bader'),\n",
    "#     # ('features', 'o', 'Ir_bader'),\n",
    "#     # ('features', 'o', 'O_bader'),\n",
    "\n",
    "#     ('features', 'o', 'active_o_metal_dist'),\n",
    "#     ('features', 'o', 'angle_O_Ir_surf_norm'),\n",
    "#     ('features', 'o', 'ir_o_mean'),\n",
    "#     ('features', 'o', 'ir_o_std'),\n",
    "#     ('features', 'o', 'octa_vol'),\n",
    "#     ('features', 'o', 'p_band_center'),\n",
    "#     ('features', 'o', 'Ir*O_bader/ir_o_mean'),\n",
    "#     ('features', 'dH_bulk', ''),\n",
    "#     ('features', 'volume_pa', ''),\n",
    "#     ('features', 'bulk_oxid_state', ''),\n",
    "#     ('features', 'effective_ox_state', ''),\n",
    "#     # ('features', 'surf_area', ''),\n",
    "\n",
    "#     # ('features_pre_dft', 'active_o_metal_dist__pre', ''),\n",
    "#     # ('features_pre_dft', 'ir_o_mean__pre', ''),\n",
    "#     # ('features_pre_dft', 'ir_o_std__pre', ''),\n",
    "#     # ('features_pre_dft', 'octa_vol__pre', ''),\n",
    "\n",
    "#     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data[[\n",
    "#     # ('targets', 'g_o', ''),\n",
    "#     ('targets', 'g_oh', ''),\n",
    "#     # ('targets', 'e_o', ''),\n",
    "#     # ('targets', 'e_oh', ''),\n",
    "#     # ('targets', 'g_o_m_oh', ''),\n",
    "#     # ('targets', 'e_o_m_oh', ''),\n",
    "\n",
    "#     # ('data', 'active_site', ''),\n",
    "#     # ('data', 'compenv', ''),\n",
    "#     # ('data', 'slab_id', ''),\n",
    "#     # ('data', 'active_site_orig__o', ''),\n",
    "#     # ('data', 'active_site_orig__oh', ''),\n",
    "#     # ('data', 'ads__o', ''),\n",
    "#     # ('data', 'ads__oh', ''),\n",
    "#     # ('data', 'att_num__o', ''),\n",
    "#     # ('data', 'att_num__oh', ''),\n",
    "#     # ('data', 'found_active_Ir__o', ''),\n",
    "#     # ('data', 'found_active_Ir__oh', ''),\n",
    "#     # ('data', 'from_oh__o', ''),\n",
    "#     # ('data', 'from_oh__oh', ''),\n",
    "#     # ('data', 'job_id_max__o', ''),\n",
    "#     # ('data', 'job_id_max__oh', ''),\n",
    "#     # ('data', 'num_missing_Os__o', ''),\n",
    "#     # ('data', 'num_missing_Os__oh', ''),\n",
    "#     # ('data', 'orig_slab_good__o', ''),\n",
    "#     # ('data', 'orig_slab_good__oh', ''),\n",
    "#     # ('data', 'used_unrelaxed_df_coord__o', ''),\n",
    "#     # ('data', 'used_unrelaxed_df_coord__oh', ''),\n",
    "#     # ('data', 'job_id_o', ''),\n",
    "#     # ('data', 'job_id_oh', ''),\n",
    "#     # ('data', 'job_id_bare', ''),\n",
    "#     # ('data', 'all_done', ''),\n",
    "#     # ('data', 'any_bare_done', ''),\n",
    "#     # ('data', 'any_oh_done', ''),\n",
    "#     # ('data', 'any_o_done', ''),\n",
    "#     # ('data', 'any_o_w_as_done', ''),\n",
    "#     # ('data', 'low_e_not_from_oh__o', ''),\n",
    "#     # ('data', 'low_e_not_from_oh__bare', ''),\n",
    "#     # ('data', 'phase', ''),\n",
    "#     # ('data', 'stoich', ''),\n",
    "#     # ('data', 'name_str', ''),\n",
    "#     # ('data', 'sum_norm_abs_magmom_diff', ''),\n",
    "#     # ('data', 'norm_sum_norm_abs_magmom_diff', ''),\n",
    "#     # ('data', 'overpot', ''),\n",
    "#     # ('data', 'lim_step', ''),\n",
    "#     # ('data', 'lim_step_str', ''),\n",
    "#     # ('data', 'lim_step_num', ''),\n",
    "#     # ('data', 'SE__area_J_m2', ''),\n",
    "#     # ('data', 'num_nonstoich_O', ''),\n",
    "#     # ('data', 'N_stoich_units', ''),\n",
    "#     # ('format', 'color', 'stoich'),\n",
    "#     # ('format', 'color', 'norm_sum_norm_abs_magmom_diff'),\n",
    "\n",
    "#     # ('features', 'oh', 'O_magmom'),\n",
    "#     # ('features', 'oh', 'Ir_magmom'),\n",
    "#     # ('features', 'oh', 'active_o_metal_dist'),\n",
    "#     # ('features', 'oh', 'angle_O_Ir_surf_norm'),\n",
    "#     # ('features', 'oh', 'closest_Ir_dist'),\n",
    "#     # ('features', 'oh', 'closest_O_dist'),\n",
    "#     # ('features', 'oh', 'ir_o_mean'),\n",
    "#     # ('features', 'oh', 'ir_o_std'),\n",
    "#     # ('features', 'oh', 'octa_vol'),\n",
    "#     # ('features', 'oh', 'oxy_opp_as_bl'),\n",
    "#     # ('features', 'oh', 'degrees_off_of_straight__as_opp'),\n",
    "#     # ('features', 'oh', 'as_ir_opp_bl_ratio'),\n",
    "\n",
    "#     # ('features', 'o', 'O_magmom'),\n",
    "#     # ('features', 'o', 'Ir_magmom'),\n",
    "#     # ('features', 'o', 'Ir*O_bader'),\n",
    "#     # ('features', 'o', 'Ir_bader'),\n",
    "#     # ('features', 'o', 'O_bader'),\n",
    "#     # ('features', 'o', 'p_band_center'),\n",
    "#     # ('features', 'o', 'Ir*O_bader/ir_o_mean'),\n",
    "\n",
    "#     ('features', 'o', 'active_o_metal_dist'),\n",
    "#     ('features', 'o', 'angle_O_Ir_surf_norm'),\n",
    "#     ('features', 'o', 'closest_Ir_dist'),\n",
    "#     ('features', 'o', 'closest_O_dist'),\n",
    "#     ('features', 'o', 'ir_o_mean'),\n",
    "#     ('features', 'o', 'ir_o_std'),\n",
    "#     ('features', 'o', 'octa_vol'),\n",
    "#     ('features', 'o', 'oxy_opp_as_bl'),\n",
    "#     ('features', 'o', 'degrees_off_of_straight__as_opp'),\n",
    "#     ('features', 'o', 'as_ir_opp_bl_ratio'),\n",
    "\n",
    "#     ('features', 'dH_bulk', ''),\n",
    "#     ('features', 'volume_pa', ''),\n",
    "#     ('features', 'bulk_oxid_state', ''),\n",
    "#     ('features', 'effective_ox_state', ''),\n",
    "#     ('features', 'surf_area', ''),\n",
    "\n",
    "#     ('features_pre_dft', 'active_o_metal_dist__pre', ''),\n",
    "#     ('features_pre_dft', 'ir_o_mean__pre', ''),\n",
    "#     ('features_pre_dft', 'ir_o_std__pre', ''),\n",
    "#     ('features_pre_dft', 'octa_vol__pre', ''),\n",
    "#     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data[[\n",
    "    ('targets', 'g_o', ''),\n",
    "    # ('targets', 'g_oh', ''),\n",
    "    ('data', 'job_id_o', ''),\n",
    "    ('data', 'job_id_oh', ''),\n",
    "    ('data', 'job_id_bare', ''),\n",
    "    ('data', 'stoich', ''),\n",
    "    ('features', 'o', 'active_o_metal_dist'),\n",
    "    ('features', 'o', 'ir_o_mean'),\n",
    "    ('features', 'o', 'octa_vol'),\n",
    "    ('features', 'o', 'oxy_opp_as_bl'),\n",
    "    ('features', 'o', 'degrees_off_of_straight__as_opp'),\n",
    "    ('features', 'dH_bulk', ''),\n",
    "    ('features', 'bulk_oxid_state', ''),\n",
    "    ('features', 'effective_ox_state', ''),\n",
    "    ('features_pre_dft', 'active_o_metal_dist__pre', ''),\n",
    "    ('features_pre_dft', 'ir_o_mean__pre', ''),\n",
    "    ('features_pre_dft', 'ir_o_std__pre', ''),\n",
    "    ('features_pre_dft', 'octa_vol__pre', ''),\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods_models import Decision_Tree_Regression\n",
    "\n",
    "DT_R = Decision_Tree_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "1\n",
      "MAE: 0.3888\n",
      "MA.r2: 0.3164\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "2\n",
      "MAE: 0.3524\n",
      "MA.r2: 0.3548\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "3\n",
      "MAE: 0.2853\n",
      "MA.r2: 0.5945\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "4\n",
      "MAE: 0.2843\n",
      "MA.r2: 0.6095\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "5\n",
      "MAE: 0.2818\n",
      "MA.r2: 0.5813\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "6\n",
      "MAE: 0.2841\n",
      "MA.r2: 0.5924\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "7\n",
      "MAE: 0.2794\n",
      "MA.r2: 0.6079\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "****************************************\n",
      "8\n",
      "MAE: 0.2606\n",
      "MA.r2: 0.6413\n",
      "MAE (in_fold): 0.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8 PCA components are ideal with an MAE of 0.2606\n"
     ]
    }
   ],
   "source": [
    "data_dict_list = []\n",
    "num_feat_cols = df_data.features.shape[1]\n",
    "# for num_pca_i in range(1, num_feat_cols + 1, do_every_nth_pca_comp):\n",
    "for num_pca_i in range(1 , num_feat_cols + 1, do_every_nth_pca_comp):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(40 * \"*\")\n",
    "        print(num_pca_i)\n",
    "\n",
    "    MA = ModelAgent(\n",
    "        df_features_targets=df_data,\n",
    "        Regression=DT_R,\n",
    "        Regression_class=Decision_Tree_Regression,\n",
    "        use_pca=True,\n",
    "        num_pca=num_pca_i,\n",
    "        adsorbates=adsorbates,\n",
    "        stand_targets=False,  # True was giving much worse errors, keep False\n",
    "        )\n",
    "\n",
    "    MA.run_kfold_cv_workflow(\n",
    "        k_fold_partition_size=k_fold_partition_size,\n",
    "        )\n",
    "\n",
    "    if MA.can_run:\n",
    "        if verbose:\n",
    "            print(\"MAE:\", np.round(MA.mae, 4))\n",
    "            print(\"MA.r2:\", np.round(MA.r2, 4))\n",
    "            print(\"MAE (in_fold):\", np.round(MA.mae_infold, 4))\n",
    "\n",
    "    data_dict_i = dict()\n",
    "    data_dict_i[\"num_pca\"] = num_pca_i\n",
    "    data_dict_i[\"MAE\"] = MA.mae\n",
    "    data_dict_i[\"ModelAgent\"] = MA\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "df_models = pd.DataFrame(data_dict_list)\n",
    "df_models = df_models.set_index(\"num_pca\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "# Finding best performing model\n",
    "row_models_i = df_models.sort_values(\"MAE\").iloc[0]\n",
    "\n",
    "MA_best = row_models_i.ModelAgent\n",
    "\n",
    "print(4 * \"\\n\")\n",
    "if verbose:\n",
    "    print(\n",
    "        row_models_i.name,\n",
    "        \" PCA components are ideal with an MAE of \",\n",
    "        np.round(\n",
    "        row_models_i.MAE,\n",
    "            4),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 PCA components are ideal with an MAE of 0.1703\n",
    "# 11 PCA components are ideal with an MAE of 0.171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods_models import ModelAgent_Plotter\n",
    "\n",
    "MA_Plot = ModelAgent_Plotter(\n",
    "    ModelAgent=MA_best,\n",
    "    layout_shared=layout_shared,\n",
    "    )\n",
    "\n",
    "MA_Plot.plot_residuals()\n",
    "MA_Plot.plot_parity()\n",
    "MA_Plot.plot_parity_infold()\n",
    "\n",
    "# # Uncomment to run pca analysis on in-fold regression\n",
    "# MA.run_pca_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MA_Plot.plot_residuals__PLT\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MA_Plot.plot_parity__PLT\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MA_Plot.plot_parity_infold__PLT\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods_models import plot_mae_vs_pca\n",
    "plot_mae_vs_pca(\n",
    "    df_models=df_models,\n",
    "    layout_shared=layout_shared,\n",
    "    scatter_marker_props=scatter_marker_props,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting cinv matrix of GP model to save disk space\n",
    "\n",
    "for num_pca, row_i in df_models.iterrows():\n",
    "    MA = row_i.ModelAgent\n",
    "    MA.cleanup_for_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_out = {\n",
    "    \"df_models\": df_models,\n",
    "    \"ModelAgent_Plot\": MA_Plot,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(root_dir, \"out_data\")\n",
    "print(directory)\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"modelling_data_NEW_88.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(data_dict_out, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"model__mine_GP.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
