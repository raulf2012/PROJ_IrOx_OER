{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing linear model for OER adsorption energies\n",
    "---\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import scatter_marker_props, layout_shared\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import run_linear_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/model_building\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "from methods_model_building import (\n",
    "    simplify_df_features_targets,\n",
    "    run_kfold_cv_wf,\n",
    "    process_feature_targets_df,\n",
    "    process_pca_analysis,\n",
    "    pca_analysis,\n",
    "    run_regression_wf,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = [\n",
    "    'active_o_metal_dist',\n",
    "    'effective_ox_state',\n",
    "    'ir_o_mean',\n",
    "    'ir_o_std',\n",
    "    'octa_vol',\n",
    "    'dH_bulk',\n",
    "    'volume_pa',\n",
    "    'bulk_oxid_state',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_features_targets\n",
    "df_features_targets = get_df_features_targets()\n",
    "\n",
    "from methods import get_df_slab\n",
    "df_slab = get_df_slab()\n",
    "\n",
    "# #########################################################\n",
    "df_i = df_features_targets\n",
    "\n",
    "# Getting phase > 1 slab ids\n",
    "df_slab_i = df_slab[df_slab.phase > 1]\n",
    "phase_2_slab_ids = df_slab_i.slab_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping phase 1 slabs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_i.index.to_frame()\n",
    "df_index_i = df_index[\n",
    "    df_index.slab_id.isin(phase_2_slab_ids)\n",
    "    ]\n",
    "\n",
    "if verbose:\n",
    "    print(\"Dropping phase 1 slabs\")\n",
    "df_i = df_i.loc[\n",
    "    df_index_i.index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj_data import layout_shared\n",
    "\n",
    "# layout_master = layout_shared.update(layout)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G_O Model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# target_ads_i = \"o\"\n",
    "\n",
    "target_ads_i = \"oh\"\n",
    "feature_ads_i = \"oh\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j = simplify_df_features_targets(\n",
    "    df_i,\n",
    "    target_ads=\"o\",\n",
    "    feature_ads=\"oh\",\n",
    "    )\n",
    "\n",
    "df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for num_pca_i in range(1, len(cols_to_use) + 1, 1):\n",
    "# for num_pca_i in range(1, 4, 1):\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(40 * \"*\")\n",
    "        print(num_pca_i)\n",
    "\n",
    "    out_dict = run_kfold_cv_wf(\n",
    "        # #################################\n",
    "        df_features_targets=df_j,\n",
    "        cols_to_use=cols_to_use,\n",
    "        df_format=df_format,\n",
    "        # #################################\n",
    "        num_pca_comp=num_pca_i,\n",
    "        k_fold_partition_size=20,\n",
    "        model_workflow=run_linear_workflow,\n",
    "        # #################################\n",
    "        )\n",
    "\n",
    "    df_target_pred = out_dict[\"df_target_pred\"]\n",
    "    MAE = out_dict[\"MAE\"]\n",
    "    R2 = out_dict[\"R2\"]\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"MAE: \",\n",
    "            np.round(MAE, 5),\n",
    "            \" eV\",\n",
    "            sep=\"\")\n",
    "\n",
    "        print(\n",
    "            \"R2: \",\n",
    "            np.round(R2, 5),\n",
    "            sep=\"\")\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    data_dict_i[\"df_target_pred\"] = df_target_pred\n",
    "    data_dict_i[\"MAE\"] = MAE\n",
    "    data_dict_i[\"R2\"] = R2\n",
    "    # #####################################################\n",
    "    data_dict[num_pca_i] = data_dict_i\n",
    "    # #####################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| - READ WRITE TEMP OBJ\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# # Pickling data ###########################################\n",
    "# import os; import pickle\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"HOME\"],\n",
    "#     \"__temp__\",\n",
    "#     \"temp.pickle\")\n",
    "# with open(path_i, \"wb\") as fle:\n",
    "#     pickle.dump(data_dict, fle)\n",
    "# # #########################################################\n",
    "\n",
    "# # #########################################################\n",
    "# import pickle; import os\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"HOME\"],\n",
    "#     \"__temp__\",\n",
    "#     \"temp.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     data_dict = pickle.load(fle)\n",
    "# # #########################################################\n",
    "\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for num_pca_i, dict_i in data_dict.items():\n",
    "\n",
    "    MAE_i = dict_i[\"MAE\"]\n",
    "    R2_i = dict_i[\"R2\"]\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    data_dict_i[\"num_pca\"] = num_pca_i\n",
    "    data_dict_i[\"MAE\"] = MAE_i\n",
    "    data_dict_i[\"R2\"] = R2_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "# #########################################################\n",
    "df = pd.DataFrame(data_dict_list)\n",
    "df = df.set_index(\"num_pca\")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=False,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=dict(\n",
    "            text=\"K-Fold Cross Validated MAE\",\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=dict(\n",
    "            text=\"Num PCA Components\",\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared_i = layout_shared.update(layout_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_marker_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_i = go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df.MAE,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        # **scatter_marker_props,\n",
    "        ),\n",
    "    )\n",
    "trace_i.marker.update(\n",
    "    scatter_marker_props\n",
    "    )\n",
    "\n",
    "data = [trace_i, ]\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=data,\n",
    "    layout=layout_shared_i,\n",
    "    )\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the best model (optimal num PCA components)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pca_best = 3\n",
    "num_pca_best = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_i = data_dict[\n",
    "    num_pca_best\n",
    "    ]\n",
    "\n",
    "df_target_pred = data_dict_i[\"df_target_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()\n",
    "\n",
    "dd = 0.1\n",
    "\n",
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=False,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Simulated \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Predicted \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared_i = layout_shared.update(layout_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_parity = go.Scatter(\n",
    "    y=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    x=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    mode=\"lines\",\n",
    "    line_color=\"black\",\n",
    "    )\n",
    "\n",
    "trace = go.Scatter(\n",
    "    y=df_target_pred[\"y\"],\n",
    "    x=df_target_pred[\"y_pred\"],\n",
    "    mode=\"markers\",\n",
    "    opacity=0.8,\n",
    "\n",
    "    marker=dict(\n",
    "        # color=df_target_pred[\"color\"],\n",
    "        # **scatter_marker_props,\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "data = [trace_parity, trace, ]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout_shared_i)\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_target_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-fold model (trained on all data, no test/train split)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = run_regression_wf(\n",
    "    df_features_targets=df_j,\n",
    "    cols_to_use=cols_to_use,\n",
    "    df_format=df_format,\n",
    "    num_pca_comp=num_pca_best,\n",
    "    model_workflow=run_linear_workflow,\n",
    "    )\n",
    "\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print(\"MAE:\", MAE)\n",
    "    print(\"R2:\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = df_target_pred[[\"y\", \"y_pred\"]].max().max()\n",
    "min_val = df_target_pred[[\"y\", \"y_pred\"]].min().min()\n",
    "\n",
    "dd = 0.1\n",
    "\n",
    "layout_mine = go.Layout(\n",
    "\n",
    "    showlegend=False,\n",
    "\n",
    "    yaxis=go.layout.YAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Simulated \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        range=[min_val - dd, max_val + dd],\n",
    "        title=dict(\n",
    "            text=\"Predicted \u0394G<sub>*{}</sub>\".format(feature_ads_i.upper()),\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "layout_shared_i = layout_shared.update(layout_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_parity = go.Scatter(\n",
    "    y=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    x=[min_val - 2 * dd, max_val + 2 * dd],\n",
    "    mode=\"lines\",\n",
    "    line_color=\"black\",\n",
    "    )\n",
    "\n",
    "trace = go.Scatter(\n",
    "    y=df_target_pred[\"y\"],\n",
    "    x=df_target_pred[\"y_pred\"],\n",
    "    mode=\"markers\",\n",
    "    opacity=0.8,\n",
    "\n",
    "    marker=dict(\n",
    "        # color=df_target_pred[\"color\"],\n",
    "        # **scatter_marker_props,\n",
    "        **scatter_marker_props.to_plotly_json(),\n",
    "        ),\n",
    "\n",
    "    )\n",
    "\n",
    "data = [trace_parity, trace, ]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout_shared_i)\n",
    "if show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"linear_model.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# from local_methods import process_feature_targets_df, process_pca_analysis, run_regression_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_test_targets[\"y_pred\"] = \n",
    "\n",
    "# y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_features_targets=df_j\n",
    "# cols_to_use=cols_to_use\n",
    "# df_format=df_format\n",
    "# run_pca=True\n",
    "# num_pca_comp=3\n",
    "# k_fold_partition_size=100\n",
    "# model_workflow=run_linear_workflow\n",
    "\n",
    "# # def run_kfold_cv_wf(\n",
    "# #     df_features_targets=None,\n",
    "# #     cols_to_use=None,\n",
    "# #     df_format=None,\n",
    "\n",
    "# #     run_pca=True,\n",
    "# #     num_pca_comp=3,\n",
    "# #     k_fold_partition_size=20,\n",
    "# #     model_workflow=None,\n",
    "# #     model_settings=None,\n",
    "# #     # kdict=None,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "\n",
    "# df_features_targets\n",
    "\n",
    "#     Column levels are as follows:\n",
    "\n",
    "#     features                         targets\n",
    "#     feat_0    feat_1    feat_2...    g_oh\n",
    "\n",
    "# \"\"\"\n",
    "# #| -  run_kfold_cv_wf\n",
    "# # df_j = df_features_targets\n",
    "\n",
    "# # df_j = process_feature_targets_df(\n",
    "# #     df_features_targets=df_features_targets,\n",
    "# #     cols_to_use=cols_to_use,\n",
    "# #     )\n",
    "\n",
    "# # df_j = df_j.dropna()\n",
    "\n",
    "# # # COMBAK New line\n",
    "# # # print(17 * \"TEMP | \")\n",
    "# # df_j = df_j.dropna(axis=1)\n",
    "\n",
    "# # # print(df_j)\n",
    "\n",
    "# # if run_pca:\n",
    "# #     # #####################################################\n",
    "# #     # df_pca = process_pca_analysis(\n",
    "# #     out_dict = process_pca_analysis(\n",
    "# #         df_features_targets=df_j,\n",
    "# #         num_pca_comp=num_pca_comp,\n",
    "# #         )\n",
    "# #     # #####################################################\n",
    "# #     df_pca = out_dict[\"df_pca\"]\n",
    "# #     pca = out_dict[\"pca\"]\n",
    "# #     # #####################################################\n",
    "\n",
    "# #     df_data = df_pca\n",
    "# # else:\n",
    "# #     df_data = df_j\n",
    "# #     pca = None\n",
    "\n",
    "\n",
    "# # #| - Creating k-fold partitions\n",
    "# # x = df_j.index.tolist()\n",
    "\n",
    "# # partitions = []\n",
    "# # for i in range(0, len(x), k_fold_partition_size):\n",
    "# #     slice_item = slice(i, i + k_fold_partition_size, 1)\n",
    "# #     partitions.append(x[slice_item])\n",
    "# # #__|\n",
    "\n",
    "# # #| - Run k-fold cross-validation\n",
    "# # df_target_pred_parts = []\n",
    "# # df_target_pred_parts_2 = []\n",
    "# # regression_model_list = []\n",
    "# # for k_cnt, part_k in enumerate(range(len(partitions))):\n",
    "\n",
    "# #     test_partition = partitions[part_k]\n",
    "\n",
    "# #     train_partition = partitions[0:part_k] + partitions[part_k + 1:]\n",
    "# #     train_partition = [item for sublist in train_partition for item in sublist]\n",
    "\n",
    "\n",
    "# #     # #####################################################\n",
    "# #     # df_test = df_pca.loc[test_partition]\n",
    "# #     # df_train = df_pca.loc[train_partition]\n",
    "# #     df_test = df_data.loc[test_partition]\n",
    "# #     df_train = df_data.loc[train_partition]\n",
    "# #     # #####################################################\n",
    "# #     df_train_features = df_train[\"features\"]\n",
    "# #     df_train_targets = df_train[\"targets\"]\n",
    "# #     df_test_features = df_test[\"features\"]\n",
    "# #     df_test_targets = df_test[\"targets\"]\n",
    "# #     # #####################################################\n",
    "\n",
    "# #     # #####################################################\n",
    "# #     # Using the model on the test set (Normal)\n",
    "# #     # #####################################################\n",
    "# #     out_dict = model_workflow(\n",
    "# #         df_train_features=df_train_features,\n",
    "# #         df_train_targets=df_train_targets,\n",
    "# #         df_test_features=df_test_features,\n",
    "# #         df_test_targets=df_test_targets,\n",
    "# #         model_settings=model_settings,\n",
    "# #         )\n",
    "# #     # #####################################################\n",
    "# #     df_target_pred = out_dict[\"df_target_pred\"]\n",
    "# #     min_val = out_dict[\"min_val\"]\n",
    "# #     max_val = out_dict[\"max_val\"]\n",
    "# #     RM_1 = out_dict[\"RegressionModel\"]\n",
    "# #     # #####################################################\n",
    "\n",
    "# #     regression_model_list.append(RM_1)\n",
    "\n",
    "# #     # #####################################################\n",
    "# #     # Using the model on the training set (check for bad model)\n",
    "# #     # #####################################################\n",
    "# #     out_dict_2 = model_workflow(\n",
    "# #         df_train_features=df_train_features,\n",
    "# #         df_train_targets=df_train_targets,\n",
    "# #         df_test_features=df_train_features,\n",
    "# #         df_test_targets=df_train_targets,\n",
    "# #         model_settings=model_settings,\n",
    "# #         # kdict=kdict,\n",
    "# #         )\n",
    "# #     # #####################################################\n",
    "# #     df_target_pred_2 = out_dict_2[\"df_target_pred\"]\n",
    "# #     min_val_2 = out_dict_2[\"min_val\"]\n",
    "# #     max_val_2 = out_dict_2[\"max_val\"]\n",
    "# #     RM_2 = out_dict_2[\"RegressionModel\"]\n",
    "# #     # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #     df_target_pred_parts.append(df_target_pred)\n",
    "# #     df_target_pred_parts_2.append(df_target_pred_2)\n",
    "\n",
    "# # # #########################################################\n",
    "# # df_target_pred_concat = pd.concat(df_target_pred_parts)\n",
    "# # df_target_pred = df_target_pred_concat\n",
    "\n",
    "# # # Get format column from main `df_features_targets` dataframe\n",
    "\n",
    "# # # df_features_targets[\"format\"][\"color\"][\"stoich\"]\n",
    "# # # df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]\n",
    "\n",
    "# # # df_format.name = \"color\"\n",
    "# # #\n",
    "# # # # Combining model output and target values\n",
    "# # # df_target_pred = pd.concat([\n",
    "# # #     df_format,\n",
    "# # #     df_target_pred,\n",
    "# # #     ], axis=1)\n",
    "\n",
    "# # df_target_pred = df_target_pred.dropna()\n",
    "# # # #########################################################\n",
    "\n",
    "\n",
    "# # # #########################################################\n",
    "# # df_target_pred_concat_2 = pd.concat(df_target_pred_parts_2)\n",
    "# # df_target_pred_2 = df_target_pred_concat_2\n",
    "\n",
    "# # # Get format column from main `df_features_targets` dataframe\n",
    "\n",
    "# # # df_features_targets[\"format\"][\"color\"][\"stoich\"]\n",
    "# # # df_format = df_features_targets[(\"format\", \"color\", \"stoich\", )]\n",
    "\n",
    "# # # df_format.name = \"color\"\n",
    "\n",
    "# # # # Combining model output and target values\n",
    "# # # df_target_pred_2 = pd.concat([\n",
    "# # #     df_format,\n",
    "# # #     df_target_pred_2,\n",
    "# # #     ], axis=1)\n",
    "\n",
    "# # # new_col_list = []\n",
    "# # # for name_i, row_i in df_target_pred_2.iterrows():\n",
    "# # #     color_i = df_format.loc[row_i.name]\n",
    "# # #     new_col_list.append(color_i)\n",
    "# # #\n",
    "# # # df_target_pred_2[\"color\"] = new_col_list\n",
    "\n",
    "\n",
    "# # df_target_pred_2 = df_target_pred_2.dropna()\n",
    "# # df_target_pred_2 = df_target_pred_2.sort_index()\n",
    "# # # #########################################################\n",
    "\n",
    "# # #__|\n",
    "\n",
    "# # # Calc MAE\n",
    "# # MAE = df_target_pred[\"diff_abs\"].sum() / df_target_pred[\"diff\"].shape[0]\n",
    "\n",
    "# # MAE_2 = df_target_pred_2[\"diff_abs\"].sum() / df_target_pred_2[\"diff\"].shape[0]\n",
    "\n",
    "\n",
    "# # # Calc R2\n",
    "# # from sklearn.metrics import r2_score\n",
    "# # coefficient_of_dermination = r2_score(\n",
    "# #     df_target_pred[\"y\"],\n",
    "# #     df_target_pred[\"y_pred\"],\n",
    "# #     )\n",
    "\n",
    "\n",
    "# # # #####################################################\n",
    "# # out_dict = dict()\n",
    "# # # #####################################################\n",
    "# # out_dict[\"df_target_pred\"] = df_target_pred\n",
    "# # out_dict[\"MAE\"] = MAE\n",
    "# # out_dict[\"R2\"] = coefficient_of_dermination\n",
    "# # out_dict[\"pca\"] = pca\n",
    "# # out_dict[\"regression_model_list\"] = regression_model_list\n",
    "\n",
    "# # out_dict[\"df_target_pred_on_train\"] = df_target_pred_2\n",
    "# # out_dict[\"MAE_pred_on_train\"] = MAE_2\n",
    "# # out_dict[\"RM_2\"] = RM_2\n",
    "# # # #####################################################\n",
    "# # # return(out_dict)\n",
    "# # # #####################################################\n",
    "# # # __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_features_targets=df_features_targets\n",
    "# cols_to_use=cols_to_use\n",
    "\n",
    "\n",
    "# # def process_feature_targets_df(\n",
    "# #     df_features_targets=None,\n",
    "# #     cols_to_use=None,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# #| - process_feature_targets_df\n",
    "# df_j = df_features_targets\n",
    "\n",
    "# #| - Controlling feature columns to use\n",
    "# cols_to_keep = []\n",
    "# cols_to_drop = []\n",
    "# for col_i in df_j[\"features\"].columns:\n",
    "#     if col_i in cols_to_use:\n",
    "#         cols_to_keep.append((\"features\", col_i))\n",
    "#     else:\n",
    "#         cols_to_drop.append((\"features\", col_i))\n",
    "\n",
    "# df_j = df_j.drop(columns=cols_to_drop)\n",
    "# #__|\n",
    "\n",
    "# # | - Changing target column name to `y`\n",
    "# new_cols = []\n",
    "# for col_i in df_j.columns:\n",
    "#     tmp = 42\n",
    "\n",
    "#     if col_i[0] == \"targets\":\n",
    "#         col_new_i = (\"targets\", \"y\")\n",
    "#         new_cols.append(col_new_i)\n",
    "#     else:\n",
    "#         new_cols.append(col_i)\n",
    "\n",
    "# df_j.columns = pd.MultiIndex.from_tuples(new_cols)\n",
    "# #__|\n",
    "\n",
    "# # Splitting dataframe into features and targets dataframe\n",
    "# df_feat = df_j[\"features\"]\n",
    "\n",
    "\n",
    "# # Standardizing features\n",
    "# df_feat = (df_feat - df_feat.mean()) / df_feat.std()\n",
    "# df_j[\"features\"] = df_feat\n",
    "\n",
    "\n",
    "# # # #####################################################\n",
    "# # df_feat_pca = pca_analysis(\n",
    "# #     df_j[\"features\"],\n",
    "# #     pca_mode=\"num_comp\",  # 'num_comp' or 'perc'\n",
    "# #     pca_comp=num_pca_comp,\n",
    "# #     verbose=False,\n",
    "# #     )\n",
    "# #\n",
    "# # cols_new = []\n",
    "# # for col_i in df_feat_pca.columns:\n",
    "# #     col_new_i = (\"features\", col_i)\n",
    "# #     cols_new.append(col_new_i)\n",
    "# # df_feat_pca.columns = pd.MultiIndex.from_tuples(cols_new)\n",
    "# #\n",
    "# # df_pca = pd.concat([\n",
    "# #     df_feat_pca,\n",
    "# #     df_j[[\"targets\"]],\n",
    "# #     ], axis=1)\n",
    "\n",
    "# return(df_j)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # df_j[\"features\"]\n",
    "\n",
    "# df_j.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# cols_to_keep = []\n",
    "# cols_to_drop = []\n",
    "# for col_i in df_j[\"features\"].columns:\n",
    "#     if col_i in cols_to_use:\n",
    "#         cols_to_keep.append((\"features\", col_i))\n",
    "#     else:\n",
    "#         cols_to_drop.append((\"features\", col_i))\n",
    "\n",
    "# df_j = df_j.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_j"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
