{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# import pickle; import os\n",
    "\n",
    "import pickle\n",
    "import  json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ase import io\n",
    "from ase.visualize import view\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.analysis import local_env\n",
    "\n",
    "# #########################################################\n",
    "from misc_modules.pandas_methods import drop_columns\n",
    "\n",
    "from methods import read_magmom_comp_data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.display.max_colwidth = 20\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_paths,\n",
    "    get_df_dft,\n",
    "    get_df_job_ids,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_data,\n",
    "    get_df_slab,\n",
    "    get_df_slab_ids,\n",
    "    get_df_jobs_data_clusters,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_slabs_oh,\n",
    "    get_df_init_slabs,\n",
    "    get_df_magmoms,\n",
    "    get_df_ads,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_rerun_from_oh,\n",
    "    get_df_slab_simil,\n",
    "    get_df_active_sites,\n",
    "    get_df_features_targets,\n",
    "\n",
    "    get_other_job_ids_in_set,\n",
    "    read_magmom_comp_data,\n",
    "\n",
    "    get_df_coord,\n",
    "    get_df_slabs_to_run,\n",
    "    get_df_features,\n",
    "    )\n",
    "\n",
    "from misc_modules.pandas_methods import reorder_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_dft = get_df_dft()\n",
    "df_job_ids = get_df_job_ids()\n",
    "df_jobs = get_df_jobs(exclude_wsl_paths=True)\n",
    "df_jobs_data = get_df_jobs_data(exclude_wsl_paths=True)\n",
    "df_jobs_data_clusters = get_df_jobs_data_clusters()\n",
    "df_slab = get_df_slab()\n",
    "df_slab_ids = get_df_slab_ids()\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "df_slabs_oh = get_df_slabs_oh()\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "df_magmoms = get_df_magmoms()\n",
    "df_ads = get_df_ads()\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "df_rerun_from_oh = get_df_rerun_from_oh()\n",
    "magmom_data_dict = read_magmom_comp_data()\n",
    "df_slab_simil = get_df_slab_simil()\n",
    "df_active_sites = get_df_active_sites()\n",
    "df_features_targets = get_df_features_targets()\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_features = get_df_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def display_df(df, df_name, display_head=True, num_spaces=3):\n",
    "    print(40 * \"*\")\n",
    "    print(df_name)\n",
    "    print(\"df_i.shape:\", df_i.shape)\n",
    "    print(40 * \"*\")\n",
    "\n",
    "    if display_head:\n",
    "        display(df.head())\n",
    "\n",
    "    print(num_spaces * \"\\n\")\n",
    "\n",
    "df_list = [\n",
    "    (\"df_dft\", df_dft),\n",
    "    (\"df_job_ids\", df_job_ids),\n",
    "    (\"df_jobs\", df_jobs),\n",
    "    (\"df_jobs_data\", df_jobs_data),\n",
    "    (\"df_jobs_data_clusters\", df_jobs_data_clusters),\n",
    "    (\"df_slab\", df_slab),\n",
    "    (\"df_slab_ids\", df_slab_ids),\n",
    "    (\"df_jobs_anal\", df_jobs_anal),\n",
    "    (\"df_jobs_paths\", df_jobs_paths),\n",
    "    (\"df_slabs_oh\", df_slabs_oh),\n",
    "    (\"df_magmoms\", df_magmoms),\n",
    "    (\"df_ads\", df_ads),\n",
    "    (\"df_atoms_sorted_ind\", df_atoms_sorted_ind),\n",
    "    (\"df_rerun_from_oh\", df_rerun_from_oh),\n",
    "    (\"df_slab_simil\", df_slab_simil),\n",
    "    (\"df_active_sites\", df_active_sites),\n",
    "    ]\n",
    "\n",
    "# for name_i, df_i in df_list:\n",
    "#     display_df(df_i, name_i)\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "\n",
    "# for name_i, df_i in df_list:\n",
    "#     display_df(\n",
    "#         df_i,\n",
    "#         name_i,\n",
    "#         display_head=False,\n",
    "#         num_spaces=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting mean for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE *O: 0.527498511550467\n",
      "MAE *Oh: 0.4290922827660661\n"
     ]
    }
   ],
   "source": [
    "g_o_list = df_features_targets[(\"targets\", \"g_o\", \"\", )]\n",
    "\n",
    "g_o_mean = g_o_list.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_o_list - g_o_mean\n",
    "    ).mean()\n",
    "print(\"MAE *O:\", mae_i)\n",
    "\n",
    "\n",
    "g_oh_list = df_features_targets[(\"targets\", \"g_oh\", \"\", )]\n",
    "\n",
    "g_oh_mean = g_oh_list.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_oh_list - g_oh_mean\n",
    "    ).mean()\n",
    "print(\"MAE *OH:\", mae_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab2 = df_features_targets.loc[\n",
    "    df_features_targets[df_features_targets[(\"data\", \"stoich\", \"\")] == \"AB2\"].index\n",
    "    ]\n",
    "\n",
    "df_ab3 = df_features_targets.loc[\n",
    "    df_features_targets[df_features_targets[(\"data\", \"stoich\", \"\")] == \"AB3\"].index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on AB2 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE *O: 0.33371104747369956\n",
      "MAE *OH: 0.26253117155223793\n"
     ]
    }
   ],
   "source": [
    "g_o_list_ab2 = df_ab2[(\"targets\", \"g_o\", \"\", )]\n",
    "\n",
    "g_o_mean_ab2 = g_o_list_ab2.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_o_list_ab2 - g_o_mean_ab2\n",
    "    ).mean()\n",
    "\n",
    "print(\"MAE *O:\", mae_i)\n",
    "\n",
    "\n",
    "g_oh_list_ab2 = df_ab2[(\"targets\", \"g_oh\", \"\", )]\n",
    "\n",
    "g_oh_mean_ab2 = g_oh_list_ab2.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_oh_list_ab2 - g_oh_mean_ab2\n",
    "    ).mean()\n",
    "\n",
    "print(\"MAE *OH:\", mae_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on AB3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE *O: 0.4207576034945268\n",
      "MAE *OH: 0.35405752814141994\n"
     ]
    }
   ],
   "source": [
    "g_o_list_ab3 = df_ab3[(\"targets\", \"g_o\", \"\", )]\n",
    "\n",
    "g_o_mean_ab3 = g_o_list_ab3.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_o_list_ab3 - g_o_mean_ab3\n",
    "    ).mean()\n",
    "\n",
    "print(\"MAE *O:\", mae_i)\n",
    "\n",
    "\n",
    "g_oh_list_ab3 = df_ab3[(\"targets\", \"g_oh\", \"\", )]\n",
    "\n",
    "g_oh_mean_ab3 = g_oh_list_ab3.mean()\n",
    "\n",
    "mae_i = np.absolute(\n",
    "    g_oh_list_ab3 - g_oh_mean_ab3\n",
    "    ).mean()\n",
    "\n",
    "print(\"MAE *OH:\", mae_i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average of the MAE for each eff. ox. state value is equal to the GP MAE for the single feature model with EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*OH \n",
      " MAE: 0.2074 eV\n"
     ]
    }
   ],
   "source": [
    "col_i = (\"features\", \"effective_ox_state\", \"\", )\n",
    "eff_ox_states = list(np.sort(df_features_targets[col_i].unique().tolist()))\n",
    "eff_ox_states = eff_ox_states[:-1]\n",
    "\n",
    "diff_list = []\n",
    "for eff_ox_i in eff_ox_states:\n",
    "    df_i = df_features_targets[\n",
    "        df_features_targets[(\"features\", \"effective_ox_state\", \"\", )] == eff_ox_i]\n",
    "\n",
    "    g_o_list_i = df_i[(\"targets\", \"g_oh\", \"\", )]\n",
    "    g_o_mean_i = g_o_list_i.mean()\n",
    "\n",
    "    mae_i = np.absolute(\n",
    "        g_o_list_i - g_o_mean_i\n",
    "        ).mean()\n",
    "\n",
    "    diff_i = (g_o_list_i - g_o_mean_i).tolist()\n",
    "    diff_list.extend(diff_i)\n",
    "\n",
    "    # if verbose:\n",
    "    if False:\n",
    "        print(\"eff_ox_i:\", np.round(eff_ox_i, 3))\n",
    "        print(\"df_i.shape:\", df_i.shape[0])\n",
    "        print(\"MAE:\", np.round(mae_i, 3))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"*OH\",\n",
    "    \"\\n\",\n",
    "    \"MAE:\",\n",
    "    np.round(\n",
    "        np.mean(np.abs(diff_list)),\n",
    "        4,\n",
    "        ),\n",
    "    \"eV\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*O \n",
      " MAE: 0.2726 eV\n"
     ]
    }
   ],
   "source": [
    "col_i = (\"features\", \"effective_ox_state\", \"\", )\n",
    "eff_ox_states = list(np.sort(df_features_targets[col_i].unique().tolist()))\n",
    "eff_ox_states = eff_ox_states[:-1]\n",
    "\n",
    "diff_list = []\n",
    "for eff_ox_i in eff_ox_states:\n",
    "    df_i = df_features_targets[\n",
    "        df_features_targets[(\"features\", \"effective_ox_state\", \"\", )] == eff_ox_i]\n",
    "\n",
    "    g_o_list_i = df_i[(\"targets\", \"g_o\", \"\", )]\n",
    "    g_o_mean_i = g_o_list_i.mean()\n",
    "\n",
    "    mae_i = np.absolute(\n",
    "        g_o_list_i - g_o_mean_i\n",
    "        ).mean()\n",
    "\n",
    "    diff_i = (g_o_list_i - g_o_mean_i).tolist()\n",
    "    diff_list.extend(diff_i)\n",
    "\n",
    "    # if verbose:\n",
    "    if False:\n",
    "        print(\"eff_ox_i:\", np.round(eff_ox_i, 3))\n",
    "        print(\"df_i.shape:\", df_i.shape[0])\n",
    "        print(\"MAE:\", np.round(mae_i, 3))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"*O\",\n",
    "    \"\\n\",\n",
    "    \"MAE:\",\n",
    "    np.round(\n",
    "        np.mean(np.abs(diff_list)),\n",
    "        4,\n",
    "        ),\n",
    "    \"eV\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_features_targets[(\"features\", \"o\", \"effective_ox_state\")] == eff_ox_i\n",
    "\n",
    "# df_features_targets[(\"features\", \"o\", \"effective_ox_state\")]\n",
    "\n",
    "# df_features_targets[(\"features\", \"effective_ox_state\", \"\", )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# g_o_list_ab3 = df_ab3[(\"targets\", \"g_o\", \"\", )]\n",
    "\n",
    "# g_o_mean_ab3 = g_o_list_ab3.mean()\n",
    "\n",
    "# np.absolute(\n",
    "#     g_o_list_ab3 - g_o_mean_ab3\n",
    "#     ).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
