{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing job sets (everything within a `02_attempt` dir for example)\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "import dictdiffer\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_data,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_paths,\n",
    "    cwd,\n",
    "    )\n",
    "\n",
    "from dft_workflow_methods import (\n",
    "    is_job_understandable,\n",
    "    job_decision,\n",
    "    transfer_job_files_from_old_to_new,\n",
    "    is_job_compl_done,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_no_file_ops = True  # True if just testing around, False for production mode\n",
    "# # TEST_no_file_ops = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "if verbose:\n",
    "    print(\"df_jobs.shape:\", 2 * \"\\t\", df_jobs.shape)\n",
    "\n",
    "df_jobs_data = get_df_jobs_data(drop_cols=False)\n",
    "if verbose:\n",
    "    print(\"df_jobs_data.shape:\", 1 * \"\\t\", df_jobs_data.shape)\n",
    "    \n",
    "df_jobs_paths = get_df_jobs_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "group_cols = [\"compenv\", \"slab_id\", \"att_num\", \"ads\", \"active_site\"]\n",
    "# group_cols = [\"compenv\", \"slab_id\", \"att_num\", ]\n",
    "grouped = df_jobs.groupby(group_cols)\n",
    "max_job_row_list = []\n",
    "data_dict_list = []\n",
    "for name, group in grouped:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    max_job = group[group.rev_num == group.rev_num.max()]\n",
    "    max_job_row_list.append(max_job.iloc[0])\n",
    "\n",
    "    compenv_i = name[0]\n",
    "    slab_id_i = name[1]\n",
    "    att_num_i = name[2]\n",
    "\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"att_num\"] = att_num_i\n",
    "    data_dict_i[\"group_key\"] = name\n",
    "\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "df_max_group_keys = pd.DataFrame(data_dict_list)\n",
    "df_jobs_max = pd.DataFrame(max_job_row_list)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Number of unique jobs :\", df_jobs_max.shape)\n",
    "    print(\"^^ Only counting hightest rev_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering `df_jobs` by rows that are present in `df_jobs_data`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_i = df_jobs.loc[\n",
    "    df_jobs.index.intersection(df_jobs_data.index)\n",
    "    ]\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"These job_ids weren't in df_jobs_data:\",\n",
    "        \"\\n\",\n",
    "        df_jobs.index.difference(df_jobs_data.index).tolist(), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "\n",
    "# print(222 * \"TEST | \")\n",
    "# # ('dos_bader', 'sherlock', 'momaposi_60', 1, 'o', 54.0)\n",
    "\n",
    "# df = df_jobs_i\n",
    "# df = df[\n",
    "#     (df[\"job_type\"] == \"dos_bader\") &\n",
    "#     (df[\"compenv\"] == \"sherlock\") &\n",
    "#     (df[\"slab_id\"] == \"momaposi_60\") &\n",
    "#     (df[\"att_num\"] == 1) &\n",
    "#     (df[\"ads\"] == \"o\") &\n",
    "#     (df[\"active_site\"] == 54.) &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_jobs_i = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "group_cols = [\"job_type\", \"compenv\", \"slab_id\", \"att_num\", \"ads\", \"active_site\"]\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "for name, group in grouped:\n",
    "\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    if verbose:\n",
    "        print(40 * \"#\")\n",
    "        print(\"name:\", name)\n",
    "\n",
    "    # #####################################################\n",
    "    job_type_i = name[0]\n",
    "    compenv_i = name[1]\n",
    "    slab_id = name[2]\n",
    "    att_num = name[3] \n",
    "    ads_i = name[4]\n",
    "    active_site_i = name[5]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    max_job = group[group.rev_num == group.rev_num.max()]\n",
    "    assert max_job.shape[0] == 1, \"Must only have 1 there\"\n",
    "    row_max_i = max_job.iloc[0]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_max_i.job_id\n",
    "    submitted_i = row_max_i.submitted\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_paths_i = df_jobs_paths[df_jobs_paths.compenv == compenv_i]\n",
    "    row_paths_max_i = df_jobs_paths_i.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    path_job_root_w_att_rev = row_paths_max_i.path_job_root_w_att_rev\n",
    "    path_rel_to_proj = row_paths_max_i.path_rel_to_proj\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_data_i = df_jobs_data[df_jobs_data.compenv == compenv_i]\n",
    "    row_data_max_i = df_jobs_data_i.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    timed_out = row_data_max_i.timed_out\n",
    "    completed = row_data_max_i.completed\n",
    "    ediff_conv_reached = row_data_max_i.ediff_conv_reached\n",
    "    brmix_issue = row_data_max_i.brmix_issue\n",
    "    num_nonconv_scf = row_data_max_i.num_nonconv_scf\n",
    "    num_conv_scf = row_data_max_i.num_conv_scf\n",
    "    true_false_ratio = row_data_max_i.true_false_ratio\n",
    "    frac_true = row_data_max_i.frac_true\n",
    "    error = row_data_max_i.error\n",
    "    error_type = row_data_max_i.error_type\n",
    "    job_state = row_data_max_i.job_state\n",
    "    incar_params = row_data_max_i.incar_params\n",
    "    # #####################################################\n",
    "    if incar_params is not None:\n",
    "        ispin = incar_params.get(\"ISPIN\", None)\n",
    "    else:\n",
    "        ispin = None\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    job_completely_done = is_job_compl_done(\n",
    "        ispin=ispin, completed=completed)\n",
    "\n",
    "    # #####################################################\n",
    "    job_understandable = is_job_understandable(\n",
    "        timed_out=timed_out, completed=completed, error=error,\n",
    "        job_state=job_state, )\n",
    "    # #####################################################\n",
    "    job_decision_i = job_decision(\n",
    "        error=error, error_type=error_type,\n",
    "        timed_out=timed_out, completed=completed, submitted=submitted_i,\n",
    "        job_understandable=job_understandable, ediff_conv_reached=ediff_conv_reached,\n",
    "        incar_params=incar_params, brmix_issue=brmix_issue,\n",
    "        num_nonconv_scf=num_nonconv_scf, num_conv_scf=num_conv_scf,\n",
    "        true_false_ratio=true_false_ratio, frac_true=frac_true, job_state=job_state,\n",
    "        job_completely_done=job_completely_done, )\n",
    "    decision_i = job_decision_i[\"decision\"]\n",
    "    dft_params_i = job_decision_i[\"dft_params\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"ads\"] = ads_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    data_dict_i[\"job_understandable\"] = job_understandable\n",
    "    data_dict_i[\"job_type\"] = job_type_i\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id\n",
    "    data_dict_i[\"att_num\"] = att_num\n",
    "    data_dict_i[\"job_id_max\"] = job_id_max_i\n",
    "    data_dict_i[\"path_rel_to_proj\"] = path_rel_to_proj\n",
    "    data_dict_i[\"timed_out\"] = timed_out\n",
    "    data_dict_i[\"completed\"] = completed\n",
    "    data_dict_i[\"brmix_issue\"] = brmix_issue\n",
    "    data_dict_i[\"decision\"] = decision_i\n",
    "    data_dict_i[\"dft_params_new\"] = dft_params_i\n",
    "    data_dict_i[\"job_completely_done\"] = job_completely_done\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal = pd.DataFrame(data_dict_list)\n",
    "# df_jobs_anal = df_jobs_anal.sort_values([\"compenv\", \"slab_id\", \"path_rel_to_proj\"])\n",
    "df_jobs_anal = df_jobs_anal.sort_values(\n",
    "    [\"job_type\", \"compenv\", \"slab_id\", \"path_rel_to_proj\"])\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering `df_jobs_anal` and setting index"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "col_order_list = [\n",
    "    \"compenv\",\n",
    "    \"slab_id\",\n",
    "    \"att_num\",\n",
    "    \"ads\",\n",
    "    \"active_site\",\n",
    "    \"job_id_max\",\n",
    "\n",
    "    \"path_short\",\n",
    "\n",
    "    \"timed_out\",\n",
    "    \"completed\",\n",
    "    \"brmix_issue\",\n",
    "    \"job_understandable\",\n",
    "\n",
    "    \"decision\",\n",
    "    \"dft_params_new\",\n",
    "\n",
    "    \"path_rel_to_proj\",\n",
    "    ]\n",
    "df_jobs_anal = reorder_df_columns(col_order_list, df_jobs_anal)\n",
    "df_jobs_anal = df_jobs_anal.drop(columns=[\"path_rel_to_proj\", ])\n",
    "\n",
    "# #########################################################\n",
    "# Setting index\n",
    "# index_keys = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\"]\n",
    "index_keys = [\"job_type\", \"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\"]\n",
    "df_jobs_anal = df_jobs_anal.set_index(index_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing `df_jobs_anal` to file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_processing/out_data\")\n",
    "file_name_i = \"df_jobs_anal.pickle\"\n",
    "path_i = os.path.join(directory, file_name_i)\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_jobs_anal, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"analyse_jobs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_paths_i = df_jobs_paths[df_jobs_paths.compenv == compenv_i]\n",
    "# row_paths_max_i = df_jobs_paths_i.loc[job_id_max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# compenv_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_paths_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal[df_jobs_anal.job_id_max == \"bisofadi_42\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # row_data_max_iNone\tFalse\n",
    "\n",
    "# df = df_jobs_anal\n",
    "# df = df[\n",
    "#     (df[\"ads\"] == \"oh\") &\n",
    "#     (df[\"active_site\"] == 69) &\n",
    "#     (df[\"att_num\"] == 0) &\n",
    "#     # (df[\"compenv\"] == \"sherlock\") &\n",
    "#     (df[\"slab_id\"] == \"bekusuvu_00\") &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# print(40 * \"TEMP | \")\n",
    "\n",
    "# # name_i = (\"nafupemu_49\", \"o\", 48., 1)\n",
    "# # name_i = (\"relovalu_12\", \"o\", \"NaN\", 1)\n",
    "# # name_i = ('sherlock', 'miforike_08', 1, 'o', 50.0)\n",
    "# name_i = ('miforike_08', 'o', 50.0, 1, )\n",
    "\n",
    "# df = df_jobs_i\n",
    "# df = df[\n",
    "#     (df[\"slab_id\"] == name_i[0]) &\n",
    "#     (df[\"ads\"] == name_i[1]) &\n",
    "#     (df[\"active_site\"] == name_i[2]) &\n",
    "#     (df[\"att_num\"] == name_i[3]) &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_jobs_i = df\n",
    "\n",
    "# df_jobs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# row_data_max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# path_rel_to_proj"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
