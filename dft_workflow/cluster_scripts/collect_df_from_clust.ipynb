{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and combine `jobs_mine` create dataframes from clusters\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/cluster_scripts\n",
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import compenvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all `df_jobs_o_clus` dataframes and combine into single `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/cluster_scripts\",\n",
    "    \"out_data\")\n",
    "\n",
    "# #########################################################\n",
    "# Read dataframes generated within all clusters\n",
    "data_frame_list = []\n",
    "data_frame_dict = dict()\n",
    "for compenv_i in compenvs:\n",
    "    file_path_i = os.path.join(\n",
    "        df_dir_path,\n",
    "        \"df_jobs_on_clus__%s.pickle\" % compenv_i)\n",
    "\n",
    "    my_file = Path(file_path_i)\n",
    "    if my_file.is_file():\n",
    "        with open(file_path_i, \"rb\") as fle:\n",
    "            df_i = pickle.load(fle)\n",
    "            data_frame_list.append(df_i)\n",
    "            data_frame_dict[compenv_i] = df_i\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_on_clus__all = pd.concat(data_frame_list)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframe to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data_dir_rel_to_proj = os.path.join(\n",
    "    \"dft_workflow/cluster_scripts\",\n",
    "    \"out_data\",\n",
    "    )\n",
    "\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    out_data_dir_rel_to_proj)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Pickling data ###########################################\n",
    "file_path = os.path.join(directory, \"df_jobs_on_clus__all.pickle\")\n",
    "with open(file_path, \"wb\") as fle:\n",
    "    pickle.dump(df_jobs_on_clus__all, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>compenv</th>\n",
       "      <th>path</th>\n",
       "      <th>path_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bekutofe_66</th>\n",
       "      <td>bekutofe_66</td>\n",
       "      <td>nersc</td>\n",
       "      <td>/global/cscratch1/sd/flores12/PROJ_IrOx_OER/df...</td>\n",
       "      <td>dft_workflow/run_dos_bader/run_o_covered/out_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natowaka_06</th>\n",
       "      <td>natowaka_06</td>\n",
       "      <td>nersc</td>\n",
       "      <td>/global/cscratch1/sd/flores12/PROJ_IrOx_OER/df...</td>\n",
       "      <td>dft_workflow/run_dos_bader/run_o_covered/out_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_id compenv  \\\n",
       "bekutofe_66  bekutofe_66   nersc   \n",
       "natowaka_06  natowaka_06   nersc   \n",
       "\n",
       "                                                          path  \\\n",
       "bekutofe_66  /global/cscratch1/sd/flores12/PROJ_IrOx_OER/df...   \n",
       "natowaka_06  /global/cscratch1/sd/flores12/PROJ_IrOx_OER/df...   \n",
       "\n",
       "                                                    path_short  \n",
       "bekutofe_66  dft_workflow/run_dos_bader/run_o_covered/out_d...  \n",
       "natowaka_06  dft_workflow/run_dos_bader/run_o_covered/out_d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods import get_df_jobs_on_clus__all\n",
    "\n",
    "df_jobs_on_clus__all_tmp = get_df_jobs_on_clus__all()\n",
    "df_jobs_on_clus__all_tmp.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.067 min\n",
      "collect_df_from_clust.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"collect_df_from_clust.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data_frame_dict[\"nersc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
