{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect DFT data into OER sets \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/collect_collate_dft_data\n",
      "oxy_ref, hyd_ref\n",
      "-7.45942759 -3.38574595\n",
      "\n",
      "corrections_dict: {'ooh': 0.3765, 'o': 0.044, 'oh': 0.2945, 'bare': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_jobs_anal\n",
    "from methods import get_df_jobs_data\n",
    "from methods import get_df_slabs_to_run\n",
    "from methods import get_df_jobs_oh_anal\n",
    "from methods import get_df_atoms_sorted_ind\n",
    "from methods import get_df_octa_info\n",
    "from methods import get_df_struct_drift\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import calc_ads_e\n",
    "from local_methods import get_oer_triplet\n",
    "from local_methods import get_group_w_all_ads, are_any_ads_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "# #########################################################\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_slabs_to_run = df_slabs_to_run.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"att_num\"], drop=False)\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_oh_anal = get_df_jobs_oh_anal()\n",
    "df_jobs_oh_anal = df_jobs_oh_anal.set_index([\"compenv\", \"slab_id\", \"active_site\"])\n",
    "\n",
    "# #########################################################\n",
    "df_atoms_sorted = get_df_atoms_sorted_ind()\n",
    "\n",
    "# #########################################################\n",
    "df_octa_info = get_df_octa_info()\n",
    "\n",
    "# #########################################################\n",
    "df_struct_drift = get_df_struct_drift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering `df_jobs_anal` to only `oer_adsorbate` job types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]\n",
    "df_jobs_anal_i = df_jobs_anal_i.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter columns in `df_jobs_anal_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_modules.pandas_methods import drop_columns\n",
    "\n",
    "cols_to_keep = [\n",
    "    'job_id_max',\n",
    "    # 'timed_out',\n",
    "    # 'completed',\n",
    "    # 'brmix_issue',\n",
    "    # 'job_understandable',\n",
    "    # 'decision',\n",
    "    # 'dft_params_new',\n",
    "    'job_completely_done',\n",
    "    ]\n",
    "\n",
    "df_jobs_anal_i = drop_columns(\n",
    "    df=df_jobs_anal_i,\n",
    "    columns=cols_to_keep,\n",
    "    keep_or_drop=\"keep\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafting `pot_e` and `as_is_nan` to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    # #####################################################\n",
    "    new_column_values_dict = {\n",
    "        \"pot_e\": None,\n",
    "        \"as_is_nan\": None,\n",
    "        }\n",
    "    # #####################################################\n",
    "    compenv_i = row_i.name[0]\n",
    "    slab_id_i = row_i.name[1]\n",
    "    ads_i = row_i.name[2]\n",
    "    active_site_i = row_i.name[3]\n",
    "    att_num_i = row_i.name[4]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    job_completely_done_i = row_i.job_completely_done\n",
    "    # #####################################################\n",
    "\n",
    "    as_is_nan = False\n",
    "    if active_site_i == \"NaN\":\n",
    "        as_is_nan = True\n",
    "\n",
    "    # #####################################################\n",
    "    row_data_i = df_jobs_data.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    pot_e_i = row_data_i.pot_e\n",
    "    rerun_from_oh_i = row_data_i.rerun_from_oh\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    new_column_values_dict[\"pot_e\"] = pot_e_i\n",
    "    new_column_values_dict[\"as_is_nan\"] = as_is_nan\n",
    "    new_column_values_dict[\"rerun_from_oh\"] = rerun_from_oh_i\n",
    "    # #####################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    # #####################################################\n",
    "    return(row_i)\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing O slabs from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Remove the *O slabs for now\n",
    "# The fact that they have NaN active sites will mess up the groupby\n",
    "ads_list = df_jobs_anal_i.index.get_level_values(\"ads\").tolist()\n",
    "ads_list_no_o = [i for i in list(set(ads_list)) if i != \"o\"]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_no_o = df_jobs_anal_i.loc[idx[:, :, ads_list_no_o, :, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows whose atoms failed to sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atoms_sorted_i = df_atoms_sorted[df_atoms_sorted.index.to_frame().job_type == \"oer_adsorbate\"] \n",
    "df_atoms_sorted_i = df_atoms_sorted_i.droplevel(level=0)\n",
    "\n",
    "df_atoms_sorted_i = df_atoms_sorted_i[df_atoms_sorted_i.failed_to_sort == True]\n",
    "\n",
    "\n",
    "# Dropping rows that have failed to sort atoms objects\n",
    "df_jobs_anal_no_o = df_jobs_anal_no_o.drop(df_atoms_sorted_i.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"TEMP TEMP TEMP | heuristic__if_lower_e=True | TEMP TEMP TEMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_jobs_anal_no_o.groupby(groupby_cols)\n",
    "for name_i, group in grouped:\n",
    "\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# for i in range(1):\n",
    "#     # name_i = ('sherlock', 'kamevuse_75', 49.0)\n",
    "#     # name_i = ('nersc', 'kererape_22', 88.0, )\n",
    "#     name_i = ('nersc', 'dakoputu_58', 74.0)\n",
    "#     # #####################################################\n",
    "#     group = grouped.get_group(name_i)\n",
    "# # #########################################################\n",
    "\n",
    "    # print(name_i)\n",
    "\n",
    "    # #####################################################\n",
    "    ads_e_o_i = None; ads_e_oh_i = None\n",
    "    job_id_o_i = None; job_id_oh_i  = None; job_id_bare_i = None\n",
    "    any_bare_done = None; any_oh_done = None; any_o_done = None\n",
    "    any_o_done_with_active_sites = None; all_jobs_in_group_done = None\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(groupby_cols, name_i))\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    out_dict = get_group_w_all_ads(\n",
    "        name=name_i,\n",
    "        group=group,\n",
    "        df_jobs_anal_i=df_jobs_anal_i,\n",
    "        )\n",
    "    group_i = out_dict[\"group_i\"]\n",
    "    any_o_done_with_active_sites = out_dict[\"any_o_done_with_active_sites\"]\n",
    "\n",
    "\n",
    "    all_jobs_in_group_done = group_i.job_completely_done.all()\n",
    "\n",
    "\n",
    "    out_dict = are_any_ads_done(\n",
    "        group=group_i,\n",
    "        )\n",
    "    any_o_done = out_dict[\"any_o_done\"]\n",
    "    any_oh_done = out_dict[\"any_oh_done\"]\n",
    "    any_bare_done = out_dict[\"any_bare_done\"]\n",
    "\n",
    "\n",
    "    # Check that potential energy is numerical\n",
    "    for i in group_i.pot_e.tolist():\n",
    "        if type(i) != float:\n",
    "            print(\"A non-numerical potential energy entered WF: \", name_i)\n",
    "\n",
    "\n",
    "    # Only consider done jobs from here\n",
    "    group_done_i = group_i[group_i.job_completely_done == True]\n",
    "\n",
    "    group_ind_i = group_done_i.index.to_frame()\n",
    "\n",
    "    necessary_ads_present = True\n",
    "    if \"o\" not in group_ind_i.ads.tolist():\n",
    "        necessary_ads_present = False\n",
    "\n",
    "    if necessary_ads_present:\n",
    "\n",
    "        oer_trip_i = get_oer_triplet(\n",
    "            name=name_i,\n",
    "            group=group_done_i,\n",
    "            df_jobs_oh_anal=df_jobs_oh_anal,\n",
    "            df_octa_info=df_octa_info,\n",
    "            heuristic__if_lower_e=False,\n",
    "            # heuristic__if_lower_e=True,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        # Checking if *O is avail and get job id\n",
    "        o_avail = \"o\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "        if o_avail:\n",
    "            idx = pd.IndexSlice\n",
    "            row_o_i = oer_trip_i.loc[idx[:, :, \"o\", :, :], :].iloc[0]\n",
    "            job_id_o_i = row_o_i.job_id_max\n",
    "            low_e_not_from_oh__o = row_o_i.low_e_not_from_oh\n",
    "        else:\n",
    "            ads_e_o_i = None\n",
    "            job_id_o_i = None\n",
    "\n",
    "        # #################################################\n",
    "        # Checking if *OH is avail and get job id\n",
    "        oh_avail = \"oh\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "        if oh_avail:\n",
    "            idx = pd.IndexSlice\n",
    "            row_oh_i = oer_trip_i.loc[idx[:, :, \"oh\", :, :], :].iloc[0]\n",
    "            job_id_oh_i = row_oh_i.job_id_max\n",
    "        else:\n",
    "            ads_e_oh_i = None\n",
    "            job_id_oh_i = None\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        # Can only compute adsorption energies if bare (*) is avail\n",
    "        bare_avail = \"bare\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "        if bare_avail:\n",
    "            idx = pd.IndexSlice\n",
    "            row_bare_i = oer_trip_i.loc[idx[:, :, \"bare\", :, :], :].iloc[0]\n",
    "            job_id_bare_i = row_bare_i.job_id_max\n",
    "            low_e_not_from_oh__bare = row_bare_i.low_e_not_from_oh\n",
    "\n",
    "            df_ads_i = calc_ads_e(oer_trip_i.reset_index())\n",
    "            df_ads_i = df_ads_i.set_index(\"ads\", drop=False)\n",
    "\n",
    "            ads_g_o_i = df_ads_i.loc[\"o\"][\"ads_e\"]\n",
    "            ads_e_o_i = df_ads_i.loc[\"o\"][\"ads_e_elec\"]\n",
    "\n",
    "            if \"oh\" in df_ads_i.index:\n",
    "                ads_g_oh_i = df_ads_i.loc[\"oh\"][\"ads_e\"]\n",
    "                ads_e_oh_i = df_ads_i.loc[\"oh\"][\"ads_e_elec\"]\n",
    "                job_id_oh_i = df_ads_i.loc[\"oh\"][\"job_id_max\"]\n",
    "            else:\n",
    "                ads_g_oh_i = None\n",
    "                ads_e_oh_i = None\n",
    "                job_id_oh_i = None\n",
    "\n",
    "        else:\n",
    "            job_id_bare_i = None\n",
    "\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_i.update(name_dict_i)\n",
    "        # #################################################\n",
    "        data_dict_i[\"g_o\"] = ads_g_o_i\n",
    "        data_dict_i[\"g_oh\"] = ads_g_oh_i\n",
    "        data_dict_i[\"e_o\"] = ads_e_o_i\n",
    "        data_dict_i[\"e_oh\"] = ads_e_oh_i\n",
    "        data_dict_i[\"job_id_o\"] = job_id_o_i\n",
    "        data_dict_i[\"job_id_oh\"] = job_id_oh_i \n",
    "        data_dict_i[\"job_id_bare\"] = job_id_bare_i\n",
    "        data_dict_i[\"all_done\"] = all_jobs_in_group_done\n",
    "        data_dict_i[\"any_bare_done\"] = any_bare_done\n",
    "        data_dict_i[\"any_oh_done\"] = any_oh_done\n",
    "        data_dict_i[\"any_o_done\"] = any_o_done\n",
    "        data_dict_i[\"any_o_w_as_done\"] = any_o_done_with_active_sites\n",
    "        data_dict_i[\"low_e_not_from_oh__o\"] = low_e_not_from_oh__o\n",
    "        data_dict_i[\"low_e_not_from_oh__bare\"] = low_e_not_from_oh__bare\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_i)\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_ads = pd.DataFrame(data_dict_list)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/collect_collate_dft_data\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_ads.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_ads, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_ads\n",
    "\n",
    "df_ads_tmp = get_df_ads()\n",
    "df_ads_tmp.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"collect_collate_dft.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
