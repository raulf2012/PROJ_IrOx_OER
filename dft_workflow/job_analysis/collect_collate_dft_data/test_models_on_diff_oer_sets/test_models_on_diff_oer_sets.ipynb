{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ML models on different OER set picking heuristics\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_features_targets,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods_models import run_gp_workflow\n",
    "\n",
    "sys.path.insert(0, \n",
    "    os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/model_building\"))\n",
    "\n",
    "from methods_model_building import (\n",
    "    simplify_df_features_targets,\n",
    "    run_kfold_cv_wf,\n",
    "    process_feature_targets_df,\n",
    "    process_pca_analysis,\n",
    "    pca_analysis,\n",
    "    run_regression_wf,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "    show_plot = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False\n",
    "    show_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pca_i = 8\n",
    "\n",
    "gp_settings = {\n",
    "    \"noise\": 0.02542,\n",
    "    }\n",
    "\n",
    "# Length scale parameter\n",
    "sigma_l_default = 1.8  # Length scale parameter\n",
    "sigma_f_default = 0.2337970892240513  # Scaling parameter.\n",
    "\n",
    "kdict = [\n",
    "    {\n",
    "        'type': 'gaussian',\n",
    "        'dimension': 'single',\n",
    "        'width': sigma_l_default,\n",
    "        'scaling': sigma_f_default,\n",
    "        'scaling_bounds': ((0.0001, 10.),),\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "\n",
    "    # ('features', 'oh', 'O_magmom'),\n",
    "    # ('features', 'oh', 'Ir_magmom'),\n",
    "    # ('features', 'oh', 'active_o_metal_dist'),\n",
    "    # ('features', 'oh', 'angle_O_Ir_surf_norm'),\n",
    "    # ('features', 'oh', 'ir_o_mean'),\n",
    "    # ('features', 'oh', 'ir_o_std'),\n",
    "    # ('features', 'oh', 'octa_vol'),\n",
    "\n",
    "    ('features', 'o', 'O_magmom'),\n",
    "    ('features', 'o', 'Ir_magmom'),\n",
    "    ('features', 'o', 'active_o_metal_dist'),\n",
    "    # ('features', 'o', 'angle_O_Ir_surf_norm'),\n",
    "    ('features', 'o', 'ir_o_mean'),\n",
    "    ('features', 'o', 'ir_o_std'),\n",
    "    ('features', 'o', 'octa_vol'),\n",
    "\n",
    "    # ('features', 'o', 'Ir*O_bader'),\n",
    "    ('features', 'o', 'Ir_bader'),\n",
    "    # ('features', 'o', 'O_bader'),\n",
    "    ('features', 'o', 'p_band_center'),\n",
    "    # ('features', 'o', 'Ir*O_bader/ir_o_mean'),\n",
    "\n",
    "    ('features', 'dH_bulk', ''),\n",
    "    ('features', 'volume_pa', ''),\n",
    "    ('features', 'bulk_oxid_state', ''),\n",
    "    ('features', 'effective_ox_state', ''),\n",
    "\n",
    "    # ('features_pre_dft', 'active_o_metal_dist__pre', ''),\n",
    "    # ('features_pre_dft', 'ir_o_mean__pre', ''),\n",
    "    # ('features_pre_dft', 'ir_o_std__pre', ''),\n",
    "    # ('features_pre_dft', 'octa_vol__pre', ''),\n",
    "\n",
    "    # #####################################################\n",
    "    # TARGETS #############################################\n",
    "    # ('targets', 'e_o', ''),\n",
    "    # ('targets', 'e_oh', ''),\n",
    "    # ('targets', 'g_o_m_oh', ''),\n",
    "    # ('targets', 'e_o_m_oh', ''),\n",
    "\n",
    "    # ('targets', 'g_o', ''),\n",
    "    ('targets', 'g_oh', ''),\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_targets = get_df_features_targets()\n",
    "df_m = df_features_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/collect_collate_dft_data\",\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(root_dir,\n",
    "    \"out_data/df_ads__from_oh.pickle\",)\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_ads__from_oh = pickle.load(fle)\n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(root_dir,\n",
    "    \"out_data/df_ads__low_e.pickle\",)\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_ads__low_e = pickle.load(fle)\n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(root_dir,\n",
    "    \"out_data/df_ads__magmom.pickle\",)\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_ads__magmom = pickle.load(fle)\n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(root_dir,\n",
    "    \"out_data/df_ads__mine.pickle\",)\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_ads__mine = pickle.load(fle)\n",
    "\n",
    "# #########################################################\n",
    "path_i = os.path.join(root_dir,\n",
    "    \"out_data/df_ads__mine_2.pickle\",)\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_ads__mine_2 = pickle.load(fle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set index on OER set dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads__from_oh = df_ads__from_oh.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ],\n",
    "    drop=False)\n",
    "\n",
    "df_ads__low_e = df_ads__low_e.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ],\n",
    "    drop=False)\n",
    "\n",
    "df_ads__magmom = df_ads__magmom.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ],\n",
    "    drop=False)\n",
    "\n",
    "df_ads__mine = df_ads__mine.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ],\n",
    "    drop=False)\n",
    "\n",
    "df_ads__mine_2 = df_ads__mine_2.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"active_site\", ],\n",
    "    drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_wo_y = df_m.drop(\n",
    "    columns=[\n",
    "        (\"targets\", \"g_o\", \"\", ),\n",
    "        (\"targets\", \"g_oh\", \"\", ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df_m_wo_y.iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `from_oh`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_ads__from_oh_y = df_ads__from_oh[[\"g_o\", \"g_oh\", ]]\n",
    "\n",
    "new_cols = []\n",
    "for col_i in df_ads__from_oh_y.columns:\n",
    "    new_col_i = (\"targets\", col_i, \"\", )\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_ads__from_oh_y.columns = idx\n",
    "\n",
    "# #########################################################\n",
    "df_m__from_oh = pd.concat([\n",
    "    df_m_wo_y,\n",
    "    df_ads__from_oh_y,\n",
    "    ], axis=1)\n",
    "\n",
    "df_m__from_oh = df_m__from_oh.reindex(\n",
    "    columns=list(df_m__from_oh.columns.levels[0]),\n",
    "    level=0)\n",
    "\n",
    "# #########################################################\n",
    "df_m__from_oh_2 = df_m__from_oh[\n",
    "    cols_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "adsorbates = [\"o\", \"oh\", \"ooh\", ] \n",
    "new_cols = []\n",
    "for col_i in df_m__from_oh_2.columns:\n",
    "    # print(col_i)\n",
    "\n",
    "    new_col_i = None\n",
    "    if col_i[0] == \"targets\":\n",
    "        new_col_i = (\"targets\", col_i[1], )\n",
    "    elif col_i[0] == \"features\" and col_i[1] in adsorbates:\n",
    "        new_col_i = (\"features\", col_i[2], )\n",
    "    elif col_i[0] == \"features\" and col_i[2] == \"\":\n",
    "        new_col_i = (\"features\", col_i[1], )\n",
    "    else:\n",
    "        print(\"Woops\")\n",
    "\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_m__from_oh_2.columns = idx\n",
    "\n",
    "df_m__from_oh_2 = df_m__from_oh_2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m__from_oh_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "cols_to_use = df_m__from_oh_2[\"features\"].columns.tolist()\n",
    "\n",
    "out_dict = run_kfold_cv_wf(\n",
    "    df_features_targets=df_m__from_oh_2,\n",
    "    cols_to_use=cols_to_use,\n",
    "    run_pca=True,\n",
    "    num_pca_comp=num_pca_i,\n",
    "    k_fold_partition_size=30,\n",
    "    model_workflow=run_gp_workflow,\n",
    "    model_settings=dict(\n",
    "        gp_settings=gp_settings,\n",
    "        kdict=kdict,\n",
    "        ),\n",
    "    )\n",
    "# #####################################################\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "PCA = out_dict[\"pca\"]\n",
    "regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "RM_2 = out_dict[\"RM_2\"]\n",
    "# #####################################################\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"MAE: \",\n",
    "        np.round(MAE, 5),\n",
    "        \" eV\",\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"R2: \",\n",
    "        np.round(R2, 5),\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"MAE (predicting on train set): \",\n",
    "        np.round(MAE_pred_on_train, 5),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `low_e`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_ads__low_e_y = df_ads__low_e[[\"g_o\", \"g_oh\", ]]\n",
    "\n",
    "new_cols = []\n",
    "for col_i in df_ads__low_e_y.columns:\n",
    "    new_col_i = (\"targets\", col_i, \"\", )\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_ads__low_e_y.columns = idx\n",
    "\n",
    "# #########################################################\n",
    "df_m__low_e = pd.concat([\n",
    "    df_m_wo_y,\n",
    "    df_ads__low_e_y,\n",
    "    ], axis=1)\n",
    "\n",
    "df_m__low_e = df_m__low_e.reindex(\n",
    "    columns=list(df_m__low_e.columns.levels[0]),\n",
    "    level=0)\n",
    "\n",
    "# #########################################################\n",
    "df_m__low_e_2 = df_m__low_e[\n",
    "    cols_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "adsorbates = [\"o\", \"oh\", \"ooh\", ] \n",
    "new_cols = []\n",
    "for col_i in df_m__low_e_2.columns:\n",
    "    # print(col_i)\n",
    "\n",
    "    new_col_i = None\n",
    "    if col_i[0] == \"targets\":\n",
    "        new_col_i = (\"targets\", col_i[1], )\n",
    "    elif col_i[0] == \"features\" and col_i[1] in adsorbates:\n",
    "        new_col_i = (\"features\", col_i[2], )\n",
    "    elif col_i[0] == \"features\" and col_i[2] == \"\":\n",
    "        new_col_i = (\"features\", col_i[1], )\n",
    "    else:\n",
    "        print(\"Woops\")\n",
    "\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_m__low_e_2.columns = idx\n",
    "\n",
    "df_m__low_e_2 = df_m__low_e_2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "cols_to_use = df_m__low_e_2[\"features\"].columns.tolist()\n",
    "\n",
    "out_dict = run_kfold_cv_wf(\n",
    "    df_features_targets=df_m__low_e_2,\n",
    "    cols_to_use=cols_to_use,\n",
    "    run_pca=True,\n",
    "    num_pca_comp=num_pca_i,\n",
    "    k_fold_partition_size=30,\n",
    "    model_workflow=run_gp_workflow,\n",
    "    model_settings=dict(\n",
    "        gp_settings=gp_settings,\n",
    "        kdict=kdict,\n",
    "        ),\n",
    "    )\n",
    "# #####################################################\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "PCA = out_dict[\"pca\"]\n",
    "regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "RM_2 = out_dict[\"RM_2\"]\n",
    "# #####################################################\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"MAE: \",\n",
    "        np.round(MAE, 5),\n",
    "        \" eV\",\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"R2: \",\n",
    "        np.round(R2, 5),\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"MAE (predicting on train set): \",\n",
    "        np.round(MAE_pred_on_train, 5),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `magmom`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_ads__magmom_y = df_ads__magmom[[\"g_o\", \"g_oh\", ]]\n",
    "\n",
    "new_cols = []\n",
    "for col_i in df_ads__magmom_y.columns:\n",
    "    new_col_i = (\"targets\", col_i, \"\", )\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_ads__magmom_y.columns = idx\n",
    "\n",
    "# #########################################################\n",
    "df_m__magmom = pd.concat([\n",
    "    df_m_wo_y,\n",
    "    df_ads__magmom_y,\n",
    "    ], axis=1)\n",
    "\n",
    "df_m__magmom = df_m__magmom.reindex(\n",
    "    columns=list(df_m__magmom.columns.levels[0]),\n",
    "    level=0)\n",
    "\n",
    "# #########################################################\n",
    "df_m__magmom_2 = df_m__magmom[\n",
    "    cols_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "adsorbates = [\"o\", \"oh\", \"ooh\", ] \n",
    "new_cols = []\n",
    "for col_i in df_m__magmom_2.columns:\n",
    "    # print(col_i)\n",
    "\n",
    "    new_col_i = None\n",
    "    if col_i[0] == \"targets\":\n",
    "        new_col_i = (\"targets\", col_i[1], )\n",
    "    elif col_i[0] == \"features\" and col_i[1] in adsorbates:\n",
    "        new_col_i = (\"features\", col_i[2], )\n",
    "    elif col_i[0] == \"features\" and col_i[2] == \"\":\n",
    "        new_col_i = (\"features\", col_i[1], )\n",
    "    else:\n",
    "        print(\"Woops\")\n",
    "\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_m__magmom_2.columns = idx\n",
    "\n",
    "df_m__magmom_2 = df_m__magmom_2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "cols_to_use = df_m__magmom_2[\"features\"].columns.tolist()\n",
    "\n",
    "out_dict = run_kfold_cv_wf(\n",
    "    df_features_targets=df_m__magmom_2,\n",
    "    cols_to_use=cols_to_use,\n",
    "    run_pca=True,\n",
    "    num_pca_comp=num_pca_i,\n",
    "    k_fold_partition_size=30,\n",
    "    model_workflow=run_gp_workflow,\n",
    "    model_settings=dict(\n",
    "        gp_settings=gp_settings,\n",
    "        kdict=kdict,\n",
    "        ),\n",
    "    )\n",
    "# #####################################################\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "PCA = out_dict[\"pca\"]\n",
    "regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "RM_2 = out_dict[\"RM_2\"]\n",
    "# #####################################################\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"MAE: \",\n",
    "        np.round(MAE, 5),\n",
    "        \" eV\",\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"R2: \",\n",
    "        np.round(R2, 5),\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"MAE (predicting on train set): \",\n",
    "        np.round(MAE_pred_on_train, 5),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mine`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_ads__mine_y = df_ads__mine[[\"g_o\", \"g_oh\", ]]\n",
    "\n",
    "new_cols = []\n",
    "for col_i in df_ads__mine_y.columns:\n",
    "    new_col_i = (\"targets\", col_i, \"\", )\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_ads__mine_y.columns = idx\n",
    "\n",
    "# #########################################################\n",
    "df_m__mine = pd.concat([\n",
    "    df_m_wo_y,\n",
    "    df_ads__mine_y,\n",
    "    ], axis=1)\n",
    "\n",
    "df_m__mine = df_m__mine.reindex(\n",
    "    columns=list(df_m__mine.columns.levels[0]),\n",
    "    level=0)\n",
    "\n",
    "# #########################################################\n",
    "df_m__mine_2 = df_m__mine[\n",
    "    cols_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "adsorbates = [\"o\", \"oh\", \"ooh\", ] \n",
    "new_cols = []\n",
    "for col_i in df_m__mine_2.columns:\n",
    "    # print(col_i)\n",
    "\n",
    "    new_col_i = None\n",
    "    if col_i[0] == \"targets\":\n",
    "        new_col_i = (\"targets\", col_i[1], )\n",
    "    elif col_i[0] == \"features\" and col_i[1] in adsorbates:\n",
    "        new_col_i = (\"features\", col_i[2], )\n",
    "    elif col_i[0] == \"features\" and col_i[2] == \"\":\n",
    "        new_col_i = (\"features\", col_i[1], )\n",
    "    else:\n",
    "        print(\"Woops\")\n",
    "\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_m__mine_2.columns = idx\n",
    "\n",
    "df_m__mine_2 = df_m__mine_2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "cols_to_use = df_m__mine_2[\"features\"].columns.tolist()\n",
    "\n",
    "out_dict = run_kfold_cv_wf(\n",
    "    df_features_targets=df_m__mine_2,\n",
    "    cols_to_use=cols_to_use,\n",
    "    run_pca=True,\n",
    "    num_pca_comp=num_pca_i,\n",
    "    k_fold_partition_size=30,\n",
    "    model_workflow=run_gp_workflow,\n",
    "    model_settings=dict(\n",
    "        gp_settings=gp_settings,\n",
    "        kdict=kdict,\n",
    "        ),\n",
    "    )\n",
    "# #####################################################\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "PCA = out_dict[\"pca\"]\n",
    "regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "RM_2 = out_dict[\"RM_2\"]\n",
    "# #####################################################\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"MAE: \",\n",
    "        np.round(MAE, 5),\n",
    "        \" eV\",\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"R2: \",\n",
    "        np.round(R2, 5),\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"MAE (predicting on train set): \",\n",
    "        np.round(MAE_pred_on_train, 5),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mine_2`"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_ads__mine_2_y = df_ads__mine_2[[\"g_o\", \"g_oh\", ]]\n",
    "\n",
    "new_cols = []\n",
    "for col_i in df_ads__mine_2_y.columns:\n",
    "    new_col_i = (\"targets\", col_i, \"\", )\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_ads__mine_2_y.columns = idx\n",
    "\n",
    "# #########################################################\n",
    "df_m__mine_2 = pd.concat([\n",
    "    df_m_wo_y,\n",
    "    df_ads__mine_2_y,\n",
    "    ], axis=1)\n",
    "\n",
    "df_m__mine_2 = df_m__mine_2.reindex(\n",
    "    columns=list(df_m__mine_2.columns.levels[0]),\n",
    "    level=0)\n",
    "\n",
    "# #########################################################\n",
    "df_m__mine_2_2 = df_m__mine_2[\n",
    "    cols_to_keep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "adsorbates = [\"o\", \"oh\", \"ooh\", ] \n",
    "new_cols = []\n",
    "for col_i in df_m__mine_2_2.columns:\n",
    "    # print(col_i)\n",
    "\n",
    "    new_col_i = None\n",
    "    if col_i[0] == \"targets\":\n",
    "        new_col_i = (\"targets\", col_i[1], )\n",
    "    elif col_i[0] == \"features\" and col_i[1] in adsorbates:\n",
    "        new_col_i = (\"features\", col_i[2], )\n",
    "    elif col_i[0] == \"features\" and col_i[2] == \"\":\n",
    "        new_col_i = (\"features\", col_i[1], )\n",
    "    else:\n",
    "        print(\"Woops\")\n",
    "\n",
    "    new_cols.append(new_col_i)\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples(new_cols)\n",
    "\n",
    "df_m__mine_2_2.columns = idx\n",
    "\n",
    "df_m__mine_2_2 = df_m__mine_2_2.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m__mine_2_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "cols_to_use = df_m__mine_2_2[\"features\"].columns.tolist()\n",
    "\n",
    "out_dict = run_kfold_cv_wf(\n",
    "    df_features_targets=df_m__mine_2_2,\n",
    "    cols_to_use=cols_to_use,\n",
    "    run_pca=True,\n",
    "    num_pca_comp=num_pca_i,\n",
    "    k_fold_partition_size=30,\n",
    "    model_workflow=run_gp_workflow,\n",
    "    model_settings=dict(\n",
    "        gp_settings=gp_settings,\n",
    "        kdict=kdict,\n",
    "        ),\n",
    "    )\n",
    "# #####################################################\n",
    "df_target_pred = out_dict[\"df_target_pred\"]\n",
    "MAE = out_dict[\"MAE\"]\n",
    "R2 = out_dict[\"R2\"]\n",
    "PCA = out_dict[\"pca\"]\n",
    "regression_model_list = out_dict[\"regression_model_list\"]\n",
    "\n",
    "df_target_pred_on_train = out_dict[\"df_target_pred_on_train\"]\n",
    "MAE_pred_on_train = out_dict[\"MAE_pred_on_train\"]\n",
    "RM_2 = out_dict[\"RM_2\"]\n",
    "# #####################################################\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"MAE: \",\n",
    "        np.round(MAE, 5),\n",
    "        \" eV\",\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"R2: \",\n",
    "        np.round(R2, 5),\n",
    "        sep=\"\")\n",
    "\n",
    "    print(\n",
    "        \"MAE (predicting on train set): \",\n",
    "        np.round(MAE_pred_on_train, 5),\n",
    "        sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on *OH results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FROM OH\n",
    "MAE: 0.18735 eV\n",
    "R2: 0.70906\n",
    "MAE (predicting on train set): 0.14474\n",
    "\n",
    "# LOW E\n",
    "MAE: 0.19039 eV\n",
    "R2: 0.7025\n",
    "MAE (predicting on train set): 0.10353\n",
    "\n",
    "# MAGMOM\n",
    "MAE: 0.19125 eV\n",
    "R2: 0.72463\n",
    "MAE (predicting on train set): 0.08905\n",
    "\n",
    "# MINE\n",
    "MAE: 0.18998 eV\n",
    "R2: 0.70478\n",
    "MAE (predicting on train set): 0.08904\n",
    "\n",
    "# MINE_2\n",
    "MAE: 0.18941 eV\n",
    "R2: 0.70577\n",
    "MAE (predicting on train set): 0.14718"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on *O results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FROM OH\n",
    "MAE: 0.19534 eV\n",
    "R2: 0.78813\n",
    "MAE (predicting on train set): 0.15341\n",
    "\n",
    "# LOW E\n",
    "MAE: 0.18201 eV\n",
    "R2: 0.82162\n",
    "MAE (predicting on train set): 0.13367\n",
    "\n",
    "# MAGMOM\n",
    "MAE: 0.21635 eV\n",
    "R2: 0.7337\n",
    "MAE (predicting on train set): 0.17447\n",
    "\n",
    "# MINE\n",
    "MAE: 0.18226 eV\n",
    "R2: 0.81959\n",
    "MAE (predicting on train set): 0.13481"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# os.environ[\"\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# # Pickling data ###########################################\n",
    "# directory = os.path.join(\n",
    "#     root_dir, \"out_data\")\n",
    "# if not os.path.exists(directory): os.makedirs(directory)\n",
    "# with open(os.path.join(directory, \"df_ads__magmom.pickle\"), \"wb\") as fle:\n",
    "#     pickle.dump(df_ads__magmom, fle)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_ads.pickle\n",
    "# df_dict.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_ads__from_oh.pickle\n",
    "# df_ads__low_e.pickle\n",
    "# df_ads__magmom.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_m__from_oh.sort_\n",
    "# df_m__from_oh = \n",
    "# df_m__from_oh.reindex(columns=[\"data\", \"features\", ], level=0)\n",
    "# df_m__from_oh.reindex(columns=[\"targets\", ], level=0)\n",
    "# [\"targets\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# list(df_m__from_oh.columns.levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_m[\"targets\"]\n",
    "\n",
    "# df_m.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# for i in new_cols:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_j = df_m__from_oh_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name_i, row_i in df_ads__magmom.iterrows():\n",
    "#     # name_i\n",
    "\n",
    "#     # #####################################################\n",
    "#     job_id_o_i = row_i.job_id_o\n",
    "#     job_id_oh_i = row_i.job_id_oh\n",
    "#     job_id_bare_i = row_i.job_id_bare\n",
    "#     # #####################################################\n",
    "\n",
    "#     # #####################################################\n",
    "#     row_mine_i = df_ads__mine.loc[name_i]\n",
    "#     # #####################################################\n",
    "#     job_id_o_i_2 = row_mine_i.job_id_o\n",
    "#     job_id_oh_i_2 = row_mine_i.job_id_oh\n",
    "#     job_id_bare_i_2 = row_mine_i.job_id_bare\n",
    "#     # #####################################################\n",
    "\n",
    "#     if not job_id_o_i == job_id_o_i_2:\n",
    "#         print(\"IJI\")\n",
    "\n",
    "#     if not job_id_oh_i == job_id_oh_i_2:\n",
    "#         print(\"IJI\")\n",
    "\n",
    "#     if not job_id_bare_i == job_id_bare_i_2:\n",
    "#         print(\"IJI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_id_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FROM_OH\n",
    "MAE: 0.18735 eV\n",
    "R2: 0.70906\n",
    "MAE (predicting on train set): 0.14474\n",
    "\n",
    "# LOW_E\n",
    "MAE: 0.19039 eV\n",
    "R2: 0.7025\n",
    "MAE (predicting on train set): 0.10353\n",
    "\n",
    "# MAGMOM\n",
    "MAE: 0.19125 eV\n",
    "R2: 0.72463\n",
    "MAE (predicting on train set): 0.08905"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FROM OH\n",
    "MAE: 0.19001 eV\n",
    "R2: 0.71487\n",
    "MAE (predicting on train set): 0.13976\n",
    "\n",
    "# LOW E\n",
    "MAE: 0.1893 eV\n",
    "R2: 0.70264\n",
    "MAE (predicting on train set): 0.11304\n",
    "\n",
    "# MAGMOM\n",
    "MAE: 0.1932 eV\n",
    "R2: 0.70798\n",
    "MAE (predicting on train set): 0.1057"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
