{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute degree of structural drift across different slabs in OER sets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/slab_struct_drift\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import metal_atom_symbol\n",
    "from methods import (\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_data,\n",
    "    get_other_job_ids_in_set,\n",
    "    nearest_atom_mine,\n",
    "    get_df_coord,\n",
    "    get_df_coord_wrap,\n",
    "    get_df_struct_drift,\n",
    "\n",
    "    match_atoms,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import (\n",
    "    # match_atoms,\n",
    "    get_mean_displacement_octahedra,\n",
    "    )\n",
    "\n",
    "from methods import get_df_init_slabs\n",
    "from methods import get_df_atoms_sorted_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_struct_drift_old = get_df_struct_drift()\n",
    "df_struct_drift_old = df_struct_drift_old.set_index(\"pair_str\", drop=False)\n",
    "\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing *O calcs that don't have an active site\n",
    "# It messes up the groupby\n",
    "df_jobs_i = df_jobs[df_jobs.active_site != \"NaN\"]\n",
    "\n",
    "\n",
    "# Only doing oer_adsorbate calculations\n",
    "df_jobs_i = df_jobs_i[df_jobs_i.job_type == \"oer_adsorbate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b006f59784de8ba90ff383744baad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1st loop', max=448.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\n",
    "    'job_type', 'compenv', 'slab_id',\n",
    "    'bulk_id', 'active_site', 'facet',\n",
    "    ]\n",
    "\n",
    "\n",
    "systems_to_process = []\n",
    "\n",
    "df_list = []\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "iterator = tqdm(grouped, desc=\"1st loop\")\n",
    "for i_cnt, (name_i, group_i) in enumerate(iterator):\n",
    "\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(\n",
    "        group_cols,\n",
    "        list(name_i)))\n",
    "    # #####################################################\n",
    "    compenv_i = name_dict_i[\"compenv\"]\n",
    "    slab_id_i = name_dict_i[\"slab_id\"]\n",
    "    active_site_i = name_dict_i[\"active_site\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    row_tmp = group_i[group_i.ads != \"o\"].iloc[0]\n",
    "\n",
    "    group_i_2 = get_other_job_ids_in_set(\n",
    "        row_tmp.name,\n",
    "        df_jobs=df_jobs,\n",
    "        oer_set=True,\n",
    "        only_last_rev=True)\n",
    "\n",
    "    group_i_3 = pd.merge(\n",
    "        group_i_2,\n",
    "        df_jobs_data[[\"final_atoms\"]],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True)\n",
    "    group_i_3 = group_i_3.dropna(subset=[\"final_atoms\", ])\n",
    "\n",
    "\n",
    "    all_binary_pairs = list(combinations(\n",
    "        group_i_3.index.tolist(), 2))\n",
    "\n",
    "    mean_displacement_dict = dict()\n",
    "\n",
    "    data_dict_list = []\n",
    "\n",
    "\n",
    "    # # TEMP\n",
    "    # print(20 * \"TEMP | \")\n",
    "    # # all_binary_pairs = [('pupofufo_14', 'tabupodu_76'), ]\n",
    "    # # all_binary_pairs = [('lalanota_37', 'wepewido_07'), ]\n",
    "    # all_binary_pairs = [('tuwetuta_57', 'firitune_96'), ]\n",
    "\n",
    "    # #####################################################\n",
    "    for pair_j in all_binary_pairs:\n",
    "\n",
    "        # #################################################\n",
    "        job_id_0 = pair_j[0]\n",
    "        job_id_1 = pair_j[1]\n",
    "        # #################################################\n",
    "        row_jobs_0 = df_jobs.loc[job_id_0]\n",
    "        row_jobs_1 = df_jobs.loc[job_id_1]\n",
    "        # #################################################\n",
    "        ads_0 = row_jobs_0.ads\n",
    "        ads_1 = row_jobs_1.ads\n",
    "        att_num_0 = row_jobs_0.att_num\n",
    "        att_num_1 = row_jobs_1.att_num\n",
    "        active_site_0 = row_jobs_0.active_site\n",
    "        active_site_1 = row_jobs_1.active_site\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "        # Getting sorted atoms objects\n",
    "        name_atoms_sorted_0 = (\n",
    "            \"oer_adsorbate\", compenv_i, slab_id_i,\n",
    "            ads_0, active_site_0, att_num_0, )\n",
    "\n",
    "        name_atoms_sorted_1 = (\n",
    "            \"oer_adsorbate\", compenv_i, slab_id_i,\n",
    "            ads_1, active_site_1, att_num_1, )\n",
    "\n",
    "        row_atoms_sorted = df_atoms_sorted_ind.loc[name_atoms_sorted_0]\n",
    "        atoms_0 = row_atoms_sorted.atoms_sorted_good\n",
    "\n",
    "        row_atoms_sorted = df_atoms_sorted_ind.loc[name_atoms_sorted_1]\n",
    "        atoms_1 = row_atoms_sorted.atoms_sorted_good\n",
    "\n",
    "\n",
    "        pair_str_sorted = \"__\".join(list(np.sort(pair_j)))\n",
    "\n",
    "\n",
    "\n",
    "        if pair_str_sorted in df_struct_drift_old.index:\n",
    "            # #############################################\n",
    "            row_struct_drift_i = df_struct_drift_old.loc[pair_str_sorted]\n",
    "            # #############################################\n",
    "            mean_displacement = row_struct_drift_i[\"mean_displacement\"]\n",
    "            mean_displacement_octahedra = row_struct_drift_i[\"mean_displacement_octahedra\"]\n",
    "            octahedra_atoms = row_struct_drift_i.octahedra_atoms\n",
    "            note = row_struct_drift_i[\"note\"]\n",
    "            error = row_struct_drift_i[\"error\"]\n",
    "            # #############################################\n",
    "\n",
    "\n",
    "\n",
    "            # #############################################\n",
    "            data_dict_i = dict()\n",
    "            # #############################################\n",
    "            data_dict_i[\"pair_str\"] = pair_str_sorted\n",
    "            data_dict_i[\"job_id_0\"] = pair_j[0]\n",
    "            data_dict_i[\"job_id_1\"] = pair_j[1]\n",
    "            data_dict_i[\"job_ids\"] = list(pair_j)\n",
    "            data_dict_i[\"ads_0\"] = ads_0\n",
    "            data_dict_i[\"ads_1\"] = ads_1\n",
    "            data_dict_i[\"att_num_0\"] = att_num_0\n",
    "            data_dict_i[\"att_num_1\"] = att_num_1\n",
    "            data_dict_i[\"mean_displacement\"] = mean_displacement\n",
    "            data_dict_i[\"mean_displacement_octahedra\"] = mean_displacement_octahedra\n",
    "            data_dict_i[\"octahedra_atoms\"] = octahedra_atoms\n",
    "            data_dict_i[\"note\"] = note\n",
    "            data_dict_i[\"error\"] = error\n",
    "            # #############################################\n",
    "            data_dict_list.append(data_dict_i)\n",
    "            # #############################################\n",
    "\n",
    "        else:\n",
    "            systems_to_process.append(pair_str_sorted)\n",
    "\n",
    "    df_tmp = pd.DataFrame(data_dict_list)\n",
    "    df_list.append(df_tmp)\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_struct_drift__done_prev = pd.concat(df_list, axis=0)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6a6e80324c43e3a283741dad59bbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1st loop', max=448.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\n",
    "    'job_type', 'compenv', 'slab_id',\n",
    "    'bulk_id', 'active_site', 'facet',\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "iterator = tqdm(grouped, desc=\"1st loop\")\n",
    "for i_cnt, (name_i, group_i) in enumerate(iterator):\n",
    "\n",
    "\n",
    "# # TEMP Use for testing\n",
    "# if True:\n",
    "#     # name_i = ('oer_adsorbate', 'slac', 'relovalu_12', 'zimixdvdxd', 24.0, '2-1-10')\n",
    "#     # name_i = ('oer_adsorbate', 'slac', 'vuraruna_65', 'z36lb3bdcq', 50.0, '001')\n",
    "#     # name_i = ('oer_adsorbate', 'nersc', 'dakoputu_58', 'bpc2nk6qz1', 74.0, '212')\n",
    "#     # name_i = ('oer_adsorbate', 'nersc', 'hibetede_02', 'mkmsvkcyc5', 32.0, '110')\n",
    "#     name_i = ('oer_adsorbate', 'slac', 'vuraruna_65', 'z36lb3bdcq', 50.0, '001')\n",
    "#     group_i = grouped.get_group(name_i)\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"\")\n",
    "    # print(20 * \"-\")\n",
    "    # print(name_i)\n",
    "\n",
    "\n",
    "    # # TEMP\n",
    "    # if i_cnt > 10:\n",
    "    #     break\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(\n",
    "        group_cols,\n",
    "        list(name_i)))\n",
    "    # #####################################################\n",
    "    compenv_i = name_dict_i[\"compenv\"]\n",
    "    slab_id_i = name_dict_i[\"slab_id\"]\n",
    "    active_site_i = name_dict_i[\"active_site\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    row_tmp = group_i[group_i.ads != \"o\"].iloc[0]\n",
    "\n",
    "    group_i_2 = get_other_job_ids_in_set(\n",
    "        row_tmp.name,\n",
    "        df_jobs=df_jobs,\n",
    "        oer_set=True,\n",
    "        only_last_rev=True)\n",
    "\n",
    "    group_i_3 = pd.merge(\n",
    "        group_i_2,\n",
    "        df_jobs_data[[\"final_atoms\"]],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True)\n",
    "    group_i_3 = group_i_3.dropna(subset=[\"final_atoms\", ])\n",
    "\n",
    "\n",
    "    all_binary_pairs = list(combinations(\n",
    "        group_i_3.index.tolist(), 2))\n",
    "\n",
    "    mean_displacement_dict = dict()\n",
    "\n",
    "    data_dict_list = []\n",
    "\n",
    "\n",
    "    # # TEMP\n",
    "    # print(20 * \"TEMP | \")\n",
    "    # # all_binary_pairs = [('pupofufo_14', 'tabupodu_76'), ]\n",
    "    # # all_binary_pairs = [('lalanota_37', 'wepewido_07'), ]\n",
    "    # all_binary_pairs = [('tuwetuta_57', 'firitune_96'), ]\n",
    "\n",
    "    # #####################################################\n",
    "    for pair_j in all_binary_pairs:\n",
    "\n",
    "        # #################################################\n",
    "        job_id_0 = pair_j[0]\n",
    "        job_id_1 = pair_j[1]\n",
    "        # #################################################\n",
    "        row_jobs_0 = df_jobs.loc[job_id_0]\n",
    "        row_jobs_1 = df_jobs.loc[job_id_1]\n",
    "        # #################################################\n",
    "        ads_0 = row_jobs_0.ads\n",
    "        ads_1 = row_jobs_1.ads\n",
    "        att_num_0 = row_jobs_0.att_num\n",
    "        att_num_1 = row_jobs_1.att_num\n",
    "        active_site_0 = row_jobs_0.active_site\n",
    "        active_site_1 = row_jobs_1.active_site\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "        # Getting sorted atoms objects\n",
    "        name_atoms_sorted_0 = (\n",
    "            \"oer_adsorbate\", compenv_i, slab_id_i,\n",
    "            ads_0, active_site_0, att_num_0, )\n",
    "\n",
    "        name_atoms_sorted_1 = (\n",
    "            \"oer_adsorbate\", compenv_i, slab_id_i,\n",
    "            ads_1, active_site_1, att_num_1, )\n",
    "\n",
    "        row_atoms_sorted = df_atoms_sorted_ind.loc[name_atoms_sorted_0]\n",
    "        atoms_0 = row_atoms_sorted.atoms_sorted_good\n",
    "\n",
    "        row_atoms_sorted = df_atoms_sorted_ind.loc[name_atoms_sorted_1]\n",
    "        atoms_1 = row_atoms_sorted.atoms_sorted_good\n",
    "\n",
    "\n",
    "        pair_str_sorted = \"__\".join(list(np.sort(pair_j)))\n",
    "\n",
    "\n",
    "\n",
    "        # if pair_str_sorted in df_struct_drift_old.index:\n",
    "        #     # print(\"IJSIDFISD\")\n",
    "        #     # #############################################\n",
    "        #     row_struct_drift_i = df_struct_drift_old.loc[pair_str_sorted]\n",
    "        #     # #############################################\n",
    "        #     mean_displacement = row_struct_drift_i[\"mean_displacement\"]\n",
    "        #     mean_displacement_octahedra = row_struct_drift_i[\"mean_displacement_octahedra\"]\n",
    "        #     octahedra_atoms = row_struct_drift_i.octahedra_atoms\n",
    "        #     note = row_struct_drift_i[\"note\"]\n",
    "        #     error = row_struct_drift_i[\"error\"]\n",
    "        #     # #############################################\n",
    "\n",
    "        if pair_str_sorted not in df_struct_drift_old.index:\n",
    "\n",
    "            print(pair_j)\n",
    "\n",
    "        # else:\n",
    "        # if True:\n",
    "\n",
    "\n",
    "            # #############################################\n",
    "            # Running analysis\n",
    "            # #############################################\n",
    "            root_dir = os.path.join(\n",
    "                os.environ[\"PROJ_irox_oer\"],\n",
    "                \"dft_workflow/job_analysis/slab_struct_drift\",\n",
    "                \"out_data/df_match_files\")\n",
    "            if not os.path.exists(root_dir):\n",
    "                os.makedirs(root_dir)\n",
    "\n",
    "            path_i = os.path.join(\n",
    "                root_dir, pair_str_sorted + \".pickle\")\n",
    "            if Path(path_i).is_file():\n",
    "                with open(path_i, \"rb\") as fle:\n",
    "                    df_match = pickle.load(fle)\n",
    "            else:\n",
    "                print(\"Running:\", pair_j)\n",
    "                df_match = match_atoms(atoms_0, atoms_1)\n",
    "\n",
    "                pickle_path = os.path.join(\n",
    "                    root_dir, pair_str_sorted + \".pickle\")\n",
    "                with open(pickle_path, \"wb\") as fle:\n",
    "                    pickle.dump(df_match, fle)\n",
    "\n",
    "            df_match_2 = df_match[df_match.closest_distance > 0.000001]\n",
    "            mean_displacement = df_match_2[\"closest_distance\"].mean()\n",
    "\n",
    "\n",
    "            # #############################################\n",
    "            # Getting mean displacement of the octahedra\n",
    "            # #############################################\n",
    "\n",
    "            out_dict_1 = get_mean_displacement_octahedra(\n",
    "                df_match=df_match,\n",
    "                df_jobs=df_jobs,\n",
    "                df_init_slabs=df_init_slabs,\n",
    "                atoms_0=atoms_0,\n",
    "                job_id_0=job_id_0,\n",
    "                active_site=name_dict_i[\"active_site\"],\n",
    "                compenv=name_dict_i[\"compenv\"],\n",
    "                slab_id=name_dict_i[\"slab_id\"],\n",
    "                ads_0=ads_0,\n",
    "                active_site_0=active_site_0,\n",
    "                att_num_0=att_num_0,\n",
    "                )\n",
    "            mean_displacement_octahedra = out_dict_1[\"mean_displacement_octahedra\"]\n",
    "            metal_active_site = out_dict_1[\"metal_active_site\"]\n",
    "            note = out_dict_1[\"note\"]\n",
    "            error = out_dict_1[\"error\"]\n",
    "            octahedra_atoms = out_dict_1[\"octahedra_atoms\"]\n",
    "\n",
    "\n",
    "\n",
    "            # #################################################\n",
    "            data_dict_i = dict()\n",
    "            # #################################################\n",
    "            data_dict_i[\"pair_str\"] = pair_str_sorted\n",
    "            data_dict_i[\"job_id_0\"] = pair_j[0]\n",
    "            data_dict_i[\"job_id_1\"] = pair_j[1]\n",
    "            data_dict_i[\"job_ids\"] = list(pair_j)\n",
    "            data_dict_i[\"ads_0\"] = ads_0\n",
    "            data_dict_i[\"ads_1\"] = ads_1\n",
    "            data_dict_i[\"att_num_0\"] = att_num_0\n",
    "            data_dict_i[\"att_num_1\"] = att_num_1\n",
    "            data_dict_i[\"mean_displacement\"] = mean_displacement\n",
    "            data_dict_i[\"mean_displacement_octahedra\"] = mean_displacement_octahedra\n",
    "            data_dict_i[\"octahedra_atoms\"] = octahedra_atoms\n",
    "            data_dict_i[\"note\"] = note\n",
    "            data_dict_i[\"error\"] = error\n",
    "            # #################################################\n",
    "            data_dict_list.append(data_dict_i)\n",
    "            # #################################################\n",
    "\n",
    "    df_tmp = pd.DataFrame(data_dict_list)\n",
    "    df_list.append(df_tmp)\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_struct_drift = pd.concat(df_list, axis=0)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_struct_drift.shape\n",
    "\n",
    "# (2242, 13)\n",
    "# (4956, 13)\n",
    "# (9895, 13)\n",
    "# (10256,13)\n",
    "# (11565, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_struct_drift_new = pd.concat([\n",
    "    df_struct_drift,\n",
    "    df_struct_drift__done_prev,\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/slab_struct_drift\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_struct_drift_new.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_struct_drift_new, fle)\n",
    "    # pickle.dump(df_struct_drift, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_struct_drift\n",
    "\n",
    "df_struct_drift_tmp = get_df_struct_drift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_str</th>\n",
       "      <th>job_id_0</th>\n",
       "      <th>job_id_1</th>\n",
       "      <th>job_ids</th>\n",
       "      <th>ads_0</th>\n",
       "      <th>ads_1</th>\n",
       "      <th>att_num_0</th>\n",
       "      <th>att_num_1</th>\n",
       "      <th>mean_displacement</th>\n",
       "      <th>mean_displacement_octahedra</th>\n",
       "      <th>octahedra_atoms</th>\n",
       "      <th>note</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>halavamu_98__nobehepu_67</td>\n",
       "      <td>nobehepu_67</td>\n",
       "      <td>halavamu_98</td>\n",
       "      <td>[nobehepu_67, halavamu_98]</td>\n",
       "      <td>bare</td>\n",
       "      <td>bare</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>[73, 34, 26, 32, 35, 33]</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fidivuwi_89__nobehepu_67</td>\n",
       "      <td>nobehepu_67</td>\n",
       "      <td>fidivuwi_89</td>\n",
       "      <td>[nobehepu_67, fidivuwi_89]</td>\n",
       "      <td>bare</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042908</td>\n",
       "      <td>0.128524</td>\n",
       "      <td>[73, 34, 26, 32, 35, 33]</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dadolita_33__nobehepu_67</td>\n",
       "      <td>nobehepu_67</td>\n",
       "      <td>dadolita_33</td>\n",
       "      <td>[nobehepu_67, dadolita_33]</td>\n",
       "      <td>bare</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>[73, 34, 26, 32, 35, 33]</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nipidida_98__nobehepu_67</td>\n",
       "      <td>nobehepu_67</td>\n",
       "      <td>nipidida_98</td>\n",
       "      <td>[nobehepu_67, nipidida_98]</td>\n",
       "      <td>bare</td>\n",
       "      <td>oh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036887</td>\n",
       "      <td>0.097491</td>\n",
       "      <td>[73, 34, 26, 32, 35, 33]</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kulurono_32__nobehepu_67</td>\n",
       "      <td>nobehepu_67</td>\n",
       "      <td>kulurono_32</td>\n",
       "      <td>[nobehepu_67, kulurono_32]</td>\n",
       "      <td>bare</td>\n",
       "      <td>oh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.101894</td>\n",
       "      <td>[73, 34, 26, 32, 35, 33]</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pair_str     job_id_0     job_id_1  \\\n",
       "0  halavamu_98__nobehepu_67  nobehepu_67  halavamu_98   \n",
       "1  fidivuwi_89__nobehepu_67  nobehepu_67  fidivuwi_89   \n",
       "2  dadolita_33__nobehepu_67  nobehepu_67  dadolita_33   \n",
       "3  nipidida_98__nobehepu_67  nobehepu_67  nipidida_98   \n",
       "4  kulurono_32__nobehepu_67  nobehepu_67  kulurono_32   \n",
       "\n",
       "                      job_ids ads_0 ads_1  att_num_0  att_num_1  \\\n",
       "0  [nobehepu_67, halavamu_98]  bare  bare          1          2   \n",
       "1  [nobehepu_67, fidivuwi_89]  bare     o          1          1   \n",
       "2  [nobehepu_67, dadolita_33]  bare     o          1          1   \n",
       "3  [nobehepu_67, nipidida_98]  bare    oh          1          0   \n",
       "4  [nobehepu_67, kulurono_32]  bare    oh          1          1   \n",
       "\n",
       "   mean_displacement  mean_displacement_octahedra           octahedra_atoms  \\\n",
       "0           0.010155                     0.012745  [73, 34, 26, 32, 35, 33]   \n",
       "1           0.042908                     0.128524  [73, 34, 26, 32, 35, 33]   \n",
       "2           0.044172                     0.130558  [73, 34, 26, 32, 35, 33]   \n",
       "3           0.036887                     0.097491  [73, 34, 26, 32, 35, 33]   \n",
       "4           0.037038                     0.101894  [73, 34, 26, 32, 35, 33]   \n",
       "\n",
       "  note  error  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_struct_drift_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 1.115 min\n",
      "slab_struct_drift_2.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"slab_struct_drift_2.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
