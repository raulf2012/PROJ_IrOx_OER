{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OH slabs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/create_oh_slabs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "import pandas as pd\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.options.display.max_colwidth = 20\n",
    "\n",
    "from ase import Atoms\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import metal_atom_symbol\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_coord\n",
    "from methods import (\n",
    "get_df_jobs_data,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_active_sites,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import get_neighbor_metal_atom\n",
    "from local_methods import get_ads_pos_oh\n",
    "from local_methods import M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data objects with methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_data = get_df_jobs_data(exclude_wsl_paths=True)\n",
    "\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_active_sites = get_df_active_sites()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering down to only `oer_adsorbate` jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal.index.to_frame()\n",
    "\n",
    "df_jobs_anal = df_jobs_anal.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "var = \"o\"\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('ads == @var')\n",
    "\n",
    "var = \"NaN\"\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('active_site == @var')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking slab to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "job_ids__completely_done__ads_o = df_jobs_anal_i.job_id_max\n",
    "df_jobs_data_i = df_jobs_data.loc[job_ids__completely_done__ads_o]\n",
    "\n",
    "# #########################################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/create_oh_slabs\",\n",
    "    \"out_data/finished_O_ads\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for job_id_i, row_data_i in df_jobs_data_i.iterrows():\n",
    "    # #####################################################\n",
    "    final_atoms_i = row_data_i.final_atoms\n",
    "    # #####################################################\n",
    "    file_name_i = job_id_i + \".cif\"\n",
    "\n",
    "    # final_atoms_i.write(os.path.join(directory, file_name_i))\n",
    "\n",
    "    # final_atoms_i.write(os.path.join(\n",
    "    #     \"out_data\",\n",
    "    #     \"finished_O_ads\",\n",
    "    #     file_name_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "df_jobs_anal_i = df_jobs_anal_i.droplevel(level=0)\n",
    "\n",
    "data_dict_list = []\n",
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "\n",
    "    if verbose:\n",
    "        print(40 * \"=\")\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "\n",
    "    if slab_id_i not in df_active_sites.index:\n",
    "        print(244 * \"slab_id not found in df_active_sites, need to run `get_all_active_sites.ipynb`\")\n",
    "\n",
    "    # #####################################################\n",
    "    row_sites_i = df_active_sites.loc[slab_id_i]\n",
    "    # #####################################################\n",
    "    active_sites_unique_i = row_sites_i.active_sites_unique\n",
    "    # #####################################################\n",
    "\n",
    "    name_full_i = tuple([\"oer_adsorbate\", ] + list(name_i))\n",
    "\n",
    "    # #####################################################\n",
    "    # if name_i in df_atoms_sorted_ind.index:\n",
    "    if name_full_i in df_atoms_sorted_ind.index:\n",
    "        # row_atoms_i = df_atoms_sorted_ind.loc[name_i]\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[name_full_i]\n",
    "            # (compenv_i, slab_id_i, ads_i, active_site_i, att_num_i, )]\n",
    "        # #####################################################\n",
    "        atoms_sorted_good_i = row_atoms_i.atoms_sorted_good\n",
    "        atoms = atoms_sorted_good_i\n",
    "        # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        name_i = (compenv_i, slab_id_i, ads_i, active_site_i, att_num_i, )\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        # #####################################################\n",
    "        for site_i in active_sites_unique_i:\n",
    "            # print(\"site_i:\", site_i)\n",
    "\n",
    "            # #################################################\n",
    "            # #################################################\n",
    "            df_coord_i = get_df_coord(\n",
    "                mode=\"post-dft\",  # 'bulk', 'slab', 'post-dft'\n",
    "                post_dft_name_tuple=name_i,\n",
    "                )\n",
    "\n",
    "            oh_slabs_list = get_ads_pos_oh(\n",
    "                atoms=atoms,\n",
    "                site_i=site_i,\n",
    "                df_coord_i=df_coord_i,\n",
    "                # #########################\n",
    "                include_colinear=True,\n",
    "                verbose=False,\n",
    "                num_side_ads=3,\n",
    "                )\n",
    "\n",
    "            for att_num_oh_j, slab_oh_j in enumerate(oh_slabs_list):\n",
    "                # #############################################\n",
    "                data_dict_i = dict()\n",
    "                # #############################################\n",
    "                data_dict_i[\"compenv\"] = compenv_i\n",
    "                data_dict_i[\"slab_id\"] = slab_id_i\n",
    "                data_dict_i[\"ads\"] = ads_i\n",
    "                data_dict_i[\"active_site\"] = site_i\n",
    "                data_dict_i[\"att_num\"] = att_num_i\n",
    "                data_dict_i[\"att_num_oh\"] = att_num_oh_j\n",
    "                data_dict_i[\"slab_oh\"] = slab_oh_j\n",
    "                # #############################################\n",
    "                data_dict_list.append(data_dict_i)\n",
    "                # #############################################\n",
    "\n",
    "df_slabs_oh = pd.DataFrame(data_dict_list)\n",
    "df_slabs_oh = df_slabs_oh.set_index([\n",
    "    \"compenv\", \"slab_id\", \"ads\",\n",
    "    \"active_site\", \"att_num\", \"att_num_oh\", ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing *OH Slabs to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/create_oh_slabs\",\n",
    "    \"out_data/oh_slabs\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for name_i, row_i in df_slabs_oh.iterrows():\n",
    "    # #####################################################\n",
    "    slab_oh_i = row_i.slab_oh\n",
    "    # #####################################################\n",
    "\n",
    "    file_name_i = '__'.join(str(e) for e in list(name_i))\n",
    "    file_name_i += \".cif\"\n",
    "\n",
    "    # if True:\n",
    "    if False:\n",
    "        slab_oh_i.write(os.path.join(directory, file_name_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/create_oh_slabs\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_slabs_oh.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slabs_oh, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_slabs_oh\n",
    "\n",
    "df_slabs_oh_tmp = get_df_slabs_oh()\n",
    "# df_slabs_oh_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.254 min\n",
      "create_oh_slabs.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"create_oh_slabs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
