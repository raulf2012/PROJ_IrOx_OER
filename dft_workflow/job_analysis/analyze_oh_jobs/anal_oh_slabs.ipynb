{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze *OH slab job sets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/analyze_oh_jobs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_features,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_features = get_df_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal.index.to_frame()\n",
    "df_jobs_anal = df_jobs_anal.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "# Dropping rows that failed atoms sort, now it's just one job that blew up \n",
    "# job_id = \"dubegupi_27\"\n",
    "df_failed_to_sort = df_atoms_sorted_ind[\n",
    "    df_atoms_sorted_ind.failed_to_sort == True]\n",
    "df_jobs_anal_i = df_jobs_anal_i.drop(labels=df_failed_to_sort.index)\n",
    "\n",
    "# #########################################################\n",
    "df_index_i = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "# df_index_i = df_index_i[df_index_i.ads != \"o\"]\n",
    "df_index_i = df_index_i[df_index_i.ads == \"oh\"]\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    df_index_i.index \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "\n",
    "    # #########################################################\n",
    "    row_feat_i = df_features[df_features[\"data\"][\"job_id_max\"] == job_id_max_i]\n",
    "    if row_feat_i.shape[0] > 0:\n",
    "        row_feat_i = row_feat_i.iloc[0]\n",
    "        # #########################################################\n",
    "        num_missing_Os_i = row_feat_i.data.num_missing_Os\n",
    "        # #########################################################\n",
    "    else:\n",
    "        num_missing_Os_i = None\n",
    "\n",
    "    return(num_missing_Os_i)\n",
    "\n",
    "df_jobs_anal_i[\"num_missing_Os\"] = df_jobs_anal_i.apply(method, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "grouped = df_jobs_anal_i.groupby([\"compenv\", \"slab_id\", \"active_site\", ])\n",
    "for name, group in grouped:\n",
    "\n",
    "# for i in range(1):\n",
    "#     name =  ('slac', 'dotivela_46', 26.0, )\n",
    "#     group = grouped.get_group(name)\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    compenv_i = name[0]\n",
    "    slab_id_i = name[1]\n",
    "    active_site_i = name[2]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # TEMP\n",
    "    # any_nan_in_missing_O_col = any(group.num_missing_Os.isna())\n",
    "    # if any_nan_in_missing_O_col:\n",
    "    #     print(\"There are NaN in missing_Os col\")\n",
    "    #     print(\"name:\", name)\n",
    "    #     continue\n",
    "\n",
    "    # if any_nan_in_missing_O_col:\n",
    "    #     print(\"This shouldn't get printed if the prev 'continue' statement is working\")\n",
    "\n",
    "    job_ids_w_missing_Os = group[group.num_missing_Os > 0].job_id_max.tolist()\n",
    "\n",
    "\n",
    "    # Group of rows that have no missing O bonds\n",
    "    group_2 = group.drop(\n",
    "        labels=group[group.num_missing_Os > 0].index\n",
    "        )\n",
    "\n",
    "    all_jobs_bad = False\n",
    "    if group_2.shape[0] == 0:\n",
    "        all_jobs_bad = True\n",
    "\n",
    "    # #####################################################\n",
    "    df_anal_ind = df_jobs_anal.index.to_frame()\n",
    "    df = df_anal_ind\n",
    "    df = df[\n",
    "        (df[\"compenv\"] == compenv_i) &\n",
    "        (df[\"slab_id\"] == slab_id_i) &\n",
    "        (df[\"ads\"] == \"oh\") &\n",
    "        (df[\"active_site\"] == active_site_i) &\n",
    "        [True for i in range(len(df))]\n",
    "        ]\n",
    "    df_anal_ind_i = df\n",
    "    # #####################################################\n",
    "    att_nums_all = df_anal_ind_i.att_num.unique().tolist()\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Checking if all *OH slabs are finished, should all be done before making decisions\n",
    "    group_index_i = group.index.to_frame()\n",
    "    att_nums_i = group_index_i.att_num.unique()\n",
    "\n",
    "    all_oh_attempts_done = np.array_equal(att_nums_all, att_nums_i)\n",
    "\n",
    "    job_ids_sorted_energy = []\n",
    "    job_id_most_stable = None\n",
    "    if group_2.shape[0] > 0:\n",
    "        # #####################################################\n",
    "        df_jobs_data_i = df_jobs_data.loc[group_2.job_id_max]\n",
    "        df_jobs_data_i = df_jobs_data_i.sort_values(\"pot_e\")\n",
    "        # #####################################################\n",
    "        job_ids_sorted_energy = df_jobs_data_i.job_id.tolist()\n",
    "        job_id_most_stable = job_ids_sorted_energy[0]\n",
    "        # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    # #####################################################\n",
    "    data_dict_i[\"all_oh_attempts_done\"] = all_oh_attempts_done\n",
    "    data_dict_i[\"job_id_most_stable\"] = job_id_most_stable\n",
    "    data_dict_i[\"all_jobs_bad\"] = all_jobs_bad\n",
    "    data_dict_i[\"job_ids_sorted_energy\"] = job_ids_sorted_energy\n",
    "    data_dict_i[\"job_ids_w_missing_Os\"] = job_ids_w_missing_Os\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_oh_anal = pd.DataFrame(data_dict_list)\n",
    "# df_jobs_oh_anal.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/analyze_oh_jobs\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "path_i = os.path.join(directory, \"df_jobs_oh_anal.pickle\")\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_jobs_oh_anal, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compenv</th>\n",
       "      <th>slab_id</th>\n",
       "      <th>active_site</th>\n",
       "      <th>all_oh_attempts_done</th>\n",
       "      <th>job_id_most_stable</th>\n",
       "      <th>all_jobs_bad</th>\n",
       "      <th>job_ids_sorted_energy</th>\n",
       "      <th>job_ids_w_missing_Os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nersc</td>\n",
       "      <td>buvivore_13</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>nipidida_98</td>\n",
       "      <td>False</td>\n",
       "      <td>[nipidida_98, kulurono_32, bamoruwa_63]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nersc</td>\n",
       "      <td>dakoputu_58</td>\n",
       "      <td>74.0</td>\n",
       "      <td>True</td>\n",
       "      <td>buvawasa_30</td>\n",
       "      <td>False</td>\n",
       "      <td>[buvawasa_30, lalanota_37, miwanuho_78]</td>\n",
       "      <td>[wepewido_07]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  compenv      slab_id  active_site  all_oh_attempts_done job_id_most_stable  \\\n",
       "0   nersc  buvivore_13         38.0                 False        nipidida_98   \n",
       "1   nersc  dakoputu_58         74.0                  True        buvawasa_30   \n",
       "\n",
       "   all_jobs_bad                    job_ids_sorted_energy job_ids_w_missing_Os  \n",
       "0         False  [nipidida_98, kulurono_32, bamoruwa_63]                   []  \n",
       "1         False  [buvawasa_30, lalanota_37, miwanuho_78]        [wepewido_07]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods import get_df_jobs_oh_anal\n",
    "\n",
    "df_jobs_oh_anal_tmp = get_df_jobs_oh_anal()\n",
    "df_jobs_oh_anal_tmp.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.209 min\n",
      "anal_oh_slabs.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"anal_oh_slabs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
