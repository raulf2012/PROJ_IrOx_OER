{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing OER sets to file for\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/prepare_oer_sets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_features_targets,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_paths,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    )\n",
    "from methods import create_name_str_from_tup\n",
    "from methods import get_df_jobs_paths, get_df_jobs_data\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import write_other_jobs_in_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "df_features_targets = get_df_features_targets()\n",
    "df_atoms = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "df_jobs_data = get_df_jobs_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atoms = df_atoms.set_index(\"job_id\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop | writing OER sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "\n",
    "# name_i = ('slac', 'wufulafe_03', 58.0)\n",
    "# df_features_targets = df_features_targets.loc[[name_i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# print(111 * \"TEMP | \")\n",
    "\n",
    "# indices = [\n",
    "#     # ('slac', 'relovalu_12', 24.0),\n",
    "\n",
    "#     ('sherlock', 'sifebelo_94', 61.0),\n",
    "#     # ('sherlock', 'sifebelo_94', 62.0),\n",
    "\n",
    "#     ]\n",
    "\n",
    "# df_features_targets = df_features_targets.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b258ca2e2d94110a8aeb2c2936ccbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1st loop:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for name_i, row_i in df_features_targets.iterrows():\n",
    "\n",
    "iterator = tqdm(df_features_targets.index, desc=\"1st loop\")\n",
    "for i_cnt, index_i in enumerate(iterator):\n",
    "    row_i = df_features_targets.loc[index_i]\n",
    "\n",
    "    #  if verbose:\n",
    "    # print(name_i)\n",
    "\n",
    "    # #####################################################\n",
    "    job_id_o_i = row_i.data.job_id_o.iloc[0]\n",
    "    job_id_bare_i = row_i.data.job_id_bare.iloc[0]\n",
    "    job_id_oh_i = row_i.data.job_id_oh.iloc[0]\n",
    "    # #####################################################\n",
    "\n",
    "    if job_id_bare_i is None:\n",
    "        continue\n",
    "\n",
    "    oh_exists = False\n",
    "    if job_id_oh_i is not None:\n",
    "        oh_exists = True\n",
    "\n",
    "    # #####################################################\n",
    "    df_atoms__o = df_atoms.loc[job_id_o_i]\n",
    "    df_atoms__bare = df_atoms.loc[job_id_bare_i]\n",
    "\n",
    "    # #####################################################\n",
    "    atoms__o = df_atoms__o.atoms_sorted_good\n",
    "    atoms__bare = df_atoms__bare.atoms_sorted_good\n",
    "\n",
    "    if oh_exists:\n",
    "        df_atoms__oh = df_atoms.loc[job_id_oh_i]\n",
    "        atoms__oh = df_atoms__oh.atoms_sorted_good\n",
    "\n",
    "    # #########################################################\n",
    "    # #########################################################\n",
    "    # dir_name = create_name_str_from_tup(name_i)\n",
    "    dir_name = create_name_str_from_tup(index_i)\n",
    "\n",
    "    dir_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"dft_workflow/job_analysis/prepare_oer_sets\",\n",
    "        \"out_data/oer_group_files\",\n",
    "        dir_name)\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    atoms__o.write(\n",
    "        os.path.join(dir_path, \"atoms__o.traj\"))\n",
    "\n",
    "    atoms__o.write(\n",
    "        os.path.join(dir_path, \"atoms__o.cif\"))\n",
    "\n",
    "    atoms__bare.write(\n",
    "        os.path.join(dir_path, \"atoms__bare.traj\"))\n",
    "    atoms__bare.write(\n",
    "        os.path.join(dir_path, \"atoms__bare.cif\"))\n",
    "\n",
    "    if oh_exists:\n",
    "        atoms__oh.write(\n",
    "            os.path.join(dir_path, \"atoms__oh.traj\"))\n",
    "        atoms__oh.write(\n",
    "            os.path.join(dir_path, \"atoms__oh.cif\"))\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_to_write = dict(\n",
    "        job_id_o=job_id_o_i,\n",
    "        job_id_bare=job_id_bare_i,\n",
    "        job_id_oh=job_id_oh_i,\n",
    "        )\n",
    "\n",
    "    data_path = os.path.join(dir_path, \"data.json\")\n",
    "    with open(data_path, \"w\") as outfile:\n",
    "        json.dump(data_dict_to_write, outfile, indent=2)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Write other jobs in OER set\n",
    "    write_other_jobs_in_set(\n",
    "        job_id_bare_i,\n",
    "        dir_path=dir_path,\n",
    "        df_jobs=df_jobs, df_atoms=df_atoms,\n",
    "        df_jobs_paths=df_jobs_paths,\n",
    "        df_jobs_data=df_jobs_data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.19.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ase\n",
    "ase.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atoms(symbols='O5IrO3Ir2O4Ir2O3IrO2IrO3Ir2O4Ir2O3IrO2IrO3Ir2O4Ir2O6', pbc=True, cell=[[7.4378, 0.0, 0.0], [1.1887264100075394, 7.691846924357673, 0.0], [0.0, 0.0, 27.505188854999997]], initial_magmoms=..., constraint=FixAtoms(indices=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39]), calculator=SinglePointCalculator(...))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms__o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing top systems to file ROUGH TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP SYSTEMS\n",
    "\n",
    "if False:\n",
    "# if True:\n",
    "    df_features_targets = df_features_targets.loc[\n",
    "        [\n",
    "\n",
    "            (\"slac\", \"tefovuto_94\", 16.0),\n",
    "#             slac__nifupidu_92__032\n",
    "#             sherlock__bihetofu_24__036\n",
    "\n",
    "            ('slac', 'hobukuno_29', 16.0),\n",
    "            ('sherlock', 'ramufalu_44', 56.0),\n",
    "            ('slac', 'nifupidu_92', 32.0),\n",
    "            ('sherlock', 'bihetofu_24', 36.0),\n",
    "            ('slac', 'dotivela_46', 32.0),\n",
    "            ('slac', 'vovumota_03', 33.0),\n",
    "            ('slac', 'ralutiwa_59', 32.0),\n",
    "            ('sherlock', 'bebodira_65', 16.0),\n",
    "            ('sherlock', 'soregawu_05', 62.0),\n",
    "            ('slac', 'hivovaru_77', 26.0),\n",
    "            ('sherlock', 'vegarebo_06', 50.0),\n",
    "            ('slac', 'ralutiwa_59', 30.0),\n",
    "            ('sherlock', 'kamevuse_75', 49.0),\n",
    "            ('nersc', 'hesegula_40', 94.0),\n",
    "            ('slac', 'fewirefe_11', 39.0),\n",
    "            ('sherlock', 'vipikema_98', 60.0),\n",
    "            ('slac', 'gulipita_22', 48.0),\n",
    "            ('sherlock', 'rofetaso_24', 48.0),\n",
    "            ('slac', 'runopeno_56', 32.0),\n",
    "            ('slac', 'magiwuni_58', 26.0),\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    for name_i, row_i in df_features_targets.iterrows():\n",
    "\n",
    "        # #####################################################\n",
    "        job_id_o_i = row_i.data.job_id_o.iloc[0]\n",
    "        job_id_bare_i = row_i.data.job_id_bare.iloc[0]\n",
    "        job_id_oh_i = row_i.data.job_id_oh.iloc[0]\n",
    "        # #####################################################\n",
    "\n",
    "        oh_exists = False\n",
    "        if job_id_oh_i is not None:\n",
    "            oh_exists = True\n",
    "\n",
    "        # #####################################################\n",
    "        df_atoms__o = df_atoms.loc[job_id_o_i]\n",
    "        df_atoms__bare = df_atoms.loc[job_id_bare_i]\n",
    "\n",
    "        # #####################################################\n",
    "        atoms__o = df_atoms__o.atoms_sorted_good\n",
    "        atoms__bare = df_atoms__bare.atoms_sorted_good\n",
    "\n",
    "        if oh_exists:\n",
    "            df_atoms__oh = df_atoms.loc[job_id_oh_i]\n",
    "            atoms__oh = df_atoms__oh.atoms_sorted_good\n",
    "\n",
    "        # #########################################################\n",
    "        # #########################################################\n",
    "        dir_name = create_name_str_from_tup(name_i)\n",
    "\n",
    "        dir_path = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer\"],\n",
    "            \"dft_workflow/job_analysis/prepare_oer_sets\",\n",
    "            \"out_data/top_overpot_sys\")\n",
    "            # dir_name)\n",
    "\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "        # atoms__o.write(\n",
    "        #     os.path.join(dir_path, dir_name + \"_o.cif\"))\n",
    "\n",
    "        # atoms__bare.write(\n",
    "        #     os.path.join(dir_path, dir_name + \"_bare.cif\"))\n",
    "\n",
    "        if oh_exists:\n",
    "            atoms__oh.write(\n",
    "                os.path.join(dir_path, dir_name + \"_oh.cif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC | Writing random cifs to file to open in VESTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_features_targets.sample(n=6)\n",
    "\n",
    "if False:\n",
    "    for name_i, row_i in df_subset.iterrows():\n",
    "        tmp = 42\n",
    "\n",
    "        job_id_oh_i = row_i[(\"data\", \"job_id_oh\", \"\", )]\n",
    "\n",
    "\n",
    "        # # #####################################################\n",
    "        # job_id_o_i = row_i.data.job_id_o.iloc[0]\n",
    "        # job_id_bare_i = row_i.data.job_id_bare.iloc[0]\n",
    "        # job_id_oh_i = row_i.data.job_id_oh.iloc[0]\n",
    "        # # #####################################################\n",
    "\n",
    "        # if job_id_bare_i is None:\n",
    "        #     continue\n",
    "\n",
    "        oh_exists = False\n",
    "        if job_id_oh_i is not None:\n",
    "            oh_exists = True\n",
    "\n",
    "        # # #####################################################\n",
    "        # df_atoms__o = df_atoms.loc[job_id_o_i]\n",
    "        # df_atoms__bare = df_atoms.loc[job_id_bare_i]\n",
    "\n",
    "        # # #####################################################\n",
    "        # atoms__o = df_atoms__o.atoms_sorted_good\n",
    "        # atoms__bare = df_atoms__bare.atoms_sorted_good\n",
    "\n",
    "        if oh_exists:\n",
    "            df_atoms__oh = df_atoms.loc[job_id_oh_i]\n",
    "            atoms__oh = df_atoms__oh.atoms_sorted_good\n",
    "\n",
    "        # #########################################################\n",
    "        # #########################################################\n",
    "        file_name_i = create_name_str_from_tup(name_i)\n",
    "        print(file_name_i)\n",
    "\n",
    "        dir_path = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer\"],\n",
    "            \"dft_workflow/job_analysis/prepare_oer_sets\",\n",
    "            \"out_data/misc_cif_files_oh\")\n",
    "            # dir_name)\n",
    "\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "\n",
    "        # #####################################################\n",
    "        # atoms__o.write(\n",
    "        #     os.path.join(dir_path, \"atoms__o.traj\"))\n",
    "\n",
    "        # atoms__o.write(\n",
    "        #     os.path.join(dir_path, \"atoms__o.cif\"))\n",
    "\n",
    "        # atoms__bare.write(\n",
    "        #     os.path.join(dir_path, \"atoms__bare.traj\"))\n",
    "        # atoms__bare.write(\n",
    "        #     os.path.join(dir_path, \"atoms__bare.cif\"))\n",
    "\n",
    "        if oh_exists:\n",
    "            atoms__oh.write(\n",
    "                os.path.join(dir_path, file_name_i + \".cif\"))\n",
    "\n",
    "                # os.path.join(dir_path, \"atoms__oh.traj\"))\n",
    "\n",
    "            # atoms__oh.write(\n",
    "            #     os.path.join(dir_path, \"atoms__oh.cif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"write_oer_sets.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getcwd())\n",
    "# import sys\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# # pd.set_option('display.max_rows', None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
