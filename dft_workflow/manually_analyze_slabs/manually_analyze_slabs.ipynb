{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing new completed *O slabs to file for analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/manually_analyze_slabs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# # #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    )\n",
    "from methods import get_df_jobs_paths\n",
    "from methods import get_df_slabs_to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs = get_df_jobs()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "# #########################################################\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_slabs_to_run = df_slabs_to_run.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"att_num\", ], drop=False)\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_paths = get_df_jobs_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering down to `oer_adsorbate` jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_jobs_anal.index.to_frame()\n",
    "df_jobs_anal = df_jobs_anal.loc[\n",
    "    df_ind[df_ind.job_type == \"oer_adsorbate\"].index\n",
    "    ]\n",
    "df_jobs_anal = df_jobs_anal.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/manually_analyze_slabs\",\n",
    "    \"out_data/o_slabs\"\n",
    "    )\n",
    "\n",
    "from pathlib import Path\n",
    "my_file = Path(directory)\n",
    "if my_file.is_dir():\n",
    "    try:\n",
    "        shutil.rmtree(directory)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal_i = df_jobs_anal_i[df_jobs_anal_i.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "var = \"o\"\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('ads == @var')\n",
    "\n",
    "# #########################################################\n",
    "var = 1\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('att_num == @var')\n",
    "\n",
    "# #########################################################\n",
    "var = \"NaN\"\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('active_site == @var')\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal_i = df_jobs_anal_i.set_index(\n",
    "    df_jobs_anal_i.index.droplevel(level=[2, 3, ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_processed_indices = []\n",
    "for index_i, row_i in df_jobs_anal_i.iterrows():\n",
    "    index_man_inspected = index_i in df_slabs_to_run.index\n",
    "    if not index_man_inspected:\n",
    "        not_processed_indices.append(index_i)\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "    not_processed_indices\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting *O slabs to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    att_num_i = name_i[2]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_paths_i = df_jobs_paths.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    gdrive_path_i = row_paths_i.gdrive_path\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_data_i = df_jobs_data.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    slab_i = row_data_i.final_atoms\n",
    "    # #####################################################\n",
    "\n",
    "    file_name_i = compenv_i + \"_\" + slab_id_i + \"_\" + str(att_num_i).zfill(2)\n",
    "    if verbose:\n",
    "        print(file_name_i)\n",
    "        print(\n",
    "            \"$PROJ_irox_oer_gdrive/\",\n",
    "            gdrive_path_i,\n",
    "            \"\\n\",\n",
    "            sep=\"\")\n",
    "\n",
    "    file_name_i = os.path.join(\n",
    "        directory,\n",
    "        file_name_i + \".cif\")\n",
    "    slab_i.write(file_name_i) \n",
    "\n",
    "        # compenv_i + \"_\" + slab_id_i + \"_\" + str(att_num_i).zfill(2) + \".cif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write systems not manually processed to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "\n",
    "if df_index.shape[0] > 0:\n",
    "    for i in range(5): print(\n",
    "        \"Number of *O slabs that need to be manually analyzed:\",\n",
    "        df_index.shape[0],\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/manually_analyze_slabs\",\n",
    "    \"not_processed.csv\")\n",
    "# print(path_i)\n",
    "# df_index.to_csv(\"not_processed.csv\", index=False, header=False)\n",
    "df_index.to_csv(path_i, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.039 min\n",
      "manually_analyze_slabs.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"manually_analyze_slabs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
